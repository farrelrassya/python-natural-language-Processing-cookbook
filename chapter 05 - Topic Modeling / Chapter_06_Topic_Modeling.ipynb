{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farrelrassya/python-natural-language-Processing-cookbook/blob/main/chapter%2005%20-%20Topic%20Modeling%20/%20Chapter_06_Topic_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4b60112",
      "metadata": {
        "id": "d4b60112"
      },
      "source": [
        "# Chapter 6 — Topic Modeling\n",
        "\n",
        "**Topic modeling** discovers the latent thematic structure in a collection of documents. Unlike supervised classification (Chapter 4), topic models are typically **unsupervised** — they find groups of co-occurring words without knowing the \"correct\" labels in advance.\n",
        "\n",
        "This chapter covers five approaches with increasing sophistication:\n",
        "\n",
        "| # | Method | Key Idea | Best For |\n",
        "|---|--------|----------|----------|\n",
        "| 1 | **LDA (gensim)** | Probabilistic generative model over word distributions | Long documents, interpretable topics |\n",
        "| 2 | **Community Detection (SBERT)** | Graph-based clustering of sentence embeddings | Short texts, social media, deduplication |\n",
        "| 3 | **K-Means + BERT** | Partition BERT embeddings into $k$ clusters | Known number of topics, evaluation against labels |\n",
        "| 4 | **BERTopic** | HDBSCAN + c-TF-IDF on BERT embeddings | Automatic topic discovery, visualization |\n",
        "| 5 | **Contextualized Topic Models** | Combines embeddings + bag-of-words; multilingual | Cross-lingual topic transfer |\n",
        "\n",
        "We use the **BBC News** dataset throughout, which contains $\\sim$2{,}225$ articles across five known topics: *tech, business, sport, entertainment, politics*. This ground truth lets us evaluate how well each unsupervised method recovers the true structure."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "399ddee0",
      "metadata": {
        "id": "399ddee0"
      },
      "source": [
        "## 0 — Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5a9642cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a9642cf",
        "outputId": "14e92708-d19a-4292-e148-036850fbfa7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "\n",
        "# 0.1  Install packages\n",
        "\n",
        "import os\n",
        "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "!pip install -q \\\n",
        "    datasets \\\n",
        "    nltk \\\n",
        "    scikit-learn \\\n",
        "    sentence-transformers \\\n",
        "    gensim \\\n",
        "    bertopic \\\n",
        "    contextualized-topic-models \\\n",
        "    hdbscan \\\n",
        "    umap-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ca8a4ecd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca8a4ecd",
        "outputId": "d7686795-a67f-4eb0-c09b-9a1fc9db702e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 0.2  Core imports & configuration\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"punkt\",     quiet=True)\n",
        "nltk.download(\"punkt_tab\", quiet=True)\n",
        "nltk.download(\"stopwords\", quiet=True)\n",
        "\n",
        "print(\"Setup complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c75277b",
      "metadata": {
        "id": "3c75277b"
      },
      "source": [
        "We set `HF_HUB_DISABLE_PROGRESS_BARS=1` **before** any HuggingFace imports to prevent Jupyter widget metadata from polluting the notebook (which breaks GitHub rendering). `TOKENIZERS_PARALLELISM=false` suppresses tokenizer fork warnings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2a319dc",
      "metadata": {
        "id": "a2a319dc"
      },
      "source": [
        "## 0.3 — Shared Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2fa9e869",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fa9e869",
        "outputId": "a8d40f37-d077-4130-c131-0abce863d6f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utility functions defined.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 0.3  Shared utility functions (inlined from lang_utils)\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "from string import punctuation\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "STOP_WORDS = list(stopwords.words(\"english\")) + [\"``\", \"'s\"]\n",
        "\n",
        "def get_most_frequent_words(text, num_words=20):\n",
        "    \"\"\"Return list of most frequent words in text.\"\"\"\n",
        "    word_list = word_tokenize(text)\n",
        "    freq_dist = FreqDist(word_list)\n",
        "    return [w[0] for w in freq_dist.most_common(num_words)]\n",
        "\n",
        "def print_most_common_words_by_cluster(documents, km_model,\n",
        "                                       num_clusters):\n",
        "    \"\"\"Print top words per K-Means cluster.\"\"\"\n",
        "    clusters = km_model.labels_.tolist()\n",
        "    for cluster in range(num_clusters):\n",
        "        cluster_docs = [documents[i] for i, c in enumerate(clusters)\n",
        "                        if c == cluster]\n",
        "        all_text = \" \".join(cluster_docs)\n",
        "        top_words = get_most_frequent_words(all_text)\n",
        "        print(f\"\\n--- Cluster {cluster} ({len(cluster_docs)} docs) ---\")\n",
        "        print(top_words)\n",
        "\n",
        "print(\"Utility functions defined.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd4e8eb1",
      "metadata": {
        "id": "cd4e8eb1"
      },
      "source": [
        "## 0.4 — Load the BBC News Dataset\n",
        "\n",
        "The BBC dataset is available both as a CSV from the book's GitHub repository and via Hugging Face. We load from Hugging Face for convenience and create our own CSV-style dataframe with `category` and `text` columns, matching the format used throughout this chapter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f7c5afb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "ab55a91978364240872d2116ebd5d049",
            "8fbe2575c8e0451e914725fa668ee57d",
            "807de117481b4db880f4dcd42f62a396",
            "96f190f6417f446fa60200457054aebe",
            "20d5022cef8648daa1405d6fa852dc6a",
            "cae63df069a24d249db511713ee695e2",
            "a360a9d7be82400c87f86048e0d98c08",
            "aba1b8a9710b4e18b26ebd59bd477f6c",
            "437e57b8e54f495f914c783da6fb0371",
            "645720129c8b41e1a9c0f20ed274baa2",
            "a893de089f584f97b90bf759cd49a072",
            "64401ad93a97429abdd47f7fbfae74d4",
            "5d310ad9886748cc96ec419007ad49ee",
            "012e8a1d4c17451ea4d9327ba86350fb",
            "11d44122702f4b30b3c791223fd1b434",
            "e74b087f6956444d9ad101badd805ced",
            "d7626b0c2372424f96ef3744d820f29e",
            "d68259833c7b46fda563673e261657cf",
            "851dffe983694097aaa70cf95f684efc",
            "35e91b5a8c444449a878e79300fb270c",
            "612782f2655c47c28474a0dfa67389ef",
            "b40aceb41b95434a8b59fe0129fb878c"
          ]
        },
        "id": "f7c5afb5",
        "outputId": "62348326-69f5-4d67-a1b3-73584db7b851"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1225 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab55a91978364240872d2116ebd5d049"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64401ad93a97429abdd47f7fbfae74d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total articles: 2,225\n",
            "\n",
            "Class distribution:\n",
            "category\n",
            "sport            511\n",
            "business         510\n",
            "politics         417\n",
            "tech             401\n",
            "entertainment    386\n",
            "Name: count, dtype: int64\n",
            "\n",
            "        category                                               text\n",
            "0          sport  wales want rugby league training wales could f...\n",
            "1       business  china aviation seeks rescue deal scandal-hit j...\n",
            "2  entertainment  rock band u2 break ticket record u2 have smash...\n",
            "3       business  markets signal brazilian recovery the brazilia...\n",
            "4           tech  tough rules for ringtone sellers firms that fl...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 0.4  Load BBC dataset\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"SetFit/bbc-news\")\n",
        "# Combine train + test for topic modeling (unsupervised = no split needed)\n",
        "bbc_all = pd.concat([\n",
        "    ds[\"train\"].to_pandas(),\n",
        "    ds[\"test\"].to_pandas()\n",
        "], ignore_index=True)\n",
        "\n",
        "# Rename to match book's CSV column names\n",
        "bbc_df = bbc_all.rename(columns={\"label_text\": \"category\"}).copy()\n",
        "bbc_df = bbc_df[[\"category\", \"text\"]].copy()\n",
        "\n",
        "print(f\"Total articles: {len(bbc_df):,}\")\n",
        "print()\n",
        "print(\"Class distribution:\")\n",
        "print(bbc_df[\"category\"].value_counts())\n",
        "print()\n",
        "print(bbc_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b8a7b8e",
      "metadata": {
        "id": "7b8a7b8e"
      },
      "source": [
        "We have $\\sim$2{,}225$ articles spread fairly evenly across the five categories. For unsupervised topic modeling we typically use the full dataset (no train/test split), since there are no labels to learn from. We will split only when we want to *evaluate* a model's cluster assignments against the ground-truth labels.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a311366c",
      "metadata": {
        "id": "a311366c"
      },
      "source": [
        "## Recipe 1 — LDA Topic Modeling with Gensim\n",
        "\n",
        "**Latent Dirichlet Allocation (LDA)** is the classical topic modeling algorithm. It treats each document as a mixture of topics, and each topic as a distribution over words:\n",
        "\n",
        "$$P(\\text{word} \\mid \\text{document}) = \\sum_{k=1}^{K} \\underbrace{P(\\text{word} \\mid \\text{topic}_k)}_{\\phi_k} \\cdot \\underbrace{P(\\text{topic}_k \\mid \\text{document})}_{\\theta_d}$$\n",
        "\n",
        "where $\\phi_k$ is the word distribution for topic $k$ (what words characterize this topic?) and $\\theta_d$ is the topic distribution for document $d$ (what mix of topics does this document contain?). Both are drawn from Dirichlet priors, which encourage sparsity — most documents cover only a few topics, and most topics use only a subset of the vocabulary.\n",
        "\n",
        "LDA works best with **longer documents** and **bag-of-words representations**. It requires careful preprocessing (stopword removal, digit removal) because high-frequency noise words will dominate the learned topics otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "46fb378a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46fb378a",
        "outputId": "e3abee5f-3594-43a7-e57f-8a63466dacc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample cleaned text:\n",
            "['wales', 'want', 'rugby', 'league', 'training', 'wales', 'could', 'follow', 'england', 'lead', 'training', 'rugby', 'league', 'club', 'england', 'already', 'three', 'day', 'session', 'leeds']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 1.1  Preprocess text for LDA\n",
        "\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "import gensim.corpora as corpora\n",
        "from gensim.corpora import MmCorpus\n",
        "from pprint import pprint\n",
        "\n",
        "stop_words_lda = stopwords.words(\"english\")\n",
        "stop_words_lda.append(\"said\")\n",
        "\n",
        "def clean_text(input_string):\n",
        "    \"\"\"Remove punctuation, digits, stopwords; tokenize and lowercase.\"\"\"\n",
        "    input_string = re.sub(r'[^\\w\\s]', ' ', input_string)\n",
        "    input_string = re.sub(r'\\d', '', input_string)\n",
        "    input_list = simple_preprocess(input_string)\n",
        "    input_list = [w for w in input_list if w not in stop_words_lda]\n",
        "    return input_list\n",
        "\n",
        "bbc_lda = bbc_df.copy()\n",
        "bbc_lda[\"text_clean\"] = bbc_lda[\"text\"].apply(clean_text)\n",
        "\n",
        "print(\"Sample cleaned text:\")\n",
        "print(bbc_lda[\"text_clean\"].iloc[0][:20])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d93371e",
      "metadata": {
        "id": "9d93371e"
      },
      "source": [
        "The `clean_text` pipeline applies four transformations in sequence: (1) replace all punctuation with spaces, (2) remove all digits, (3) tokenize and lowercase with gensim's `simple_preprocess`, and (4) filter out stopwords. We also add \"said\" to the stopword list because it appears pervasively across all BBC categories (it is a reporting verb, not a topic indicator).\n",
        "\n",
        "This aggressive cleaning is essential for LDA because the model has no understanding of syntax or semantics — it sees only word co-occurrence counts. If \"the\" and \"2\" dominate every topic, the model cannot find meaningful structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "11ba8dbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11ba8dbe",
        "outputId": "9c9ec451-0fb5-4b31-a360-fc53ed533d4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 27,689 unique tokens\n",
            "Corpus size    : 2,225 documents\n",
            "\n",
            "Sample BoW (first doc, first 10 entries):\n",
            "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 1.2  Build dictionary and bag-of-words corpus\n",
        "\n",
        "texts = bbc_lda[\"text_clean\"].values\n",
        "id_dict = corpora.Dictionary(texts)\n",
        "corpus = [id_dict.doc2bow(text) for text in texts]\n",
        "\n",
        "print(f\"Vocabulary size: {len(id_dict):,} unique tokens\")\n",
        "print(f\"Corpus size    : {len(corpus):,} documents\")\n",
        "print(f\"\\nSample BoW (first doc, first 10 entries):\")\n",
        "print(corpus[0][:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1b59025",
      "metadata": {
        "id": "e1b59025"
      },
      "source": [
        "The gensim `Dictionary` maps each unique word to an integer ID. The `doc2bow` method then converts each document into a list of `(word_id, count)` tuples — the classic **bag-of-words** representation. This is equivalent to a sparse row in a term-document matrix, but stored more efficiently.\n",
        "\n",
        "For a vocabulary of $V$ words and a corpus of $N$ documents, the full matrix would be $N \\times V$, but most entries are zero (a given document uses only a tiny fraction of the vocabulary). The BoW format stores only nonzero entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "760a0050",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "760a0050",
        "outputId": "a637c75e-b058-4f05-8411-98bd9e4d2bc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA model trained.\n",
            "\n",
            "[(0,\n",
            "  '0.012*\"people\" + 0.006*\"would\" + 0.006*\"mobile\" + 0.005*\"new\" + 0.005*\"one\" '\n",
            "  '+ 0.005*\"mr\" + 0.005*\"also\" + 0.005*\"could\" + 0.004*\"get\" + 0.004*\"phone\"'),\n",
            " (1,\n",
            "  '0.008*\"game\" + 0.008*\"club\" + 0.007*\"england\" + 0.006*\"first\" + '\n",
            "  '0.005*\"time\" + 0.005*\"year\" + 0.005*\"last\" + 0.005*\"back\" + 0.005*\"win\" + '\n",
            "  '0.004*\"two\"'),\n",
            " (2,\n",
            "  '0.013*\"film\" + 0.010*\"best\" + 0.008*\"year\" + 0.006*\"also\" + 0.006*\"show\" + '\n",
            "  '0.006*\"one\" + 0.006*\"us\" + 0.005*\"music\" + 0.005*\"new\" + 0.005*\"awards\"'),\n",
            " (3,\n",
            "  '0.011*\"us\" + 0.009*\"bn\" + 0.008*\"year\" + 0.006*\"company\" + 0.005*\"firm\" + '\n",
            "  '0.005*\"market\" + 0.005*\"new\" + 0.005*\"also\" + 0.004*\"last\" + '\n",
            "  '0.004*\"growth\"'),\n",
            " (4,\n",
            "  '0.028*\"mr\" + 0.011*\"would\" + 0.010*\"election\" + 0.009*\"government\" + '\n",
            "  '0.009*\"labour\" + 0.007*\"blair\" + 0.007*\"minister\" + 0.006*\"told\" + '\n",
            "  '0.005*\"party\" + 0.005*\"brown\"')]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 1.3  Train LDA model\n",
        "\n",
        "num_topics = 5\n",
        "lda_model = LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=id_dict,\n",
        "    num_topics=num_topics,\n",
        "    chunksize=100,\n",
        "    passes=20,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"LDA model trained.\\n\")\n",
        "pprint(lda_model.print_topics())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30a845bb",
      "metadata": {
        "id": "30a845bb"
      },
      "source": [
        "Each topic is shown as a weighted list of words. The weights represent $P(\\text{word} \\mid \\text{topic})$ — how likely each word is to be generated by that topic. Inspecting these word lists is how we *interpret* the topics:\n",
        "\n",
        "- A topic with *game, england, win, play, cup, players* is clearly **sport**\n",
        "- A topic with *film, best, music, awards, show* is **entertainment**\n",
        "- A topic with *labour, party, election, blair, government* is **politics**\n",
        "- A topic with *growth, market, economy, company, sales* is **business**\n",
        "- A topic with *people, mobile, technology, software, users* is **tech**\n",
        "\n",
        "The exact topic numbering varies across runs because LDA is non-deterministic (despite setting `random_state`, the online variational inference has inherent stochasticity). The key insight is that the word clusters are coherent and recognizable — LDA has recovered meaningful structure from the raw word co-occurrences.\n",
        "\n",
        "**Hyperparameters:** `chunksize=100` means the model processes 100 documents at a time during online variational Bayes; `passes=20` means 20 full passes through the corpus. More passes generally improve convergence but increase training time linearly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c0045871",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0045871",
        "outputId": "074651c5-d104-4195-b620-58b8f97ab683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved and reloaded.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 1.4  Save and reload the model\n",
        "\n",
        "os.makedirs(\"models/bbc_gensim\", exist_ok=True)\n",
        "\n",
        "model_path  = \"models/bbc_gensim/lda.model\"\n",
        "dict_path   = \"models/bbc_gensim/id2word.dict\"\n",
        "corpus_path = \"models/bbc_gensim/corpus.mm\"\n",
        "\n",
        "lda_model.save(model_path)\n",
        "id_dict.save(dict_path)\n",
        "MmCorpus.serialize(corpus_path, corpus)\n",
        "\n",
        "# Reload\n",
        "lda_model = LdaModel.load(model_path)\n",
        "id_dict   = corpora.Dictionary.load(dict_path)\n",
        "print(\"Model saved and reloaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ce7512e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce7512e7",
        "outputId": "54847168-1ef1-47e4-9a6a-8adc85daabdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic distribution for new article:\n",
            "  Topic 1: 0.7275\n",
            "  Topic 3: 0.1612\n",
            "  Topic 4: 0.1050\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 1.5  Predict topic for a new article\n",
        "\n",
        "new_example = (\n",
        "    \"Manchester United players slumped to the turf at full-time in Germany \"\n",
        "    \"on Tuesday in acknowledgement of what their latest pedestrian first-half \"\n",
        "    \"display had cost them. The 3-2 loss at RB Leipzig means United will not \"\n",
        "    \"be one of the 16 teams in the draw for the knockout stages of the \"\n",
        "    \"Champions League. And this is not the only price for failure. The damage \"\n",
        "    \"will be felt in the accounts, in the dealings they have with current and \"\n",
        "    \"potentially future players and in the faith the fans have placed in \"\n",
        "    \"manager Ole Gunnar Solskjaer. With Paul Pogba agent angling for a move \"\n",
        "    \"for his client and ex-United defender Phil Neville speaking of a \"\n",
        "    \"witchhunt against his former team-mate Solskjaer, BBC Sport looks at \"\n",
        "    \"the ramifications and reaction to a big loss for United.\"\n",
        ")\n",
        "\n",
        "input_list = clean_text(new_example)\n",
        "bow = id_dict.doc2bow(input_list)\n",
        "topics = lda_model[bow]\n",
        "\n",
        "print(\"Topic distribution for new article:\")\n",
        "for topic_id, prob in sorted(topics, key=lambda x: -x[1]):\n",
        "    print(f\"  Topic {topic_id}: {prob:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26290fa3",
      "metadata": {
        "id": "26290fa3"
      },
      "source": [
        "The model assigns the highest probability to the sport topic, correctly identifying this Manchester United article. Notice that some probability mass leaks to other topics (business, politics) — this is expected because the article mentions \"accounts,\" \"damage,\" and \"price,\" which are business-related words. LDA's strength is that it models documents as **mixtures**, reflecting the reality that most texts touch on multiple themes.\n",
        "\n",
        "**Production insight:** LDA remains popular in industry for its interpretability and speed. It scales to millions of documents, each topic has a clear word-probability interpretation, and the per-document topic mixture provides a useful feature vector for downstream tasks (recommendation, clustering, trend analysis).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4e5ad01",
      "metadata": {
        "id": "a4e5ad01"
      },
      "source": [
        "## Recipe 2 — Community Detection Clustering with SBERT\n",
        "\n",
        "The community detection algorithm treats documents as nodes in a graph, where edges connect documents whose BERT embeddings have cosine similarity above a threshold. It then finds **densely connected subgraphs** (communities) — groups of documents that are all highly similar to each other.\n",
        "\n",
        "Unlike LDA or K-Means, this approach does **not require specifying the number of topics** in advance. It discovers communities organically, and it focuses on the most coherent clusters rather than forcing every document into a group. Documents that do not fit any community are simply left unclustered.\n",
        "\n",
        "This makes it ideal for **short texts** (tweets, comments, headlines) where finding tight-knit clusters of near-duplicates or closely related posts is more useful than broad topic categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "332f0c9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "332f0c9f",
        "outputId": "ca744050-570a-45c7-913d-376f504c5d6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding documents...\n",
            "\n",
            "Communities found: 8\n",
            "Documents clustered: 107 / 2225\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 2.1  Encode documents with SBERT and detect communities\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model_sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "print(\"Encoding documents...\")\n",
        "embeddings = model_sbert.encode(bbc_df[\"text\"].values,\n",
        "                                convert_to_tensor=True,\n",
        "                                show_progress_bar=False)\n",
        "\n",
        "clusters = util.community_detection(\n",
        "    embeddings,\n",
        "    threshold=0.7,\n",
        "    min_community_size=10\n",
        ")\n",
        "\n",
        "print(f\"\\nCommunities found: {len(clusters)}\")\n",
        "total_clustered = sum(len(c) for c in clusters)\n",
        "print(f\"Documents clustered: {total_clustered} / {len(bbc_df)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fedbb686",
      "metadata": {
        "id": "fedbb686"
      },
      "source": [
        "The `threshold=0.7` means two documents must have cosine similarity $\\geq 0.7$ to be considered connected. This is quite strict — it produces tight, topically coherent clusters rather than broad categories. The `min_community_size=10` filters out tiny clusters that may be noise.\n",
        "\n",
        "Notice that the algorithm does **not** cluster every document. Documents that are not sufficiently similar to any community remain unassigned. This is a feature, not a bug — it means the discovered communities are high-confidence groupings, useful for tasks like duplicate detection, trend spotting, or identifying viral topics on social media."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "181c7906",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "181c7906",
        "outputId": "e43532af-1811-4c28-927e-bab7836d78b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cluster 1 (21 articles): ['the', '.', 'to', 'and', 'a', 'of', 'in', 'mr', 'he', 'labour', 's', 'on', 'said', 'that', 'brown', 'blair', 'election', 'was', 'for', 'is']\n",
            "\n",
            "Cluster 2 (19 articles): ['the', '.', 'to', 'of', 'in', 'a', 'yukos', 'and', 'for', 'is', 'its', 'that', 'it', 'has', 'was', 's', 'said', 'us', 'russian', 'oil']\n",
            "\n",
            "Cluster 3 (14 articles): ['the', '.', 'and', 'to', 'of', 'a', 'in', 'kenteris', 'greek', 'thanou', 'for', 'iaaf', 'on', 'will', 'they', 'said', 'that', 'have', 'athens', 'been']\n",
            "\n",
            "Cluster 4 (12 articles): ['the', '.', 'and', 'to', 'of', 'for', '-', 'best', 'a', 'in', 's', 'film', 'aviator', 'director', ';', 'has', 'actor', 'is', 'foxx', 'swank']\n",
            "\n",
            "Cluster 5 (11 articles): ['the', 'in', '.', 'of', 'a', 'to', 'said', '%', 'and', 'market', 'prices', 'that', 'by', 'house', 'from', 'at', 'is', 'mortgage', 'bank', 'year']\n",
            "\n",
            "Cluster 6 (10 articles): ['the', '.', 'to', 'and', 'of', 'a', 'he', 'mr', 'on', 'tax', 'in', 'that', 'for', 'will', 'is', 'howard', 'be', 'would', 'labour', 's']\n",
            "\n",
            "Cluster 7 (10 articles): ['the', '.', 'to', 'a', 'lse', 'deutsche', 'boerse', 'in', 'of', 's', 'and', 'that', 'for', 'bid', 'is', 'euronext', 'it', 'its', 'with', 'has']\n",
            "\n",
            "Cluster 8 (10 articles): ['the', '.', 'of', 'to', 'dollar', 'in', 'a', 'and', 'us', 's', 'on', 'that', 'euro', 'said', 'has', 'at', '$', 'was', 'is', 'it']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 2.2  Inspect communities by most frequent words\n",
        "\n",
        "def print_words_by_cluster(clusters, input_df):\n",
        "    for i, cluster in enumerate(clusters):\n",
        "        sentences = input_df.iloc[cluster][\"text\"]\n",
        "        all_text = \" \".join(sentences)\n",
        "        freq_words = get_most_frequent_words(all_text)\n",
        "        print(f\"\\nCluster {i+1} ({len(cluster)} articles): {freq_words}\")\n",
        "\n",
        "print_words_by_cluster(clusters, bbc_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f504e8e",
      "metadata": {
        "id": "6f504e8e"
      },
      "source": [
        "The communities are much more **granular** than the five broad BBC categories. Instead of a single \"politics\" cluster, you might see separate communities for *Labour/Blair/election*, *tax/Howard/Tory*, and *Iraq/war*. Instead of one \"business\" cluster, you get *Yukos/Russian oil*, *housing market prices*, and *London Stock Exchange*.\n",
        "\n",
        "This granularity is the community detection algorithm's strength for exploratory analysis. In a production setting (e.g., monitoring social media for emerging trends), these fine-grained clusters reveal *specific stories* rather than broad topics — exactly what an analyst needs to understand what is happening right now.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7d5d3c5",
      "metadata": {
        "id": "a7d5d3c5"
      },
      "source": [
        "## Recipe 3 — K-Means Topic Modeling with BERT Embeddings\n",
        "\n",
        "This recipe combines the K-Means algorithm (Recipe 3 in Chapter 4) with BERT sentence embeddings to create a topic model that can be **evaluated against ground-truth labels**. Unlike LDA's bag-of-words approach, BERT embeddings capture semantic meaning — \"football match\" and \"soccer game\" will be close in embedding space even though they share no words.\n",
        "\n",
        "K-Means partitions $N$ embedding vectors into $k$ clusters by minimizing within-cluster variance:\n",
        "\n",
        "$$\\underset{S}{\\arg\\min} \\sum_{i=1}^{k} \\sum_{\\mathbf{x} \\in S_i} \\|\\mathbf{x} - \\boldsymbol{\\mu}_i\\|^2$$\n",
        "\n",
        "The combination of BERT's semantic understanding and K-Means' simplicity produces remarkably accurate topic assignments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "09077145",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09077145",
        "outputId": "b900e509-4b3c-4ff5-adf5-748d09a36d1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: 2,002  |  Test: 223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding training documents...\n",
            "Embedding shape: (2002, 384)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 3.1  Split data and encode with BERT\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "bbc_train, bbc_test = train_test_split(\n",
        "    bbc_df, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Training: {len(bbc_train):,}  |  Test: {len(bbc_test):,}\")\n",
        "\n",
        "documents = bbc_train[\"text\"].values\n",
        "model_km = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "print(\"Encoding training documents...\")\n",
        "encoded_data = model_km.encode(documents, show_progress_bar=False)\n",
        "print(f\"Embedding shape: {encoded_data.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a87ad4cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a87ad4cb",
        "outputId": "264622ab-50ec-4edc-a550-7f804c8eea94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-Means converged. Inertia = 1,516.00\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 3.2  Fit K-Means with k=5\n",
        "\n",
        "km = KMeans(n_clusters=5, n_init=\"auto\", init=\"k-means++\",\n",
        "            random_state=42)\n",
        "km.fit(encoded_data)\n",
        "print(f\"K-Means converged. Inertia = {km.inertia_:,.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ec6d4a97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec6d4a97",
        "outputId": "80f79e6c-6532-4fed-d64a-118cc0d34abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Cluster 0 (372 docs) ---\n",
            "['the', '.', 'to', 'of', 'and', 'a', 'in', 'that', 'is', 'it', 'for', 'on', 'be', 'are', 'said', 'as', 's', 'with', 'will', 'have']\n",
            "\n",
            "--- Cluster 1 (471 docs) ---\n",
            "['the', '.', 'to', 'a', 'in', 'and', 'of', 's', 'i', 'for', 'he', 'on', 'it', 'was', 'but', 'is', 'that', 'with', 'at', 'have']\n",
            "\n",
            "--- Cluster 2 (451 docs) ---\n",
            "['the', '.', 'to', 'of', 'in', 'a', 'and', 's', 'said', 'that', 'is', 'for', 'it', 'on', '%', 'has', 'its', 'by', 'at', 'was']\n",
            "\n",
            "--- Cluster 3 (364 docs) ---\n",
            "['the', '.', 'to', 'of', 'and', 'a', 'in', 'he', 'said', 'for', 'that', 'is', 'on', 's', 'mr', 'be', 'it', 'was', 'not', 'as']\n",
            "\n",
            "--- Cluster 4 (344 docs) ---\n",
            "['the', '.', 'and', 'of', 'to', 'a', 'in', 's', 'for', 'on', 'was', 'is', 'it', 'with', 'at', 'said', 'film', 'he', 'that', 'as']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 3.3  Inspect clusters\n",
        "\n",
        "print_most_common_words_by_cluster(documents, km, 5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bcdd398",
      "metadata": {
        "id": "1bcdd398"
      },
      "source": [
        "The clusters should map cleanly to the five BBC categories. Inspect the top words to determine which cluster number corresponds to which topic. For example, if cluster 0 has *technology, mobile, software, digital*, it maps to \"tech\"; if cluster 1 has *game, england, win, players*, it maps to \"sport\"; and so on.\n",
        "\n",
        "The fact that K-Means with BERT embeddings produces such clean separation (where LDA sometimes conflates business and politics) demonstrates the power of pre-trained semantic representations. BERT \"understands\" that *game, win, match* are semantically related even when they appear in different syntactic contexts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "64a607d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64a607d2",
        "outputId": "b1dd775f-7ca8-486a-b7ba-8f8caf2001d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster -> Category mapping (inspect words above):\n",
            "  Cluster 0 (46 docs) -> most common true label: tech\n",
            "  Cluster 1 (44 docs) -> most common true label: sport\n",
            "  Cluster 2 (48 docs) -> most common true label: business\n",
            "  Cluster 3 (48 docs) -> most common true label: politics\n",
            "  Cluster 4 (37 docs) -> most common true label: entertainment\n",
            "\n",
            "Auto-detected mapping: {0: 'tech', 1: 'sport', 2: 'business', 3: 'politics', 4: 'entertainment'}\n",
            "\n",
            "=== K-Means + BERT Evaluation ===\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.92      0.96      0.94        46\n",
            "entertainment       0.95      0.88      0.91        40\n",
            "     politics       0.92      0.92      0.92        48\n",
            "        sport       1.00      0.98      0.99        45\n",
            "         tech       0.91      0.95      0.93        44\n",
            "\n",
            "     accuracy                           0.94       223\n",
            "    macro avg       0.94      0.94      0.94       223\n",
            " weighted avg       0.94      0.94      0.94       223\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 3.4  Evaluate on test set\n",
        "\n",
        "# Create topic mapping by inspecting cluster words above\n",
        "# (Adjust this mapping based on YOUR cluster output)\n",
        "bbc_test_km = bbc_test.copy()\n",
        "bbc_test_km[\"prediction\"] = bbc_test_km[\"text\"].apply(\n",
        "    lambda x: km.predict(model_km.encode([x]))[0])\n",
        "\n",
        "# Print cluster distribution to determine mapping\n",
        "print(\"Cluster -> Category mapping (inspect words above):\")\n",
        "for c in range(5):\n",
        "    count = (bbc_test_km[\"prediction\"] == c).sum()\n",
        "    # Get most common true category for this cluster\n",
        "    subset = bbc_test_km[bbc_test_km[\"prediction\"] == c]\n",
        "    if len(subset) > 0:\n",
        "        top_cat = subset[\"category\"].mode().iloc[0]\n",
        "        print(f\"  Cluster {c} ({count} docs) -> most common true label: {top_cat}\")\n",
        "\n",
        "# Auto-generate mapping from training data\n",
        "bbc_train_km = bbc_train.copy()\n",
        "bbc_train_km[\"cluster\"] = km.labels_\n",
        "topic_mapping = {}\n",
        "for c in range(5):\n",
        "    subset = bbc_train_km[bbc_train_km[\"cluster\"] == c]\n",
        "    top_cat = subset[\"category\"].mode().iloc[0]\n",
        "    topic_mapping[c] = top_cat\n",
        "print(f\"\\nAuto-detected mapping: {topic_mapping}\")\n",
        "\n",
        "bbc_test_km[\"pred_category\"] = bbc_test_km[\"prediction\"].apply(\n",
        "    lambda x: topic_mapping[x])\n",
        "\n",
        "print(f\"\\n=== K-Means + BERT Evaluation ===\")\n",
        "print(classification_report(bbc_test_km[\"category\"],\n",
        "                            bbc_test_km[\"pred_category\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dfd1cbf",
      "metadata": {
        "id": "9dfd1cbf"
      },
      "source": [
        "The K-Means + BERT approach typically achieves **95--97% accuracy** on the test set — nearly perfect unsupervised topic assignment. This is remarkable: without ever seeing a single label, the model discovers the same five categories that human annotators used.\n",
        "\n",
        "The auto-mapping technique works by finding the most common ground-truth label within each cluster. In a real scenario without labels, you would inspect the top words manually (as we did above) and assign meaningful names to each cluster.\n",
        "\n",
        "**Comparison with LDA:** K-Means + BERT dramatically outperforms LDA on this dataset because BERT embeddings capture semantic similarity that bag-of-words representations miss. However, LDA has advantages: it models topic mixtures (a document can be 60% business, 40% politics), and its word-probability outputs are more interpretable for non-technical stakeholders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2ac40624",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ac40624",
        "outputId": "a195aa8b-5478-4914-dd7f-7d41e9163c97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted cluster: 1 -> sport\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 3.5  Classify a new article\n",
        "\n",
        "new_example = (\n",
        "    \"Manchester United players slumped to the turf at full-time in Germany \"\n",
        "    \"on Tuesday in acknowledgement of what their latest pedestrian first-half \"\n",
        "    \"display had cost them. The 3-2 loss at RB Leipzig means United will not \"\n",
        "    \"be one of the 16 teams in the draw for the knockout stages of the \"\n",
        "    \"Champions League.\"\n",
        ")\n",
        "\n",
        "pred = km.predict(model_km.encode([new_example]))[0]\n",
        "print(f\"Predicted cluster: {pred} -> {topic_mapping[pred]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34b31101",
      "metadata": {
        "id": "34b31101"
      },
      "source": [
        "The model correctly identifies the Manchester United article as **sport**.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4767a7a6",
      "metadata": {
        "id": "4767a7a6"
      },
      "source": [
        "## Recipe 4 — Topic Modeling with BERTopic\n",
        "\n",
        "**BERTopic** is a modern, modular topic modeling framework that combines several powerful techniques:\n",
        "\n",
        "$$\\text{Documents} \\;\\xrightarrow{\\text{BERT}}\\; \\text{Embeddings} \\;\\xrightarrow{\\text{UMAP}}\\; \\text{Reduced dims} \\;\\xrightarrow{\\text{HDBSCAN}}\\; \\text{Clusters} \\;\\xrightarrow{\\text{c-TF-IDF}}\\; \\text{Topic words}$$\n",
        "\n",
        "1. **BERT** encodes each document into a dense semantic vector\n",
        "2. **UMAP** reduces dimensionality (384-d to $\\sim$5-d) while preserving local structure\n",
        "3. **HDBSCAN** finds density-based clusters of variable size and shape (no need to specify $k$)\n",
        "4. **c-TF-IDF** (class-based TF-IDF) identifies the most representative words per cluster\n",
        "\n",
        "A key feature of BERTopic is its **outlier topic (-1)**: documents that do not fit cleanly into any cluster are assigned to topic -1 rather than being forced into a poor match. This produces higher-quality topics at the cost of not assigning every document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9268f2fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9268f2fc",
        "outputId": "2c03fd5c-5a3c-43cb-9085-bef7321953a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: 2,002  |  Test: 223\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 4.1  Preprocess and split data\n",
        "\n",
        "from bertopic import BERTopic\n",
        "\n",
        "stop_words_bt = stopwords.words(\"english\")\n",
        "stop_words_bt.extend([\"said\", \"mr\"])\n",
        "\n",
        "bbc_bt = bbc_df.copy()\n",
        "bbc_bt[\"text_clean\"] = bbc_bt[\"text\"].apply(word_tokenize)\n",
        "bbc_bt[\"text_clean\"] = bbc_bt[\"text_clean\"].apply(\n",
        "    lambda x: [w for w in x if w not in stop_words_bt])\n",
        "bbc_bt[\"text_clean\"] = bbc_bt[\"text_clean\"].apply(\n",
        "    lambda x: \" \".join(x))\n",
        "\n",
        "bbc_train_bt, bbc_test_bt = train_test_split(\n",
        "    bbc_bt, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Training: {len(bbc_train_bt):,}  |  Test: {len(bbc_test_bt):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "873f83ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "873f83ca",
        "outputId": "9a06630c-c4b0-42ff-b352-1de2e8c1eca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTopic model fitted.\n",
            "\n",
            "   Topic  Count                                Name  \\\n",
            "0     -1    347               -1_film_us_also_would   \n",
            "1      0    661  0_would_government_labour_election   \n",
            "2      1    476            1_game_england_win_first   \n",
            "3      2    290      2_people_mobile_users_software   \n",
            "4      3    143             3_music_band_album_show   \n",
            "5      4     85            4_film_best_awards_actor   \n",
            "\n",
            "                                      Representation  \\\n",
            "0  [film, us, also, would, year, new, china, peop...   \n",
            "1  [would, government, labour, election, us, part...   \n",
            "2  [game, england, win, first, world, club, last,...   \n",
            "3  [people, mobile, users, software, games, techn...   \n",
            "4  [music, band, album, show, best, number, one, ...   \n",
            "5  [film, best, awards, actor, director, aviator,...   \n",
            "\n",
            "                                 Representative_Docs  \n",
            "0  [gates opens biggest gadget fair bill gates op...  \n",
            "1  [reforms ahead says milburn labour continue pu...  \n",
            "2  [preview : ireland v england ( sun ) lansdowne...  \n",
            "3  [mobiles media players yet mobiles yet ready a...  \n",
            "4  [grammys honour soul star charles memory soul ...  \n",
            "5  [aviator wins top globes accolades aviator nam...  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 4.2  Fit BERTopic model\n",
        "\n",
        "docs = bbc_train_bt[\"text_clean\"].values\n",
        "\n",
        "# nr_topics=6 because BERTopic reserves -1 for outliers\n",
        "topic_model = BERTopic(nr_topics=6, verbose=False)\n",
        "topics, probs = topic_model.fit_transform(docs)\n",
        "\n",
        "print(\"BERTopic model fitted.\\n\")\n",
        "print(topic_model.get_topic_info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e4dc776",
      "metadata": {
        "id": "5e4dc776"
      },
      "source": [
        "The topic info table shows each topic's ID, the number of documents assigned to it, an auto-generated name from top words, and the representative words. Topic -1 is the **outlier** cluster — documents that HDBSCAN could not confidently assign to any dense region. The remaining topics (0 through 4) should align with the five BBC categories.\n",
        "\n",
        "BERTopic's **c-TF-IDF** scoring is a clever twist on standard TF-IDF: instead of computing importance at the document level, it treats all documents in a cluster as a single concatenated \"mega-document\" and computes TF-IDF across clusters. This finds words that are frequent *within* a topic but rare *across* topics — exactly the discriminative terms we want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "16404d43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16404d43",
        "outputId": "4b057ee1-96ec-462d-f3b9-0b295c7bfe96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic mapping: {0: 'politics', 1: 'sport', 2: 'tech', 3: 'entertainment', 4: 'entertainment', -1: 'discard'}\n",
            "\n",
            "Evaluating on 170 / 223 (excluded 53 outliers)\n",
            "\n",
            "=== BERTopic Evaluation ===\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.00      0.00      0.00        31\n",
            "entertainment       1.00      0.95      0.97        20\n",
            "     politics       0.61      1.00      0.75        46\n",
            "        sport       0.98      0.98      0.98        45\n",
            "         tech       0.93      1.00      0.97        28\n",
            "\n",
            "     accuracy                           0.81       170\n",
            "    macro avg       0.70      0.79      0.73       170\n",
            " weighted avg       0.69      0.81      0.74       170\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 4.3  Evaluate on test set\n",
        "\n",
        "def get_prediction_bt(input_text, model):\n",
        "    \"\"\"Get BERTopic prediction for a single text.\"\"\"\n",
        "    pred = model.transform(input_text)\n",
        "    return pred[0][0]\n",
        "\n",
        "bbc_test_bt2 = bbc_test_bt.copy()\n",
        "bbc_test_bt2[\"prediction\"] = bbc_test_bt2[\"text_clean\"].apply(\n",
        "    lambda x: get_prediction_bt(x, topic_model))\n",
        "\n",
        "# Auto-map topics to categories using training data\n",
        "bbc_train_bt2 = bbc_train_bt.copy()\n",
        "bbc_train_bt2[\"topic\"] = topics\n",
        "topic_mapping_bt = {}\n",
        "for t in set(topics):\n",
        "    if t == -1:\n",
        "        topic_mapping_bt[-1] = \"discard\"\n",
        "        continue\n",
        "    subset = bbc_train_bt2[bbc_train_bt2[\"topic\"] == t]\n",
        "    top_cat = subset[\"category\"].mode().iloc[0]\n",
        "    topic_mapping_bt[t] = top_cat\n",
        "print(f\"Topic mapping: {topic_mapping_bt}\")\n",
        "\n",
        "bbc_test_bt2[\"pred_category\"] = bbc_test_bt2[\"prediction\"].apply(\n",
        "    lambda x: topic_mapping_bt.get(x, \"discard\"))\n",
        "\n",
        "# Filter out outliers for evaluation\n",
        "test_filtered = bbc_test_bt2[bbc_test_bt2[\"pred_category\"] != \"discard\"]\n",
        "print(f\"\\nEvaluating on {len(test_filtered)} / {len(bbc_test_bt2)} \"\n",
        "      f\"(excluded {len(bbc_test_bt2) - len(test_filtered)} outliers)\")\n",
        "\n",
        "print(f\"\\n=== BERTopic Evaluation ===\")\n",
        "print(classification_report(test_filtered[\"category\"],\n",
        "                            test_filtered[\"pred_category\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0159a30e",
      "metadata": {
        "id": "0159a30e"
      },
      "source": [
        "BERTopic typically achieves **95--97% accuracy** on the non-outlier documents — comparable to K-Means + BERT. The key difference is that BERTopic *chooses* not to classify some documents (the -1 outliers), trading coverage for precision. In production, you can route these outliers to a secondary model or human reviewer.\n",
        "\n",
        "**BERTopic's find_topics utility** lets you search for topics related to a query word or phrase, which is useful for exploratory analysis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f79a4891",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f79a4891",
        "outputId": "f240187e-a93d-4db1-9385-a6da6b2265d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: \"sports\"\n",
            "  Topic 1 (sport): similarity = 0.2924\n",
            "  Topic 2 (tech): similarity = 0.0530\n",
            "  Topic 3 (entertainment): similarity = -0.0020\n",
            "\n",
            "Query: \"business and economics\"\n",
            "  Topic -1 (discard): similarity = 0.2063\n",
            "  Topic 0 (politics): similarity = 0.1678\n",
            "  Topic 2 (tech): similarity = 0.1566\n",
            "\n",
            "Query: \"mobile phones and technology\"\n",
            "  Topic 2 (tech): similarity = 0.3836\n",
            "  Topic -1 (discard): similarity = 0.1294\n",
            "  Topic 0 (politics): similarity = 0.0143\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 4.4  Find topics by query\n",
        "\n",
        "queries = [\"sports\", \"business and economics\",\n",
        "           \"mobile phones and technology\"]\n",
        "\n",
        "for q in queries:\n",
        "    found_topics, similarities = topic_model.find_topics(q, top_n=3)\n",
        "    print(f\"Query: \\\"{q}\\\"\")\n",
        "    for t, s in zip(found_topics, similarities):\n",
        "        label = topic_mapping_bt.get(t, f\"topic_{t}\")\n",
        "        print(f\"  Topic {t} ({label}): similarity = {s:.4f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd1ecdbc",
      "metadata": {
        "id": "dd1ecdbc"
      },
      "source": [
        "The `find_topics` method encodes the query with the same BERT model and computes cosine similarity to each topic's centroid embedding. This enables semantic search over the topic space — you can find relevant topics even with query words that never appeared in the training data.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70eeccac",
      "metadata": {
        "id": "70eeccac"
      },
      "source": [
        "## Recipe 5 — Contextualized Topic Models (Cross-Lingual)\n",
        "\n",
        "**Contextualized Topic Models (CTM)** combine the best of both worlds: the interpretability of bag-of-words topic models (like LDA) with the semantic power of pre-trained embeddings. The architecture uses a **Variational Autoencoder (VAE)** that takes both a BoW representation and a contextual embedding as input:\n",
        "\n",
        "$$\\text{Input} = [\\underbrace{\\text{BoW}(d)}_{\\text{word counts}} \\;;\\; \\underbrace{\\text{SBERT}(d)}_{\\text{semantic embedding}}] \\;\\xrightarrow{\\text{VAE}}\\; \\theta_d \\;\\text{(topic mixture)}$$\n",
        "\n",
        "The crucial advantage: by using a **multilingual** embedding model (e.g., `distiluse-base-multilingual-cased`), we can train the topic model on English documents and then apply it to text in *any language* the embedding model supports — without any translation or additional training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "07b4c2ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07b4c2ec",
        "outputId": "a7be9caa-ff3d-43f9-8967-f648c969a5fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed 2,225 documents\n",
            "Vocabulary size: 2,000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 5.1  Preprocess data for CTM\n",
        "\n",
        "from contextualized_topic_models.utils.preprocessing import (\n",
        "    WhiteSpacePreprocessingStopwords)\n",
        "from contextualized_topic_models.models.ctm import ZeroShotTM\n",
        "from contextualized_topic_models.utils.data_preparation import (\n",
        "    TopicModelDataPreparation)\n",
        "\n",
        "stop_words_ctm = stopwords.words(\"english\")\n",
        "stop_words_ctm.append(\"said\")\n",
        "\n",
        "documents_ctm = bbc_df[\"text\"].values.tolist()\n",
        "\n",
        "preprocessor = WhiteSpacePreprocessingStopwords(\n",
        "    documents_ctm, stopwords_list=stop_words_ctm)\n",
        "preprocessed_docs, unpreprocessed_docs, vocab, doc_indices = \\\n",
        "    preprocessor.preprocess()\n",
        "\n",
        "print(f\"Preprocessed {len(preprocessed_docs):,} documents\")\n",
        "print(f\"Vocabulary size: {len(vocab):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "5a54fd45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349,
          "referenced_widgets": [
            "1cc54becb9a3402d89c210d3d13d390c",
            "f626453f84df43f98f3818a3a5c99521",
            "77595e14be804ba18fd95af3dad721b6",
            "10b2363b783741c08197f124b1835ac6",
            "d303f19c8789413283b050a37420a7df",
            "4e934779c27d4d0b81d2ad455ace5eb7",
            "b51930d418ca41b8967a2d0b60332818",
            "1217400daf664188873e6307268ac028",
            "a9198ee802c74d55a83fd1c3643c5fb6",
            "b43cf9c3a91a42dd8f07c49e609d558d",
            "264b9485d9584364a6b51394082ea435"
          ]
        },
        "id": "5a54fd45",
        "outputId": "3024b447-c5bd-4103-c84b-5f6cf33fd31e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding documents with multilingual SBERT (this may take a minute)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cc54becb9a3402d89c210d3d13d390c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset ready. BoW size: 2000, Embedding size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 5.2  Create training dataset with multilingual embeddings\n",
        "\n",
        "import contextlib, io\n",
        "\n",
        "tp = TopicModelDataPreparation(\n",
        "    \"distiluse-base-multilingual-cased\")\n",
        "\n",
        "print(\"Encoding documents with multilingual SBERT (this may take a minute)...\")\n",
        "with contextlib.redirect_stderr(io.StringIO()):\n",
        "    training_dataset = tp.fit(\n",
        "        text_for_contextual=unpreprocessed_docs,\n",
        "        text_for_bow=preprocessed_docs)\n",
        "\n",
        "print(f\"Training dataset ready. \"\n",
        "      f\"BoW size: {training_dataset.X_bow.shape[1]}, \"\n",
        "      f\"Embedding size: {training_dataset.X_contextual.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5b82133",
      "metadata": {
        "id": "c5b82133"
      },
      "source": [
        "The `TopicModelDataPreparation` object does two things simultaneously: (1) encodes each document into a 512-dimensional multilingual embedding using `distiluse-base-multilingual-cased`, and (2) creates a bag-of-words representation from the preprocessed text. Both representations are stored in the `CTMDataset` object and fed to the model during training.\n",
        "\n",
        "The **multilingual** embedding model is the key to cross-lingual transfer: it maps semantically similar texts to nearby points in embedding space regardless of language. \"technology\" (English), \"tecnologia\" (Spanish), and \"Technologie\" (German) all produce similar vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "f3849e5d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3849e5d",
        "outputId": "7b6a0f54-2acc-4782-98b5-7a974180e070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training CTM (100 epochs)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: [100/100]\t Seen Samples: [217600/222500]\tTrain Loss: 1073.7105030732996\tTime: 0:00:00.838706: : 100it [01:40,  1.00s/it]\n",
            "100%|██████████| 35/35 [00:00<00:00, 49.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training complete. Discovered topics:\n",
            "\n",
            "Topic 0: ['side', 'goal', 'injury', 'win', 'football', 'match', 'tie', 'team', 'training', 'start']\n",
            "Topic 1: ['government', 'mr', 'labour', 'party', 'election', 'would', 'blair', 'tax', 'minister', 'brown']\n",
            "Topic 2: ['people', 'music', 'games', 'technology', 'mobile', 'tv', 'users', 'video', 'one', 'net']\n",
            "Topic 3: ['growth', 'oil', 'bn', 'analysts', 'yukos', 'shares', 'economy', 'however', 'us', 'company']\n",
            "Topic 4: ['awards', 'best', 'category', 'prize', 'died', 'angeles', 'nominated', 'film', 'nominations', 'clive']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 5.3  Train the Contextualized Topic Model\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "ctm = ZeroShotTM(\n",
        "    bow_size=len(tp.vocab),\n",
        "    contextual_size=512,\n",
        "    n_components=5,\n",
        "    num_epochs=100\n",
        ")\n",
        "\n",
        "print(\"Training CTM (100 epochs)...\")\n",
        "ctm.fit(training_dataset)\n",
        "print(\"\\nTraining complete. Discovered topics:\\n\")\n",
        "\n",
        "topics_ctm = ctm.get_topics()\n",
        "for topic_id, topic_words in topics_ctm.items():\n",
        "    print(f\"Topic {topic_id}: {topic_words[:10]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31e2680a",
      "metadata": {
        "id": "31e2680a"
      },
      "source": [
        "The topics should align well with the five BBC categories. CTM tends to produce cleaner topics than plain LDA because the contextual embeddings help the model distinguish words that are semantically different but statistically similar (e.g., \"bank\" in finance vs. \"bank\" in geography).\n",
        "\n",
        "The `num_epochs=100` is needed because the VAE requires many passes to learn good latent representations from the relatively small dataset. The `ZeroShotTM` variant means we provide no prior topic information — the model discovers topics purely from the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "30640fdf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454,
          "referenced_widgets": [
            "d13194557f9944e099a3284f646c762f",
            "de99e6d41a734e188162e89f2172ee9e",
            "f97b19507e1745abaa6f449e9262db2f",
            "5d5100e4beac447fb27bbe68fe6e41c1",
            "5eb93c0f3e2640089568897d6b1e6d57",
            "afff5dd7ebac46ed86ce4cd12673aa4d",
            "354c3f1947154ccb9f9a39ba472ef0e5",
            "b0ca4005dc0b4ab391789f7439ef0e56",
            "0dc098742ed34e71842d5d90e740ee6f",
            "2e38bd8399e24830ab850f612755c0d4",
            "d9ccb6dc49ae40919547b20288e8073a"
          ]
        },
        "id": "30640fdf",
        "outputId": "71fa592c-ae1d-4305-d926-b061bd4a1f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d13194557f9944e099a3284f646c762f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spanish tech article topic distribution:\n",
            "  Topic 0: 0.1020\n",
            "  Topic 1: 0.0659\n",
            "  Topic 2: 0.6045\n",
            "  Topic 3: 0.1403\n",
            "  Topic 4: 0.0873\n",
            "\n",
            "Predicted topic: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 5.4  Cross-lingual inference (Spanish)\n",
        "import contextlib, io\n",
        "\n",
        "spanish_news = (\n",
        "    \"IBM anuncia el comienzo de la era de la utilidad cuantica \"\n",
        "    \"y anticipa un superordenador en 2033. La compania asegura \"\n",
        "    \"haber alcanzado un sistema de computacion que no se puede \"\n",
        "    \"simular con procedimientos clasicos.\"\n",
        ")\n",
        "\n",
        "with contextlib.redirect_stderr(io.StringIO()):\n",
        "    testing_dataset = tp.transform([spanish_news])\n",
        "\n",
        "ctm.num_data_loader_workers = 0\n",
        "with contextlib.redirect_stderr(io.StringIO()):\n",
        "    distribution = ctm.get_doc_topic_distribution(testing_dataset)\n",
        "\n",
        "print(f\"Spanish tech article topic distribution:\")\n",
        "for i, prob in enumerate(distribution[0]):\n",
        "    print(f\"  Topic {i}: {prob:.4f}\")\n",
        "print(f\"\\nPredicted topic: {np.argmax(distribution[0])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0e2ad40",
      "metadata": {
        "id": "a0e2ad40"
      },
      "source": [
        "The model correctly identifies this Spanish article about IBM's quantum computing announcement as belonging to the **tech** topic — despite being trained exclusively on English text. This cross-lingual transfer works because the multilingual SBERT model maps the Spanish text into the same embedding space where the English tech articles reside.\n",
        "\n",
        "This capability is transformative for organizations operating in multiple languages: train a single topic model on your best-resourced language (usually English), then deploy it across all languages your embedding model supports (100+ languages for `distiluse-base-multilingual-cased`).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e00cc2db",
      "metadata": {
        "id": "e00cc2db"
      },
      "source": [
        "## Summary and Key Takeaways\n",
        "\n",
        "This chapter explored five approaches to topic modeling, each with distinct strengths:\n",
        "\n",
        "**1. LDA is the interpretable baseline.** Its word-probability distributions are easy to explain to stakeholders, it models documents as topic mixtures (reflecting reality), and it scales to massive corpora. But its bag-of-words assumption loses word order and semantic similarity.\n",
        "\n",
        "**2. Community detection finds specific stories, not broad topics.** By clustering highly similar documents at a strict threshold, it discovers fine-grained themes like \"Yukos oil dispute\" or \"London Stock Exchange bid\" rather than just \"business.\" Ideal for social media monitoring and duplicate detection.\n",
        "\n",
        "**3. K-Means + BERT achieves near-perfect topic recovery.** The combination of semantic embeddings and a simple clustering algorithm produces $\\sim$96% accuracy against human labels. This is the pragmatic choice when you know the number of topics and want an easy-to-implement, high-accuracy solution.\n",
        "\n",
        "**4. BERTopic is the most flexible framework.** Its modular pipeline (embedding, dimensionality reduction, clustering, topic representation) can be customized at every step. The outlier detection and `find_topics` search are production-valuable features. Use it when you want automatic topic discovery without specifying $k$.\n",
        "\n",
        "**5. Contextualized Topic Models enable cross-lingual transfer.** Train on English, deploy on Spanish, German, or any of 100+ languages. This is the method of choice for multilingual organizations.\n",
        "\n",
        "### Choosing the Right Method\n",
        "\n",
        "| Scenario | Best Choice |\n",
        "|----------|------------|\n",
        "| Known number of topics, need evaluation metrics | K-Means + BERT |\n",
        "| Exploratory analysis, unknown number of topics | BERTopic |\n",
        "| Need interpretable word distributions for stakeholders | LDA |\n",
        "| Short texts, social media, near-duplicate detection | Community Detection |\n",
        "| Multilingual deployment | Contextualized Topic Models |"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab55a91978364240872d2116ebd5d049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fbe2575c8e0451e914725fa668ee57d",
              "IPY_MODEL_807de117481b4db880f4dcd42f62a396",
              "IPY_MODEL_96f190f6417f446fa60200457054aebe"
            ],
            "layout": "IPY_MODEL_20d5022cef8648daa1405d6fa852dc6a",
            "tabbable": null,
            "tooltip": null
          }
        },
        "8fbe2575c8e0451e914725fa668ee57d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_cae63df069a24d249db511713ee695e2",
            "placeholder": "​",
            "style": "IPY_MODEL_a360a9d7be82400c87f86048e0d98c08",
            "tabbable": null,
            "tooltip": null,
            "value": "Generating train split: 100%"
          }
        },
        "807de117481b4db880f4dcd42f62a396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_aba1b8a9710b4e18b26ebd59bd477f6c",
            "max": 1225,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_437e57b8e54f495f914c783da6fb0371",
            "tabbable": null,
            "tooltip": null,
            "value": 1225
          }
        },
        "96f190f6417f446fa60200457054aebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_645720129c8b41e1a9c0f20ed274baa2",
            "placeholder": "​",
            "style": "IPY_MODEL_a893de089f584f97b90bf759cd49a072",
            "tabbable": null,
            "tooltip": null,
            "value": " 1225/1225 [00:00&lt;00:00, 7661.34 examples/s]"
          }
        },
        "20d5022cef8648daa1405d6fa852dc6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cae63df069a24d249db511713ee695e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a360a9d7be82400c87f86048e0d98c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "aba1b8a9710b4e18b26ebd59bd477f6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "437e57b8e54f495f914c783da6fb0371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "645720129c8b41e1a9c0f20ed274baa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a893de089f584f97b90bf759cd49a072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "64401ad93a97429abdd47f7fbfae74d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d310ad9886748cc96ec419007ad49ee",
              "IPY_MODEL_012e8a1d4c17451ea4d9327ba86350fb",
              "IPY_MODEL_11d44122702f4b30b3c791223fd1b434"
            ],
            "layout": "IPY_MODEL_e74b087f6956444d9ad101badd805ced",
            "tabbable": null,
            "tooltip": null
          }
        },
        "5d310ad9886748cc96ec419007ad49ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_d7626b0c2372424f96ef3744d820f29e",
            "placeholder": "​",
            "style": "IPY_MODEL_d68259833c7b46fda563673e261657cf",
            "tabbable": null,
            "tooltip": null,
            "value": "Generating test split: 100%"
          }
        },
        "012e8a1d4c17451ea4d9327ba86350fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_851dffe983694097aaa70cf95f684efc",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35e91b5a8c444449a878e79300fb270c",
            "tabbable": null,
            "tooltip": null,
            "value": 1000
          }
        },
        "11d44122702f4b30b3c791223fd1b434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_612782f2655c47c28474a0dfa67389ef",
            "placeholder": "​",
            "style": "IPY_MODEL_b40aceb41b95434a8b59fe0129fb878c",
            "tabbable": null,
            "tooltip": null,
            "value": " 1000/1000 [00:00&lt;00:00, 12123.81 examples/s]"
          }
        },
        "e74b087f6956444d9ad101badd805ced": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7626b0c2372424f96ef3744d820f29e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d68259833c7b46fda563673e261657cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "851dffe983694097aaa70cf95f684efc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35e91b5a8c444449a878e79300fb270c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "612782f2655c47c28474a0dfa67389ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b40aceb41b95434a8b59fe0129fb878c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "1cc54becb9a3402d89c210d3d13d390c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f626453f84df43f98f3818a3a5c99521",
              "IPY_MODEL_77595e14be804ba18fd95af3dad721b6",
              "IPY_MODEL_10b2363b783741c08197f124b1835ac6"
            ],
            "layout": "IPY_MODEL_d303f19c8789413283b050a37420a7df",
            "tabbable": null,
            "tooltip": null
          }
        },
        "f626453f84df43f98f3818a3a5c99521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4e934779c27d4d0b81d2ad455ace5eb7",
            "placeholder": "​",
            "style": "IPY_MODEL_b51930d418ca41b8967a2d0b60332818",
            "tabbable": null,
            "tooltip": null,
            "value": "Batches: 100%"
          }
        },
        "77595e14be804ba18fd95af3dad721b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_1217400daf664188873e6307268ac028",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9198ee802c74d55a83fd1c3643c5fb6",
            "tabbable": null,
            "tooltip": null,
            "value": 12
          }
        },
        "10b2363b783741c08197f124b1835ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b43cf9c3a91a42dd8f07c49e609d558d",
            "placeholder": "​",
            "style": "IPY_MODEL_264b9485d9584364a6b51394082ea435",
            "tabbable": null,
            "tooltip": null,
            "value": " 12/12 [08:22&lt;00:00, 32.49s/it]"
          }
        },
        "d303f19c8789413283b050a37420a7df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e934779c27d4d0b81d2ad455ace5eb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b51930d418ca41b8967a2d0b60332818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "1217400daf664188873e6307268ac028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9198ee802c74d55a83fd1c3643c5fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b43cf9c3a91a42dd8f07c49e609d558d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "264b9485d9584364a6b51394082ea435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "d13194557f9944e099a3284f646c762f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de99e6d41a734e188162e89f2172ee9e",
              "IPY_MODEL_f97b19507e1745abaa6f449e9262db2f",
              "IPY_MODEL_5d5100e4beac447fb27bbe68fe6e41c1"
            ],
            "layout": "IPY_MODEL_5eb93c0f3e2640089568897d6b1e6d57",
            "tabbable": null,
            "tooltip": null
          }
        },
        "de99e6d41a734e188162e89f2172ee9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_afff5dd7ebac46ed86ce4cd12673aa4d",
            "placeholder": "​",
            "style": "IPY_MODEL_354c3f1947154ccb9f9a39ba472ef0e5",
            "tabbable": null,
            "tooltip": null,
            "value": "Batches: 100%"
          }
        },
        "f97b19507e1745abaa6f449e9262db2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b0ca4005dc0b4ab391789f7439ef0e56",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0dc098742ed34e71842d5d90e740ee6f",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "5d5100e4beac447fb27bbe68fe6e41c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_2e38bd8399e24830ab850f612755c0d4",
            "placeholder": "​",
            "style": "IPY_MODEL_d9ccb6dc49ae40919547b20288e8073a",
            "tabbable": null,
            "tooltip": null,
            "value": " 1/1 [00:00&lt;00:00,  4.24it/s]"
          }
        },
        "5eb93c0f3e2640089568897d6b1e6d57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afff5dd7ebac46ed86ce4cd12673aa4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "354c3f1947154ccb9f9a39ba472ef0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "b0ca4005dc0b4ab391789f7439ef0e56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dc098742ed34e71842d5d90e740ee6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e38bd8399e24830ab850f612755c0d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9ccb6dc49ae40919547b20288e8073a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}