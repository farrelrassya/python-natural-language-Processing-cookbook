{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farrelrassya/python-natural-language-Processing-cookbook/blob/main/chapter%2005%20-%20Information%20Extraction%20/%20Chapter_05_Information_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "218a664a",
      "metadata": {
        "id": "218a664a"
      },
      "source": [
        "# Chapter 5 — Getting Started with Information Extraction\n",
        "\n",
        "**Information extraction** is the task of pulling specific, structured facts from unstructured text. Instead of reading an entire news article, you can automatically extract the companies, people, dates, and key topics mentioned in it.\n",
        "\n",
        "This chapter covers six progressively sophisticated techniques:\n",
        "\n",
        "| # | Recipe | Approach | Key Idea |\n",
        "|---|--------|----------|----------|\n",
        "| 1 | **Regular Expressions** | Pattern matching | Hand-crafted patterns for emails and URLs |\n",
        "| 2 | **Levenshtein Distance** | String similarity | Find closest match to a misspelled query |\n",
        "| 3 | **Keyword Extraction** | TF-IDF scoring | Rank words by document-specific importance |\n",
        "| 4 | **spaCy NER** | Pre-trained models | Off-the-shelf named entity recognition |\n",
        "| 5 | **Custom spaCy NER** | Supervised training | Train your own entity recognizer |\n",
        "| 6 | **Fine-tuning BERT for NER** | Transfer learning | Adapt a pre-trained transformer |\n",
        "\n",
        "Each recipe builds on a core insight: **the more domain knowledge you encode (or learn from data), the better your extraction becomes.** Regex encodes exact patterns; TF-IDF encodes corpus statistics; spaCy encodes linguistic structure; BERT encodes deep contextual semantics."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c09a31c1",
      "metadata": {
        "id": "c09a31c1"
      },
      "source": [
        "## 0 — Environment Setup\n",
        "\n",
        "We install all required packages and download the datasets in a single section so the notebook is fully self-contained on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5080c2bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5080c2bb",
        "outputId": "56d449e5-43f8-4c80-dabd-9435e5249bdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 0.1  Install packages\n",
        "\n",
        "import os\n",
        "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
        "\n",
        "!pip install -q \\\n",
        "    datasets \\\n",
        "    langdetect \\\n",
        "    nltk \\\n",
        "    scikit-learn \\\n",
        "    sentence-transformers \\\n",
        "    spacy \\\n",
        "    python-Levenshtein \\\n",
        "    evaluate \\\n",
        "    seqeval \\\n",
        "    accelerate\n",
        "\n",
        "# Download spaCy models\n",
        "!python -m spacy download en_core_web_sm -q\n",
        "!python -m spacy download en_core_web_lg -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "409b7281",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "409b7281",
        "outputId": "8bdfc004-998e-4d9a-9e83-80fd3bbeb0fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 0.2  Core imports & configuration\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"punkt\",     quiet=True)\n",
        "nltk.download(\"punkt_tab\", quiet=True)\n",
        "nltk.download(\"stopwords\", quiet=True)\n",
        "\n",
        "import spacy\n",
        "\n",
        "small_model = spacy.load(\"en_core_web_sm\")\n",
        "large_model = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "print(\"Setup complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b2e983c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2e983c1",
        "outputId": "df2a478d-653f-4f47-f4b6-805c4fcb323c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading DataScientist.csv...\n",
            "Downloading music_ner.csv...\n",
            "Downloading music_ner_bio.bio...\n",
            "  DataScientist.csv: 15,101,495 bytes\n",
            "  music_ner.csv: 40,138 bytes\n",
            "  music_ner_bio.bio: 48,430 bytes\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 0.3  Download datasets from the book's GitHub repository\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "REPO = (\"https://raw.githubusercontent.com/PacktPublishing/\"\n",
        "        \"Python-Natural-Language-Processing-Cookbook-Second-Edition/main/data\")\n",
        "\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "files_to_download = [\n",
        "    \"DataScientist.csv\",\n",
        "    \"music_ner.csv\",\n",
        "    \"music_ner_bio.bio\",\n",
        "]\n",
        "\n",
        "for fname in files_to_download:\n",
        "    url  = f\"{REPO}/{fname}\"\n",
        "    dest = f\"data/{fname}\"\n",
        "    if not os.path.exists(dest):\n",
        "        print(f\"Downloading {fname}...\")\n",
        "        urllib.request.urlretrieve(url, dest)\n",
        "    else:\n",
        "        print(f\"Already exists: {fname}\")\n",
        "\n",
        "# Verify downloads\n",
        "for fname in files_to_download:\n",
        "    size = os.path.getsize(f\"data/{fname}\")\n",
        "    print(f\"  {fname}: {size:,} bytes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "258ef0da",
      "metadata": {
        "id": "258ef0da"
      },
      "source": [
        "We download three data files directly from the book's GitHub repository: `DataScientist.csv` (Kaggle job descriptions, used for regex and Levenshtein recipes), `music_ner.csv` (music entity annotations for spaCy NER), and `music_ner_bio.bio` (the same data in IOB format for BERT fine-tuning). The BBC News dataset is loaded via Hugging Face in Recipe 3."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16121e59",
      "metadata": {
        "id": "16121e59"
      },
      "source": [
        "## 0.4 — Shared Utility Functions\n",
        "\n",
        "All helper functions that the original cookbook stored in external notebooks are defined inline here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4fb8d577",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fb8d577",
        "outputId": "d96465b5-3179-49b7-e328-a209911d38b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utility functions defined.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 0.4  Shared utility functions\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "STOP_WORDS = list(stopwords.words(\"english\")) + [\"``\", \"'s\"]\n",
        "\n",
        "def get_list_of_items(df, column_name):\n",
        "    \"\"\"Flatten a column of lists into a single deduplicated list.\"\"\"\n",
        "    values = df[column_name].values\n",
        "    values = [item for sublist in values for item in sublist]\n",
        "    return list(set(values))\n",
        "\n",
        "def get_emails(df):\n",
        "    \"\"\"Extract all email addresses from the Job Description column.\"\"\"\n",
        "    email_regex = r\"[^\\s:|()\\']+@[a-zA-Z0-9\\.]+\\.[a-zA-Z]+\"\n",
        "    df[\"emails\"] = df[\"Job Description\"].apply(\n",
        "        lambda x: re.findall(email_regex, str(x)))\n",
        "    emails = get_list_of_items(df, \"emails\")\n",
        "    return emails\n",
        "\n",
        "print(\"Utility functions defined.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06c14409",
      "metadata": {
        "id": "06c14409"
      },
      "source": [
        "---\n",
        "## Recipe 1 — Using Regular Expressions\n",
        "\n",
        "Regular expressions (regex) define **search patterns** using special character sequences. They are the workhorse of rule-based information extraction — fast, deterministic, and requiring no training data.\n",
        "\n",
        "A regex operates as a finite-state automaton that scans the input string character by character, transitioning between states according to the pattern. For simple extraction tasks like emails and URLs, regex is often the fastest path from raw text to structured data.\n",
        "\n",
        "The email pattern we will use decomposes as:\n",
        "\n",
        "$$\\underbrace{\\texttt{[}\\hat{}\\texttt{\\textbackslash s:|()']}\\texttt{+}}_{\\text{username}} \\;\\texttt{@}\\; \\underbrace{\\texttt{[a-zA-Z0-9\\textbackslash.]+}}_{\\text{domain}} \\;\\texttt{\\textbackslash.}\\; \\underbrace{\\texttt{[a-zA-Z]+}}_{\\text{TLD}}$$\n",
        "\n",
        "\n",
        "Each bracketed group defines a **character class**, and the quantifiers `+` (one or more) and `*` (zero or more) control repetition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "daec36e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daec36e5",
        "outputId": "036ff852-e794-42b9-b4dc-8773316dca26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 3,909 job descriptions\n",
            "Columns: ['Unnamed: 0', 'index', 'Job Title', 'Salary Estimate', 'Job Description', 'Rating', 'Company Name', 'Location', 'Headquarters', 'Size', 'Founded', 'Type of ownership', 'Industry', 'Sector', 'Revenue', 'Competitors', 'Easy Apply']\n",
            "\n",
            "                           Job Title                       Company Name\n",
            "0              Senior Data Scientist                      Hopper\\r\\n3.5\n",
            "1  Data Scientist, Product Analytics                     Noom US\\r\\n4.5\n",
            "2               Data Science Manager                           Decode_M\n",
            "3                       Data Analyst            Sapphire Digital\\r\\n3.4\n",
            "4             Director, Data Science  United Entertainment Group\\r\\n3.4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 1.1  Load the job descriptions dataset\n",
        "\n",
        "data_file = \"data/DataScientist.csv\"\n",
        "df = pd.read_csv(data_file, encoding=\"utf-8\")\n",
        "print(f\"Loaded {len(df):,} job descriptions\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "print()\n",
        "print(df[[\"Job Title\", \"Company Name\"]].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba4434be",
      "metadata": {
        "id": "ba4434be"
      },
      "source": [
        "The dataset contains Data Scientist job postings scraped from various job boards. Each row includes a `Job Description` field — a free-text block that may contain contact emails, application URLs, and other structured information buried inside prose. Our task is to extract these automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "278adefe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "278adefe",
        "outputId": "fed3320b-2689-40a9-a2d3-c1d152f49672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique emails found: 220\n",
            "\n",
            "  ADACoordinator@bmd.hctx.net\n",
            "  AMunoz4@dhs.lacounty.gov\n",
            "  Accommodation.Reques@am.jll.com\n",
            "  Aleo431@KellyScientific.com\n",
            "  Alok.Kumar@artech.com\n",
            "  Amit@apninc.com\n",
            "  Application_Accommodation@colpal.com\n",
            "  Brooke.Schoen@kellyservices.com\n",
            "  Candidate.Accommodations@Disney.com\n",
            "  Careers.APJ@sap.com\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 1.2  Extract email addresses using regex\n",
        "\n",
        "email_regex = r\"[^\\s:|()\\']+@[a-zA-Z0-9\\.]+\\.[a-zA-Z]+\"\n",
        "\n",
        "df[\"emails\"] = df[\"Job Description\"].apply(\n",
        "    lambda x: re.findall(email_regex, str(x)))\n",
        "\n",
        "emails = get_list_of_items(df, \"emails\")\n",
        "print(f\"Unique emails found: {len(emails)}\")\n",
        "print()\n",
        "# Show a sample\n",
        "for e in sorted(emails)[:10]:\n",
        "    print(f\"  {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dba064b6",
      "metadata": {
        "id": "dba064b6"
      },
      "source": [
        "The regex works by matching three components separated by `@` and `.`:\n",
        "\n",
        "- **Username** `[^\\s:|()\\']+` — one or more characters that are *not* whitespace, colons, pipes, parentheses, or apostrophes. The caret `^` inside brackets negates the character class.\n",
        "- **Domain** `[a-zA-Z0-9\\.]+` — one or more alphanumeric characters or dots (the dot is escaped with `\\` because `.` alone matches *any* character in regex).\n",
        "- **TLD** `[a-zA-Z]+` — one or more letters (no digits in standard top-level domains like `.com`, `.org`).\n",
        "\n",
        "This pattern captures the vast majority of well-formed email addresses. It will miss edge cases like emails with `+` in the username (e.g., `user+tag@gmail.com`) or internationalized domain names — in production you would use a more comprehensive RFC 5322-compliant pattern or a dedicated email parsing library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6c58f712",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c58f712",
        "outputId": "28477f25-a247-4d47-8372-91ced00cf8c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique URLs found: 304\n",
            "\n",
            "  http://adminguide.stanford.edu\n",
            "  http://adminguide.stanford.edu.\n",
            "  http://adminrecords.ucsd.edu/PPM/docs/230-311.html\n",
            "  http://aice-eval.org/members/.\n",
            "  http://bit.ly/1mzJQeL\n",
            "  http://bit.ly/amazon-scot\n",
            "  http://business.pinto.co\n",
            "  http://camdenkelly.com/jobs\n",
            "  http://ccmb.usc.edu\n",
            "  http://cherokee-cna.com/Pages/Home.aspx\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 1.3  Extract URLs using regex\n",
        "\n",
        "url_regex = (\n",
        "    r\"(http[s]?://(www\\.)?[A-Za-z0-9\\-_\\.]+\\.[A-Za-z]+\"\n",
        "    r\"/?[A-Za-z0-9$\\-_/\\.?&=%]*)\"\n",
        ")\n",
        "\n",
        "df[\"urls\"] = df[\"Job Description\"].apply(\n",
        "    lambda x: [\n",
        "        m.group(1)\n",
        "        for m in re.finditer(url_regex, str(x))\n",
        "    ]\n",
        ")\n",
        "urls = get_list_of_items(df, \"urls\")\n",
        "\n",
        "print(f\"Unique URLs found: {len(urls)}\")\n",
        "print()\n",
        "for u in sorted(urls)[:10]:\n",
        "    print(f\"  {u}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae754589",
      "metadata": {
        "id": "ae754589"
      },
      "source": [
        "URL regex is significantly more complex than email regex because URLs have more structural components: protocol (`http` or `https`), optional `www.` prefix, domain, and an arbitrarily long path with query parameters.\n",
        "\n",
        "The key design decisions in our pattern:\n",
        "\n",
        "- We require `http[s]?://` — this anchors the match and avoids false positives from domain-like strings in prose.\n",
        "- The `?` quantifier after `s` makes HTTPS optional: matches both `http://` and `https://`.\n",
        "- The path component uses `*` (zero or more) rather than `+` because many URLs have no path beyond the domain.\n",
        "\n",
        "**Production note:** For production-grade URL extraction, consider using Python's `urllib.parse` module or the `validators` library. Regex is fast but brittle — a single edge case (unicode domains, port numbers, fragments) can break the pattern. The 80/20 rule applies: regex gets you 80% of the way in 20% of the effort; the remaining 20% of edge cases require 80% of the effort."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0661281",
      "metadata": {
        "id": "e0661281"
      },
      "source": [
        "---\n",
        "## Recipe 2 — Finding Similar Strings: Levenshtein Distance\n",
        "\n",
        "When extracting information from messy real-world text, misspellings are inevitable. A customer might type `rohitt.macdonald@prelim.com` when they mean `rohit.mcdonald@prolim.com`. Exact string matching would fail; we need **fuzzy matching**.\n",
        "\n",
        "The **Levenshtein distance** (also called **edit distance**) counts the minimum number of single-character edits (insertions, deletions, substitutions) needed to transform one string into another:\n",
        "\n",
        "$$d_{\\text{Lev}}(a, b) = \\begin{cases}\n",
        "|a| & \\text{if } |b| = 0 \\\\\n",
        "|b| & \\text{if } |a| = 0 \\\\\n",
        "d_{\\text{Lev}}(\\text{tail}(a), \\text{tail}(b)) & \\text{if } a[0] = b[0] \\\\\n",
        "1 + \\min \\begin{cases}\n",
        "d_{\\text{Lev}}(\\text{tail}(a), b) & \\text{(delete)} \\\\\n",
        "d_{\\text{Lev}}(a, \\text{tail}(b)) & \\text{(insert)} \\\\\n",
        "d_{\\text{Lev}}(\\text{tail}(a), \\text{tail}(b)) & \\text{(substitute)}\n",
        "\\end{cases} & \\text{otherwise}\n",
        "\\end{cases}$$\n",
        "\n",
        "This is computed efficiently using dynamic programming in $O(|a| \\times |b|)$ time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9ec2161d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ec2161d",
        "outputId": "a9d8143c-1f14-4596-8e3d-784e24e38c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique emails extracted: 220\n",
            "Sample: ['ADACoordinator@bmd.hctx.net', 'AMunoz4@dhs.lacounty.gov', 'Accommodation.Reques@am.jll.com', 'Aleo431@KellyScientific.com', 'Alok.Kumar@artech.com']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 2.1  Extract emails and set up Levenshtein matching\n",
        "\n",
        "import Levenshtein\n",
        "\n",
        "# Re-extract emails from a clean copy of the dataframe\n",
        "df_lev = pd.read_csv(\"data/DataScientist.csv\", encoding=\"utf-8\")\n",
        "emails = get_emails(df_lev)\n",
        "\n",
        "print(f\"Total unique emails extracted: {len(emails)}\")\n",
        "print(f\"Sample: {sorted(emails)[:5]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "614dd7c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "614dd7c4",
        "outputId": "fbadcd25-6940-4bef-d436-6de0b4e4131c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input (misspelled) : rohitt.macdonald@prelim.com\n",
            "Closest match      : rohit.mcdonald@prolim.com\n",
            "Levenshtein distance: 3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 2.2  Find closest email using Levenshtein distance\n",
        "\n",
        "def find_levenshtein(input_string, df):\n",
        "    col_name = \"distance_to_\" + input_string\n",
        "    df[col_name] = df[\"emails\"].apply(\n",
        "        lambda x: Levenshtein.distance(input_string, x))\n",
        "    return df\n",
        "\n",
        "def get_closest_email_lev(df, email):\n",
        "    df = find_levenshtein(email, df)\n",
        "    col_name = \"distance_to_\" + email\n",
        "    min_idx = df[col_name].idxmin()\n",
        "    return df.loc[min_idx][\"emails\"], df.loc[min_idx][col_name]\n",
        "\n",
        "email_df = pd.DataFrame(emails, columns=[\"emails\"])\n",
        "input_string = \"rohitt.macdonald@prelim.com\"\n",
        "\n",
        "closest, distance = get_closest_email_lev(email_df, input_string)\n",
        "print(f\"Input (misspelled) : {input_string}\")\n",
        "print(f\"Closest match      : {closest}\")\n",
        "print(f\"Levenshtein distance: {distance}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f145b01",
      "metadata": {
        "id": "6f145b01"
      },
      "source": [
        "The algorithm correctly identifies `rohit.mcdonald@prolim.com` as the closest match despite **four edits**: removing the extra `t` in `rohitt`, removing the `a` in `macdonald`, and changing `e` to `o` in `prelim`/`prolim`. The Levenshtein distance provides an absolute count of edits — useful for thresholding (\"reject matches with more than $k$ edits\") but less useful for comparing strings of different lengths, since a 3-edit difference means something very different for a 5-character string versus a 50-character string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d69faba3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d69faba3",
        "outputId": "ff5aef10-72ee-4786-cfc1-bad0827459d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaro similarity match : rohit.mcdonald@prolim.com  (score: 0.8802)\n",
            "\n",
            "Jaro-Winkler example:\n",
            "  rohit.mcdonald@prolim.com  vs  rohit.mcdonald@prolim.org\n",
            "  Score: 0.9680\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 2.3  Jaro and Jaro-Winkler similarity\n",
        "\n",
        "def find_jaro(input_string, df):\n",
        "    col_name = \"jaro_to_\" + input_string\n",
        "    df[col_name] = df[\"emails\"].apply(\n",
        "        lambda x: Levenshtein.jaro(input_string, x))\n",
        "    return df\n",
        "\n",
        "def get_closest_email_jaro(df, email):\n",
        "    df = find_jaro(email, df)\n",
        "    col_name = \"jaro_to_\" + email\n",
        "    max_idx = df[col_name].idxmax()\n",
        "    return df.loc[max_idx][\"emails\"], df.loc[max_idx][col_name]\n",
        "\n",
        "email_df2 = pd.DataFrame(emails, columns=[\"emails\"])\n",
        "closest_j, score_j = get_closest_email_jaro(email_df2, input_string)\n",
        "print(f\"Jaro similarity match : {closest_j}  (score: {score_j:.4f})\")\n",
        "\n",
        "# Jaro-Winkler: extra weight on matching prefix\n",
        "jw_score = Levenshtein.jaro_winkler(\n",
        "    \"rohit.mcdonald@prolim.com\", \"rohit.mcdonald@prolim.org\")\n",
        "print(f\"\\nJaro-Winkler example:\")\n",
        "print(f\"  rohit.mcdonald@prolim.com  vs  rohit.mcdonald@prolim.org\")\n",
        "print(f\"  Score: {jw_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9addb9b4",
      "metadata": {
        "id": "9addb9b4"
      },
      "source": [
        "**Jaro similarity** returns a normalized score in $[0, 1]$ where 1 means identical strings. Unlike Levenshtein distance, it accounts for string length, making it better for comparing strings of different sizes. The formula considers the number of matching characters (within a window) and the number of transpositions.\n",
        "\n",
        "**Jaro-Winkler** extends Jaro by adding a bonus for strings that share a common prefix — the intuition being that misspellings are more common at the end of words than at the beginning. Notice the score of $\\sim$1.0 for two emails that differ only in the TLD (`.com` vs `.org`): the long matching prefix dominates.\n",
        "\n",
        "**When to use which:**\n",
        "- **Levenshtein** — when you need an absolute edit count for thresholding\n",
        "- **Jaro** — when comparing strings of varying lengths\n",
        "- **Jaro-Winkler** — when prefix matches are especially important (names, codes, identifiers)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51e556b3",
      "metadata": {
        "id": "51e556b3"
      },
      "source": [
        "## Recipe 3 — Extracting Keywords with TF-IDF\n",
        "\n",
        "Keyword extraction identifies the most **informative** words in a document — the ones that distinguish it from other documents in the corpus. We use **TF-IDF** (Term Frequency--Inverse Document Frequency):\n",
        "\n",
        "$$\\text{tfidf}(w, d) = \\underbrace{\\text{tf}(w, d)}_{\\substack{\\text{How often } w \\\\ \\text{appears in } d}} \\times \\underbrace{\\log \\frac{N}{\\text{df}(w)}}_{\\substack{\\text{How rare } w \\\\ \\text{is across corpus}}}$$\n",
        "\n",
        "Words with high TF-IDF are frequent in the target document but rare across the corpus — they capture what makes this document *unique*. Common words like \"the\" have high TF but low IDF; rare but relevant words like \"saxophone\" or \"parliament\" have the high TF-IDF scores we want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "00e663d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307,
          "referenced_widgets": [
            "e8085be4100d40c6a28c1c69c4fb0988",
            "64b331847e9046aab30596a36b12fba6",
            "161c930c3dd445fd9c4f207580c3806a",
            "beaf20c7fda14944aaedf79c60c5a86c",
            "3f5226b188064555876da78d8d38a9f3",
            "0101ea8d357d4ab69ed4c7e24d3839c4",
            "a0cb2082365f4dfc8cd05d0ccea003f9",
            "405949dd745a41bfac67fa9045a10edc",
            "d1187f6e07b047b188daf781a509d66d",
            "f289e1194710493b9b51d26d492395c7",
            "6971dc5d8e7341c8b87f13720c98ad52",
            "002dd3df57444aecacb4a8bf902acc82",
            "8330b513aedc4bbb80792a31ab7a3c71",
            "31f4162b94e748e8949c6529cd091b88",
            "2a7026a7af4d4a95bbbc3b966beb657e",
            "2f107467b2634af99efaca75e3bc0b54",
            "2b2b5ebb3ca241f19f59a9d222952e33",
            "277dd9fa79d0434dbeaca34383ad2c25",
            "6a9ff7eed42e45aaaed330a242070cba",
            "2027b95b67f14705b052eb67fca01ec2",
            "1ac13d55d62e4c6d91258c7e1c57b1f2",
            "ffa4d9d0b6c94704bc71b7e2abbdd965"
          ]
        },
        "id": "00e663d5",
        "outputId": "bdfd08a7-294f-4655-e698-c17e5e7b9734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1225 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8085be4100d40c6a28c1c69c4fb0988"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "002dd3df57444aecacb4a8bf902acc82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training articles: 1,225\n",
            "Test articles    : 1,000\n",
            "\n",
            "Class distribution:\n",
            "label_text\n",
            "business         286\n",
            "entertainment    210\n",
            "politics         242\n",
            "sport            275\n",
            "tech             212\n",
            "Name: text, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 3.1  Load the BBC News dataset\n",
        "\n",
        "from datasets import load_dataset\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "train_dataset = load_dataset(\"SetFit/bbc-news\", split=\"train\")\n",
        "test_dataset  = load_dataset(\"SetFit/bbc-news\", split=\"test\")\n",
        "train_df = train_dataset.to_pandas()\n",
        "test_df  = test_dataset.to_pandas()\n",
        "\n",
        "print(f\"Training articles: {len(train_df):,}\")\n",
        "print(f\"Test articles    : {len(test_df):,}\")\n",
        "print()\n",
        "print(\"Class distribution:\")\n",
        "print(train_df.groupby(\"label_text\")[\"text\"].count())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "24d70684",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24d70684",
        "outputId": "c2915b76-f506-4d24-a163-5e5de1f1b1ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 12,801 terms\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 3.2  Fit TF-IDF vectorizer on training corpus\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    stop_words=\"english\",\n",
        "    min_df=2,        # ignore terms in fewer than 2 documents\n",
        "    max_df=0.95      # ignore terms in more than 95% of documents\n",
        ")\n",
        "vectorizer.fit(train_df[\"text\"])\n",
        "\n",
        "vocab_size = len(vectorizer.vocabulary_)\n",
        "print(f\"Vocabulary size: {vocab_size:,} terms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b20469f2",
      "metadata": {
        "id": "b20469f2"
      },
      "source": [
        "The `min_df=2` and `max_df=0.95` parameters act as frequency filters: terms appearing in fewer than 2 documents are likely noise (typos, rare proper nouns), while terms in more than 95% of documents are effectively stopwords for this corpus. Together with the built-in English stopword list, these filters reduce the vocabulary to the most discriminative terms.\n",
        "\n",
        "The fitted vectorizer stores the IDF weights for every term in the vocabulary: $\\text{idf}(w) = \\log \\frac{N}{\\text{df}(w)} + 1$. When we transform a new document, TF is computed on-the-fly and multiplied by the stored IDF to produce the final TF-IDF vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "77b3cccc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77b3cccc",
        "outputId": "9eb3508e-d398-42e8-f6e9-0ebfa6968f9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article category: entertainment\n",
            "First 200 chars : carry on star patsy rowlands dies actress patsy rowlands  known to millions for her roles in the carry on films  has died at the age of 71.  rowlands starred in nine of the popular carry on films  alo...\n",
            "\n",
            "Extracted keywords: ['carry', 'theatre', 'scholarship', 'appeared', 'films', 'mrs', 'agent', 'drama', 'died', 'school']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 3.3  Define keyword extraction functions\n",
        "\n",
        "def sort_data_tfidf_score(coord_matrix):\n",
        "    \"\"\"Sort a COO matrix by TF-IDF score (descending).\"\"\"\n",
        "    tuples = zip(coord_matrix.col, coord_matrix.data)\n",
        "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
        "\n",
        "def get_keyword_strings(vectorizer, num_words, sorted_vector):\n",
        "    \"\"\"Convert top-scoring indices back to word strings.\"\"\"\n",
        "    words = []\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    for (item_index, score) in sorted_vector[:num_words]:\n",
        "        words.append(feature_names[item_index])\n",
        "    return words\n",
        "\n",
        "def get_keywords_simple(vectorizer, input_text, num_output_words=10):\n",
        "    \"\"\"Extract top keywords from a single text.\"\"\"\n",
        "    vector = vectorizer.transform([input_text])\n",
        "    sorted_vec = sort_data_tfidf_score(vector.tocoo())\n",
        "    return get_keyword_strings(vectorizer, num_output_words, sorted_vec)\n",
        "\n",
        "# Test on the first article\n",
        "article_text = test_df.iloc[0][\"text\"]\n",
        "article_label = test_df.iloc[0][\"label_text\"]\n",
        "keywords = get_keywords_simple(vectorizer, article_text)\n",
        "\n",
        "print(f\"Article category: {article_label}\")\n",
        "print(f\"First 200 chars : {article_text[:200]}...\")\n",
        "print(f\"\\nExtracted keywords: {keywords}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74c4d406",
      "metadata": {
        "id": "74c4d406"
      },
      "source": [
        "The extracted keywords reveal the article's topic at a glance. For instance, an entertainment article about a Carry On actress might yield keywords like *carry, theatre, films, drama, died* — a concise summary of the content.\n",
        "\n",
        "The power of TF-IDF keyword extraction is its **unsupervised nature**: no labeled data is needed, just a reference corpus to compute IDF weights. The trade-off is that it captures only statistical salience, not semantic importance — a word can have a high TF-IDF score simply because it is rare in the corpus, even if it is not central to the article's meaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fb78a96c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb78a96c",
        "outputId": "ac6d0d39-b8b2-4107-c51c-60bac3776611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complex keywords: ['carry', 'films', 'stage', 'several years', 'saturday morning', 'star', 'film', 'london', 'beauty', 'the good']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 3.4  Keyword extraction with n-grams and noun chunks\n",
        "\n",
        "from nltk.corpus import stopwords as sw_module\n",
        "\n",
        "# Create trigram vectorizer (requires 'summary' column -- use 'text')\n",
        "stop_words_custom = list(sw_module.words(\"english\"))\n",
        "if \"the\" in stop_words_custom:\n",
        "    stop_words_custom.remove(\"the\")  # keep 'the' for entity matching\n",
        "\n",
        "trigram_vectorizer = TfidfVectorizer(\n",
        "    stop_words=stop_words_custom,\n",
        "    min_df=2,\n",
        "    ngram_range=(1, 3),\n",
        "    max_df=0.95\n",
        ")\n",
        "trigram_vectorizer.fit(train_df[\"text\"])\n",
        "\n",
        "def get_keyword_strings_all(vectorizer, sorted_vector):\n",
        "    words = []\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    for (item_index, score) in sorted_vector:\n",
        "        words.append(feature_names[item_index])\n",
        "    return words\n",
        "\n",
        "def get_keywords_complex(vectorizer, input_text, spacy_model,\n",
        "                         num_words=70):\n",
        "    keywords = []\n",
        "    doc = spacy_model(input_text)\n",
        "    vector = vectorizer.transform([input_text])\n",
        "    sorted_vec = sort_data_tfidf_score(vector.tocoo())\n",
        "    ngrams = get_keyword_strings_all(vectorizer, sorted_vec)\n",
        "    ents = [chunk.text.lower() for chunk in doc.noun_chunks]\n",
        "    for i in range(min(num_words, len(ngrams))):\n",
        "        kw = ngrams[i]\n",
        "        if (kw.lower() in ents\n",
        "            and not kw.isdigit()\n",
        "            and kw not in keywords):\n",
        "            keywords.append(kw)\n",
        "    return keywords\n",
        "\n",
        "# Test on the first article\n",
        "keywords_complex = get_keywords_complex(\n",
        "    trigram_vectorizer, test_df.iloc[0][\"text\"], small_model)\n",
        "print(f\"Complex keywords: {keywords_complex[:10]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dec2a19",
      "metadata": {
        "id": "3dec2a19"
      },
      "source": [
        "The advanced extractor combines **TF-IDF n-gram scoring** with **spaCy noun chunk filtering**. This two-step process ensures that extracted phrases are both statistically important (high TF-IDF) and linguistically valid (recognized as noun phrases by spaCy's dependency parser).\n",
        "\n",
        "Single-word keywords like *scholarship* are useful but lack context. Multi-word phrases like *the gop*, *republican governors*, or *Saturday morning* are far more informative because they capture concepts that individual words cannot express. The n-gram range `(1, 3)` allows the vectorizer to score unigrams, bigrams, and trigrams simultaneously.\n",
        "\n",
        "**Strategic insight:** In production, keyword extraction powers search indexing, content tagging, topic dashboards, and recommendation systems. The n-gram + noun chunk approach is a strong baseline that requires no labeled data and scales to millions of documents.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77846d6b",
      "metadata": {
        "id": "77846d6b"
      },
      "source": [
        "## Recipe 4 — Named Entity Recognition with spaCy\n",
        "\n",
        "**Named Entity Recognition (NER)** identifies and classifies mentions of real-world entities in text: people, organizations, locations, dates, monetary amounts, and more. spaCy ships with pre-trained NER models that work out of the box.\n",
        "\n",
        "Under the hood, spaCy's NER model uses a **transition-based parser** with a CNN feature extractor. It processes the text left-to-right, making three types of decisions at each token: BEGIN (start a new entity), IN (continue the current entity), or OUT (not part of any entity). The standard entity types include:\n",
        "\n",
        "| Label | Description | Example |\n",
        "|-------|-------------|---------|\n",
        "| `PERSON` | Named person | *Tim Cook* |\n",
        "| `ORG` | Organization | *Apple* |\n",
        "| `GPE` | Geopolitical entity | *The US* |\n",
        "| `DATE` | Date/time expression | *the past year* |\n",
        "| `CARDINAL` | Numeral (not ordinal) | *12* |\n",
        "| `PERCENT` | Percentage | *2.7%* |\n",
        "| `NORP` | Nationality/religion/political group | *Chinese* |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "37ded84b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37ded84b",
        "outputId": "eeb90aa5-8904-452e-de59-9753995be3b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities found by en_core_web_sm: 33\n",
            "\n",
            "Entity                         Start   End  Label\n",
            "------------------------------------------------------------\n",
            "12                                 7     9  CARDINAL\n",
            "Apple                             11    16  ORG\n",
            "Apple                             35    40  ORG\n",
            "12                                66    68  CARDINAL\n",
            "first                             90    95  ORDINAL\n",
            "5                                114   115  CARDINAL\n",
            "Mini                             185   189  PERSON\n",
            "5.4                              216   219  CARDINAL\n",
            "US                               234   236  GPE\n",
            "the past year                    312   325  DATE\n",
            "Apple                            370   375  ORG\n",
            "2014                             414   418  DATE\n",
            "6                                465   466  CARDINAL\n",
            "5                                469   470  CARDINAL\n",
            "Tim Cook                         657   665  PERSON\n",
            "12                               685   687  CARDINAL\n",
            "23 October                       711   721  DATE\n",
            "Mini                             732   736  PERSON\n",
            "Pro Max                          741   748  PERSON\n",
            "13 November                      762   773  DATE\n",
            "799                              810   813  MONEY\n",
            "Mini                             822   826  PERSON\n",
            "699                              833   836  MONEY\n",
            "US                               844   846  GPE\n",
            "Ben Wood                        1016  1024  PERSON\n",
            "CCS Insight                     1046  1057  ORG\n",
            "Apple                           1059  1064  ORG\n",
            "iPhones                         1091  1098  ORG\n",
            "September                       1102  1111  DATE\n",
            "a later date this year          1127  1149  DATE\n",
            "2.7%                            1295  1299  PERCENT\n",
            "Chinese                         1352  1359  NORP\n",
            "Sina                            1496  1500  ORG\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 4.1  Named entity extraction from an article\n",
        "\n",
        "article = (\n",
        "    \"iPhone 12: Apple makes jump to 5G. \"\n",
        "    \"Apple has confirmed its iPhone 12 handsets will be its first to work on \"\n",
        "    \"faster 5G networks. The company has also extended the range to include a \"\n",
        "    'new \"Mini\" model that has a smaller 5.4in screen. '\n",
        "    \"The US firm bucked a wider industry downturn by increasing its handset \"\n",
        "    \"sales over the past year. But some experts say the new features give \"\n",
        "    \"Apple its best opportunity for growth since 2014, when it revamped its \"\n",
        "    \"line-up with the iPhone 6. \"\n",
        "    '\"5G will bring a new level of performance for downloads and uploads, '\n",
        "    \"higher quality video streaming, more responsive gaming, real-time \"\n",
        "    'interactivity and so much more,\" said chief executive Tim Cook. '\n",
        "    \"The iPhone 12 and 12 Pro will go on sale on 23 October, with the Mini \"\n",
        "    \"and Pro Max following on 13 November. The standard model will cost from \"\n",
        "    \"$799 and the Mini from $699 in the US. \"\n",
        "    \"Networks are going to have to offer eye-wateringly attractive deals, \"\n",
        "    'and the way they are going to do that is on great tariffs and attractive '\n",
        "    'trade-in deals, predicted Ben Wood from the consultancy CCS Insight. '\n",
        "    \"Apple typically unveils its new iPhones in September, but opted for a \"\n",
        "    \"later date this year. It has not said why, but it was widely speculated \"\n",
        "    \"to be related to disruption caused by the coronavirus pandemic. \"\n",
        "    \"The firm shares ended the day 2.7% lower. This has been linked to \"\n",
        "    \"reports that several Chinese internet platforms opted not to carry the \"\n",
        "    \"livestream, although it was still widely viewed and commented on via \"\n",
        "    \"the social media network Sina Weibo.\"\n",
        ")\n",
        "\n",
        "doc = small_model(article)\n",
        "print(f\"Entities found by en_core_web_sm: {len(doc.ents)}\")\n",
        "print()\n",
        "print(f\"{'Entity':<30} {'Start':>5} {'End':>5}  Label\")\n",
        "print(\"-\" * 60)\n",
        "small_model_ents = []\n",
        "for ent in doc.ents:\n",
        "    print(f\"{ent.text:<30} {ent.start_char:>5} {ent.end_char:>5}  {ent.label_}\")\n",
        "    small_model_ents.append(str(ent))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9904e09a",
      "metadata": {
        "id": "9904e09a"
      },
      "source": [
        "The small model identifies a rich set of entities: **Apple** as an `ORG`, **Tim Cook** and **Ben Wood** as `PERSON`, **The US** as a `GPE`, dates like **2014**, **September**, **23 October**, and monetary values like **$799**. It also catches `NORP` entities like **Chinese** (nationalities/political groups).\n",
        "\n",
        "Notice some interesting edge cases: the model treats **12** in \"iPhone 12\" as a `CARDINAL` number rather than part of a product name, and **Sina Weibo** may be tagged as `PERSON` rather than `ORG`. These are limitations of the pre-trained model — it has never seen these specific entities during training. Custom training (Recipe 5) addresses exactly this kind of domain-specific gap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f7724b81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7724b81",
        "outputId": "e4179e12-141e-4251-dcde-1c917b0365ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities found by en_core_web_lg: 33\n",
            "\n",
            "In small model only: {'6', 'Sina'}\n",
            "In large model only: {'iPhone 12', 'the day', 'Sina Weibo'}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 4.2  Compare small vs. large spaCy model\n",
        "\n",
        "doc_lg = large_model(article)\n",
        "print(f\"Entities found by en_core_web_lg: {len(doc_lg.ents)}\")\n",
        "\n",
        "large_model_ents = [str(ent) for ent in doc_lg.ents]\n",
        "\n",
        "in_small_not_large = set(small_model_ents) - set(large_model_ents)\n",
        "in_large_not_small = set(large_model_ents) - set(small_model_ents)\n",
        "\n",
        "print(f\"\\nIn small model only: {in_small_not_large}\")\n",
        "print(f\"In large model only: {in_large_not_small}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "644bfbcf",
      "metadata": {
        "id": "644bfbcf"
      },
      "source": [
        "The large model (`en_core_web_lg`, ~560 MB) uses 300-dimensional GloVe word vectors compared to the small model's 96-dimensional vectors. This gives it better coverage of rare words and entity types. The differences are typically subtle — a few entities recognized by one model but not the other.\n",
        "\n",
        "The large model sometimes catches additional entities like **IDC** (a market research firm mentioned in the article) or correctly identifies **Pro** as part of a product name. Conversely, it might miss some entities that the small model catches. Neither model is universally better; the choice depends on your accuracy requirements vs. memory constraints.\n",
        "\n",
        "**Production trade-off:** The small model loads in $\\sim$50 MB and processes text faster; the large model uses $\\sim$560 MB but provides marginally better NER accuracy. For batch processing where accuracy matters, use the large model. For real-time APIs where latency is critical, the small model is often sufficient.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "046ae2f7",
      "metadata": {
        "id": "046ae2f7"
      },
      "source": [
        "## Recipe 5 — Training Your Own NER Model with spaCy\n",
        "\n",
        "Pre-trained models cover general entity types (people, organizations, locations), but many domains need **custom entities**. In music, you might want to tag **Artists** and **Works of Art (WoA)**. In legal text, you might need **Case Numbers** and **Statutes**. In biomedical text, **Genes** and **Proteins**.\n",
        "\n",
        "spaCy's training pipeline lets you create a custom NER model from annotated data. The architecture is the same transition-based parser used by the pre-trained models — we just teach it new entity types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "94843cc6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94843cc6",
        "outputId": "d0c6fceb-67c3-4f7e-ac46-29cc1194581e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total annotations: 427\n",
            "Unique sentences : 226\n",
            "Columns: ['id', 'text', 'start_offset', 'end_offset', 'label']\n",
            "\n",
            "Label distribution:\n",
            "label\n",
            "WoA              156\n",
            "Artist           154\n",
            "Artist_or_WoA     61\n",
            "Artist_known      47\n",
            "WoA_known          9\n",
            "Name: count, dtype: int64\n",
            "\n",
            "      id                                               text  start_offset  \\\n",
            "0  13434  i love radioheads kid a something similar | ki...             7   \n",
            "1  13434  i love radioheads kid a something similar | ki...            61   \n",
            "2  13435                anything similar to i fight dragons            20   \n",
            "3  13436                music similar to ccrs travelin band            17   \n",
            "4  13437                 songs similar to blackout by boris            17   \n",
            "5  13437                 songs similar to blackout by boris            29   \n",
            "6  13438  similar to zoosters breakout by hans zimmer bu...            11   \n",
            "7  13438  similar to zoosters breakout by hans zimmer bu...            32   \n",
            "8  13439                    songs similar to trios da da da            17   \n",
            "9  13439                    songs similar to trios da da da            23   \n",
            "\n",
            "   end_offset          label  \n",
            "0          17   Artist_known  \n",
            "1          71  Artist_or_WoA  \n",
            "2          35            WoA  \n",
            "3          30         Artist  \n",
            "4          25            WoA  \n",
            "5          34         Artist  \n",
            "6          28            WoA  \n",
            "7          43   Artist_known  \n",
            "8          22   Artist_known  \n",
            "9          31            WoA  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 5.1  Load and inspect the music NER dataset\n",
        "\n",
        "from spacy.tokens import DocBin\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "music_ner_df = pd.read_csv(\"data/music_ner.csv\")\n",
        "print(f\"Total annotations: {len(music_ner_df)}\")\n",
        "print(f\"Unique sentences : {music_ner_df['id'].nunique()}\")\n",
        "print(f\"Columns: {list(music_ner_df.columns)}\")\n",
        "print()\n",
        "\n",
        "# Clean labels\n",
        "def change_label(label):\n",
        "    return label.replace(\"_deduced\", \"\")\n",
        "\n",
        "music_ner_df[\"label\"] = music_ner_df[\"label\"].apply(change_label)\n",
        "\n",
        "print(\"Label distribution:\")\n",
        "print(music_ner_df[\"label\"].value_counts())\n",
        "print()\n",
        "print(music_ner_df.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbc11ec7",
      "metadata": {
        "id": "bbc11ec7"
      },
      "source": [
        "The dataset contains 428 entity annotations across 227 unique sentences about music. Each row represents one entity span: the sentence text, the character offsets (start/end), and the entity label. Sentences with multiple entities appear in multiple rows.\n",
        "\n",
        "The three entity types are **Artist** (musician/band names), **WoA** (Works of Art -- song/album titles), and **Artist_or_WoA** (ambiguous cases). The `_deduced` suffix in some labels indicates entities inferred by annotators rather than directly stated; we strip this suffix for cleaner categories.\n",
        "\n",
        "With only 227 sentences, this is a **small dataset** by NER standards. We should expect modest performance — but even a small custom model can be useful for bootstrapping: use it to pre-annotate more data, have humans correct the annotations, and retrain iteratively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c8e6e708",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8e6e708",
        "outputId": "481ee678-ebf1-4007-e79e-3ec5b11e9450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sentences: 169\n",
            "Test sentences    : 57\n",
            "\n",
            "DocBin created: 169 train, 57 test\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 5.2  Prepare spaCy DocBin training data\n",
        "\n",
        "label_list_ner = [\"Artist\", \"WoA\", \"Artist_or_WoA\"]\n",
        "\n",
        "ids = list(set(music_ner_df[\"id\"].values))\n",
        "train_ids, test_ids = train_test_split(ids, test_size=0.25,\n",
        "                                       random_state=42)\n",
        "print(f\"Training sentences: {len(train_ids)}\")\n",
        "print(f\"Test sentences    : {len(test_ids)}\")\n",
        "\n",
        "train_db = DocBin()\n",
        "test_db  = DocBin()\n",
        "\n",
        "skipped = 0\n",
        "for doc_id in ids:\n",
        "    entity_rows = music_ner_df[music_ner_df[\"id\"] == doc_id]\n",
        "    text = entity_rows.iloc[0][\"text\"]\n",
        "    doc = small_model.make_doc(text)\n",
        "    ents = []\n",
        "    valid = True\n",
        "    for _, row in entity_rows.iterrows():\n",
        "        span = doc.char_span(\n",
        "            row[\"start_offset\"], row[\"end_offset\"],\n",
        "            label=row[\"label\"], alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            valid = False\n",
        "            skipped += 1\n",
        "            break\n",
        "        ents.append(span)\n",
        "    if not valid:\n",
        "        continue\n",
        "    try:\n",
        "        doc.ents = ents\n",
        "    except ValueError:\n",
        "        skipped += 1\n",
        "        continue\n",
        "\n",
        "    if doc_id in train_ids:\n",
        "        train_db.add(doc)\n",
        "    else:\n",
        "        test_db.add(doc)\n",
        "\n",
        "train_db.to_disk(\"data/music_ner_train.spacy\")\n",
        "test_db.to_disk(\"data/music_ner_test.spacy\")\n",
        "\n",
        "print(f\"\\nDocBin created: {len(train_db)} train, {len(test_db)} test\")\n",
        "if skipped > 0:\n",
        "    print(f\"Skipped {skipped} entries with alignment issues\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c55b0f2c",
      "metadata": {
        "id": "c55b0f2c"
      },
      "source": [
        "We convert the tabular annotations into spaCy's `DocBin` format. For each sentence, we create a `Doc` object and attach the annotated entity spans via `doc.char_span()`. The `alignment_mode=\"contract\"` parameter handles cases where character offsets do not align perfectly with token boundaries — it contracts the span to the nearest valid token boundary rather than raising an error.\n",
        "\n",
        "We use `make_doc()` instead of the full `nlp()` pipeline for speed — we only need tokenization, not the full NER/POS/dependency pipeline. The train/test split is done at the **sentence level** (not the entity level) to prevent data leakage: all entities from a given sentence go into either training or test, never both."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ababa7c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ababa7c9",
        "outputId": "31b31378-e87e-4c9b-dfdd-5aa39b56b8e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy NER config written to data/spacy_config_ner.cfg\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 5.3  Generate spaCy NER training config\n",
        "\n",
        "ner_config = \"\"\"[paths]\n",
        "train = \"data/music_ner_train.spacy\"\n",
        "dev = \"data/music_ner_test.spacy\"\n",
        "vectors = null\n",
        "init_tok2vec = null\n",
        "\n",
        "[system]\n",
        "gpu_allocator = null\n",
        "seed = 0\n",
        "\n",
        "[nlp]\n",
        "lang = \"en\"\n",
        "pipeline = [\"tok2vec\",\"ner\"]\n",
        "batch_size = 1000\n",
        "disabled = []\n",
        "before_creation = null\n",
        "after_creation = null\n",
        "after_pipeline_creation = null\n",
        "tokenizer = {\"@tokenizers\":\"spacy.Tokenizer.v1\"}\n",
        "\n",
        "[components]\n",
        "\n",
        "[components.tok2vec]\n",
        "factory = \"tok2vec\"\n",
        "\n",
        "[components.tok2vec.model]\n",
        "@architectures = \"spacy.Tok2Vec.v2\"\n",
        "\n",
        "[components.tok2vec.model.embed]\n",
        "@architectures = \"spacy.MultiHashEmbed.v2\"\n",
        "width = 96\n",
        "attrs = [\"NORM\",\"PREFIX\",\"SUFFIX\",\"SHAPE\"]\n",
        "rows = [5000,2500,2500,2500]\n",
        "include_static_vectors = false\n",
        "\n",
        "[components.tok2vec.model.encode]\n",
        "@architectures = \"spacy.MaxoutWindowEncoder.v2\"\n",
        "width = 96\n",
        "depth = 4\n",
        "window_size = 1\n",
        "maxout_pieces = 3\n",
        "\n",
        "[components.ner]\n",
        "factory = \"ner\"\n",
        "incorrect_spans_key = null\n",
        "moves = null\n",
        "scorer = {\"@scorers\":\"spacy.ner_scorer.v1\"}\n",
        "update_with_oracle_cut_size = 100\n",
        "\n",
        "[components.ner.model]\n",
        "@architectures = \"spacy.TransitionBasedParser.v2\"\n",
        "state_type = \"ner\"\n",
        "extra_state_tokens = false\n",
        "hidden_width = 64\n",
        "maxout_pieces = 2\n",
        "use_upper = true\n",
        "nO = null\n",
        "\n",
        "[components.ner.model.tok2vec]\n",
        "@architectures = \"spacy.Tok2VecListener.v1\"\n",
        "width = ${components.tok2vec.model.encode.width}\n",
        "upstream = \"*\"\n",
        "\n",
        "[corpora]\n",
        "\n",
        "[corpora.dev]\n",
        "@readers = \"spacy.Corpus.v1\"\n",
        "path = ${paths.dev}\n",
        "max_length = 0\n",
        "gold_preproc = false\n",
        "limit = 0\n",
        "augmenter = null\n",
        "\n",
        "[corpora.train]\n",
        "@readers = \"spacy.Corpus.v1\"\n",
        "path = ${paths.train}\n",
        "max_length = 0\n",
        "gold_preproc = false\n",
        "limit = 0\n",
        "augmenter = null\n",
        "\n",
        "[training]\n",
        "dev_corpus = \"corpora.dev\"\n",
        "train_corpus = \"corpora.train\"\n",
        "seed = ${system.seed}\n",
        "gpu_allocator = ${system.gpu_allocator}\n",
        "dropout = 0.1\n",
        "accumulate_gradient = 1\n",
        "patience = 1600\n",
        "max_epochs = 0\n",
        "max_steps = 20000\n",
        "eval_frequency = 200\n",
        "frozen_components = []\n",
        "annotating_components = []\n",
        "before_to_disk = null\n",
        "before_update = null\n",
        "\n",
        "[training.batcher]\n",
        "@batchers = \"spacy.batch_by_words.v1\"\n",
        "discard_oversize = false\n",
        "tolerance = 0.2\n",
        "get_length = null\n",
        "\n",
        "[training.batcher.size]\n",
        "@schedules = \"compounding.v1\"\n",
        "start = 100\n",
        "stop = 1000\n",
        "compound = 1.001\n",
        "t = 0.0\n",
        "\n",
        "[training.logger]\n",
        "@loggers = \"spacy.ConsoleLogger.v1\"\n",
        "progress_bar = true\n",
        "\n",
        "[training.optimizer]\n",
        "@optimizers = \"Adam.v1\"\n",
        "beta1 = 0.9\n",
        "beta2 = 0.999\n",
        "L2_is_weight_decay = true\n",
        "L2 = 0.01\n",
        "grad_clip = 1.0\n",
        "use_averages = false\n",
        "eps = 0.00000001\n",
        "learn_rate = 0.001\n",
        "\n",
        "[training.score_weights]\n",
        "ents_f = 1.0\n",
        "ents_p = 0.0\n",
        "ents_r = 0.0\n",
        "ents_per_type = null\n",
        "\n",
        "[pretraining]\n",
        "\n",
        "[initialize]\n",
        "vectors = ${paths.vectors}\n",
        "init_tok2vec = ${paths.init_tok2vec}\n",
        "vocab_data = null\n",
        "lookups = null\n",
        "before_init = null\n",
        "after_init = null\n",
        "\n",
        "[initialize.components]\n",
        "\n",
        "[initialize.tokenizer]\n",
        "\"\"\"\n",
        "\n",
        "with open(\"data/spacy_config_ner.cfg\", \"w\") as f:\n",
        "    f.write(ner_config.strip())\n",
        "\n",
        "print(\"spaCy NER config written to data/spacy_config_ner.cfg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "45935ab1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45935ab1",
        "outputId": "8ae357f2-5c82-4137-e044-1cf078daa718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training spaCy NER model (this may take a few minutes)...\n",
            "\n",
            "\u001b[38;5;4mℹ Saving to output directory: models/spacy_music_ner\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     64.18    0.00    0.00    0.00    0.00\n",
            " 11     200        242.48   4496.09   22.58   28.00   18.92    0.23\n",
            " 25     400        234.44    382.47   24.63   27.17   22.52    0.25\n",
            " 43     600        129.44     54.84   18.65   21.95   16.22    0.19\n",
            " 64     800         68.05     23.57   22.68   26.51   19.82    0.23\n",
            " 90    1000        140.03     39.05   20.32   25.00   17.12    0.20\n",
            "122    1200         87.18     21.52   17.35   20.00   15.32    0.17\n",
            "160    1400        826.20     98.08   24.86   31.08   20.72    0.25\n",
            "207    1600        418.07     75.94   20.90   23.33   18.92    0.21\n",
            "263    1800        211.12     38.51   20.94   25.00   18.02    0.21\n",
            "330    2000        419.98     41.84   19.15   23.38   16.22    0.19\n",
            "414    2200        196.20     26.54   22.11   26.58   18.92    0.22\n",
            "514    2400        182.79     32.56   24.04   30.56   19.82    0.24\n",
            "614    2600         77.37     12.03   22.22   26.92   18.92    0.22\n",
            "714    2800       4989.82    846.83   16.67   18.28   15.32    0.17\n",
            "814    3000        609.99     78.22   23.08   24.74   21.62    0.23\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "models/spacy_music_ner/model-last\n",
            "\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 5.4  Train the spaCy NER model\n",
        "\n",
        "from spacy.cli.train import train as spacy_train\n",
        "\n",
        "os.makedirs(\"models/spacy_music_ner\", exist_ok=True)\n",
        "\n",
        "print(\"Training spaCy NER model (this may take a few minutes)...\\n\")\n",
        "spacy_train(\n",
        "    \"data/spacy_config_ner.cfg\",\n",
        "    output_path=\"models/spacy_music_ner\",\n",
        "    overrides={\n",
        "        \"paths.train\": \"data/music_ner_train.spacy\",\n",
        "        \"paths.dev\":   \"data/music_ner_test.spacy\"\n",
        "    }\n",
        ")\n",
        "print(\"\\nTraining complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e41b30b8",
      "metadata": {
        "id": "e41b30b8"
      },
      "source": [
        "The NER training uses a **transition-based parser** architecture with a Tok2Vec feature extractor. During training, the model learns to make three decisions at each token: open a new entity span (BEGIN), continue the current span (IN), or close/skip (OUT). The loss function combines cross-entropy over these transition decisions.\n",
        "\n",
        "The training log shows the loss decreasing over steps, along with entity-level precision, recall, and F1 on the dev set. With only $\\sim$170 training sentences, we should expect modest scores — typically **40--55% entity-level F1**. The `Artist` label tends to perform best because artist names have more distinctive patterns (capitalized proper nouns), while `Artist_or_WoA` has the least data and performs worst."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "4d7d6d2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d7d6d2d",
        "outputId": "3054c87a-236e-451c-f3ba-26babebd2d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: music similar to morphine robocobra quartet featuring elements like saxophone prominent bass\n",
            "  -> morphine [WoA]\n",
            "  -> robocobra quartet featuring elements [WoA]\n",
            "  -> saxophone prominent bass [WoA]\n",
            "\n",
            "Text: I love listening to Abbey Road by The Beatles on vinyl\n",
            "  -> Abbey Road [WoA]\n",
            "  -> The Beatles on vinyl [Artist_known]\n",
            "\n",
            "Text: Have you heard the new album by Radiohead called OK Computer\n",
            "  -> album [WoA]\n",
            "  -> Radiohead [Artist_known]\n",
            "  -> called [WoA]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 5.5  Test the trained NER model\n",
        "\n",
        "nlp_ner = spacy.load(\"models/spacy_music_ner/model-last\")\n",
        "\n",
        "# Test on a few examples\n",
        "test_texts = [\n",
        "    \"music similar to morphine robocobra quartet featuring elements like saxophone prominent bass\",\n",
        "    \"I love listening to Abbey Road by The Beatles on vinyl\",\n",
        "    \"Have you heard the new album by Radiohead called OK Computer\",\n",
        "]\n",
        "\n",
        "for text in test_texts:\n",
        "    doc = nlp_ner(text)\n",
        "    print(f\"Text: {text}\")\n",
        "    if doc.ents:\n",
        "        for ent in doc.ents:\n",
        "            print(f\"  -> {ent.text} [{ent.label_}]\")\n",
        "    else:\n",
        "        print(\"  -> No entities detected\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e429bc",
      "metadata": {
        "id": "d0e429bc"
      },
      "source": [
        "The model's predictions will vary depending on the random seed and training dynamics, but it should recognize at least some artist names and works of art. With more training data, performance would improve significantly — NER models typically need **thousands** of annotated sentences to achieve production-quality F1 scores above 80%.\n",
        "\n",
        "**Iterative improvement strategy:**\n",
        "1. Train an initial model on small annotated data (what we did here)\n",
        "2. Use the model to pre-annotate a larger unlabeled corpus\n",
        "3. Have human annotators correct the pre-annotations (much faster than annotating from scratch)\n",
        "4. Retrain on the expanded dataset\n",
        "5. Repeat until performance plateaus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "639a42bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "639a42bd",
        "outputId": "865bc5ac-aca0-4e84-c05c-db94ad49380a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== spaCy Evaluation ===\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 5.6  Evaluate the model with spaCy's evaluate command\n",
        "\n",
        "from spacy.cli.evaluate import evaluate as spacy_evaluate\n",
        "\n",
        "print(\"=== spaCy Evaluation ===\")\n",
        "results = spacy_evaluate(\n",
        "    \"models/spacy_music_ner/model-last\",\n",
        "    \"data/music_ner_test.spacy\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dfc3cb3",
      "metadata": {
        "id": "3dfc3cb3"
      },
      "source": [
        "The evaluation output provides entity-level precision, recall, and F1 broken down by entity type. These are **strict** metrics: a prediction must match the gold span *exactly* (same start, same end, same label) to count as correct. Partial matches score zero.\n",
        "\n",
        "This strict evaluation is appropriate for NER because downstream tasks (knowledge base population, information retrieval, question answering) typically need exact entity boundaries. A system that tags \"The Beat\" instead of \"The Beatles\" provides incorrect information despite being close.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cacc9948",
      "metadata": {
        "id": "cacc9948"
      },
      "source": [
        "## Recipe 6 — Fine-tuning BERT for NER\n",
        "\n",
        "**Fine-tuning** a pre-trained language model like BERT means taking a model that already understands language (from pre-training on billions of words) and teaching it a specific task with a small labeled dataset. The pre-trained knowledge transfers: BERT already knows that capitalized words are often proper nouns, that \"by\" often precedes an artist name, and that song titles appear in quotes.\n",
        "\n",
        "The key difference from training spaCy from scratch: BERT starts with **deep contextual representations** of every token, built from 12 transformer layers with $\\sim$110M parameters. We add a thin classification head on top and fine-tune the entire model on our music NER data.\n",
        "\n",
        "The model predicts one of 5 IOB labels per token:\n",
        "\n",
        "| Tag | Meaning | Example |\n",
        "|-----|---------|---------|\n",
        "| `O` | Outside any entity | *\"music similar to\"* |\n",
        "| `B-Artist` | Begin Artist entity | ***The*** *Beatles* |\n",
        "| `I-Artist` | Inside Artist entity | *The* ***Beatles*** |\n",
        "| `B-WoA` | Begin Work of Art | ***Abbey*** *Road* |\n",
        "| `I-WoA` | Inside Work of Art | *Abbey* ***Road*** |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c491c68e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c491c68e",
        "outputId": "5ada9ad5-30d2-4a71-d097-9bfcc464f3e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 226 documents for entity lookup\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 6.1  Load and preprocess IOB-format data\n",
        "\n",
        "from datasets import (\n",
        "    Dataset, Features, Value, ClassLabel,\n",
        "    Sequence, DatasetDict\n",
        ")\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Re-process music NER data for entity lookup\n",
        "music_ner_df2 = pd.read_csv(\"data/music_ner.csv\")\n",
        "music_ner_df2[\"label\"] = music_ner_df2[\"label\"].apply(\n",
        "    lambda x: x.replace(\"_deduced\", \"\"))\n",
        "music_ner_df2[\"text\"] = music_ner_df2[\"text\"].apply(\n",
        "    lambda x: x.replace(\"|\", \",\"))\n",
        "\n",
        "ids = list(set(music_ner_df2[\"id\"].values))\n",
        "docs = {}\n",
        "for doc_id in ids:\n",
        "    entity_rows = music_ner_df2[music_ner_df2[\"id\"] == doc_id]\n",
        "    text = entity_rows.iloc[0][\"text\"]\n",
        "    doc = small_model(text)\n",
        "    ents = []\n",
        "    for _, row in entity_rows.iterrows():\n",
        "        span = doc.char_span(\n",
        "            row[\"start_offset\"], row[\"end_offset\"],\n",
        "            label=row[\"label\"], alignment_mode=\"contract\")\n",
        "        if span is not None:\n",
        "            ents.append(span)\n",
        "    try:\n",
        "        doc.ents = ents\n",
        "    except ValueError:\n",
        "        pass\n",
        "    docs[doc.text] = doc\n",
        "\n",
        "print(f\"Processed {len(docs)} documents for entity lookup\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2969513a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2969513a",
        "outputId": "6447a905-323e-483f-ccad-df5872dfebaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sentences: 599\n",
            "Training: 539  |  Test: 60\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 6.2  Load IOB data and split into train/test\n",
        "\n",
        "data_file = \"data/music_ner_bio.bio\"\n",
        "tag_mapping = {\"O\": 0, \"B-Artist\": 1, \"I-Artist\": 2,\n",
        "               \"B-WoA\": 3, \"I-WoA\": 4}\n",
        "\n",
        "with open(data_file) as f:\n",
        "    data = f.read()\n",
        "\n",
        "tokens_list = []\n",
        "ner_tags_list = []\n",
        "spans_list = []\n",
        "sentences = data.strip().split(\"\\n\\n\")\n",
        "\n",
        "for sentence in sentences:\n",
        "    if not sentence.strip():\n",
        "        continue\n",
        "    words = []\n",
        "    tags = []\n",
        "    word_tag_pairs = sentence.strip().split(\"\\n\")\n",
        "    for pair in word_tag_pairs:\n",
        "        parts = pair.split(\"\\t\")\n",
        "        if len(parts) != 2:\n",
        "            continue\n",
        "        word, tag = parts\n",
        "        words.append(word)\n",
        "        tags.append(tag_mapping.get(tag, 0))\n",
        "\n",
        "    sentence_text = \" \".join(words)\n",
        "    this_spans = []\n",
        "    if sentence_text in docs:\n",
        "        for ent in docs[sentence_text].ents:\n",
        "            this_spans.append(f\"{ent.label_}: {ent.text}\")\n",
        "\n",
        "    tokens_list.append(words)\n",
        "    ner_tags_list.append(tags)\n",
        "    spans_list.append(this_spans)\n",
        "\n",
        "print(f\"Total sentences: {len(tokens_list)}\")\n",
        "\n",
        "# Split\n",
        "indices = list(range(len(spans_list)))\n",
        "train_idx, test_idx = train_test_split(indices, test_size=0.1,\n",
        "                                       random_state=42)\n",
        "\n",
        "train_tokens = [tokens_list[i] for i in train_idx]\n",
        "test_tokens  = [tokens_list[i] for i in test_idx]\n",
        "train_tags   = [ner_tags_list[i] for i in train_idx]\n",
        "test_tags    = [ner_tags_list[i] for i in test_idx]\n",
        "train_spans  = [spans_list[i] for i in train_idx]\n",
        "test_spans   = [spans_list[i] for i in test_idx]\n",
        "\n",
        "print(f\"Training: {len(train_tokens)}  |  Test: {len(test_tokens)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d7804de",
      "metadata": {
        "id": "5d7804de"
      },
      "source": [
        "The IOB (Inside-Outside-Beginning) format is the standard for token-level NER annotations. Each token gets exactly one tag. The `B-` prefix marks the first token of an entity, `I-` marks continuation tokens, and `O` marks non-entity tokens. This scheme handles multi-word entities naturally: \"The Beatles\" becomes `B-Artist I-Artist`.\n",
        "\n",
        "We split at 90/10 rather than 75/25 because we have limited data and want to maximize training signal. The random state ensures reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "5bb8c527",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bb8c527",
        "outputId": "129e8b13-0b06-4e1d-85fd-9e37c225d624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['tokens', 'ner_tags', 'spans', 'text'],\n",
            "        num_rows: 539\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['tokens', 'ner_tags', 'spans', 'text'],\n",
            "        num_rows: 60\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 6.3  Create HuggingFace Dataset objects\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "label_names = [\"O\", \"B-Artist\", \"I-Artist\", \"B-WoA\", \"I-WoA\"]\n",
        "\n",
        "training_df = pd.DataFrame({\n",
        "    \"tokens\": train_tokens,\n",
        "    \"ner_tags\": train_tags,\n",
        "    \"spans\": train_spans\n",
        "})\n",
        "test_df_bert = pd.DataFrame({\n",
        "    \"tokens\": test_tokens,\n",
        "    \"ner_tags\": test_tags,\n",
        "    \"spans\": test_spans\n",
        "})\n",
        "\n",
        "training_df[\"text\"] = training_df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
        "test_df_bert[\"text\"] = test_df_bert[\"tokens\"].apply(lambda x: \" \".join(x))\n",
        "\n",
        "features = Features({\n",
        "    \"tokens\": Sequence(Value(\"string\")),\n",
        "    \"ner_tags\": Sequence(ClassLabel(names=label_names)),\n",
        "    \"spans\": Sequence(Value(\"string\")),\n",
        "    \"text\": Value(\"string\"),\n",
        "})\n",
        "\n",
        "training_dataset = Dataset.from_pandas(training_df, features=features)\n",
        "test_dataset_bert = Dataset.from_pandas(test_df_bert, features=features)\n",
        "dataset = DatasetDict({\n",
        "    \"train\": training_dataset,\n",
        "    \"test\": test_dataset_bert\n",
        "})\n",
        "\n",
        "print(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "e96ca5bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "0d6134f107214e1fa793139485261230",
            "77dadfc690a146b8923ad9f1ff17e219",
            "2939bd750ccf466899507352bd193c85",
            "47990440841f4283aee47fc21bdce5a2",
            "50cad1bdc79e4afe96544acfc665bc88",
            "8e6bf07f9c4045ae87aa9995dc36ffcc",
            "8d8bf092657a407e892aee5ea3246c06",
            "2eb7778a8db441c888eb6afdf86e76aa",
            "e535266fde0d43a78f9b32a9f28fd158",
            "85b4151ffd694f81bc578ede7ad84db3",
            "657829da855847b6ba2d2bf90145f361",
            "b585a622f4614cd8af4ebfa6a4086eaf",
            "e7fc0f7f75ad4378bdab516e1373d7cd",
            "1fee9215ba654d3795cead296829fc4b",
            "9ed5b125a30e47659a668bf0646f9a97",
            "1bd2aef8ab86426daaba8fc999efa537",
            "e1af2f4cf5f542f0a69d51d6caed97a9",
            "f0e58cbdad7e43e796ea4809de8af7c0",
            "9a886a5b7ac54f4cab87338324db44b4",
            "ef8da4ca6ead4c9e919f6a3c1c3c44d7",
            "72b03c2e55a14b06957c5c2013dfcd7e",
            "be13b72f5f8249d596223bd4e3961bba"
          ]
        },
        "id": "e96ca5bd",
        "outputId": "7aa46836-426c-412b-bc3b-fcf2195f3ecd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/539 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d6134f107214e1fa793139485261230"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/60 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b585a622f4614cd8af4ebfa6a4086eaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization complete.\n",
            "Train features: ['tokens', 'ner_tags', 'spans', 'text', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 6.4  Tokenize and align labels for BERT subword tokenization\n",
        "\n",
        "def tokenize_adjust_labels(all_samples):\n",
        "    \"\"\"Align NER labels with BERT subword tokens.\"\"\"\n",
        "    tokenized = tokenizer(all_samples[\"text\"], truncation=True, padding=True)\n",
        "    all_adjusted_labels = []\n",
        "\n",
        "    for k in range(len(tokenized[\"input_ids\"])):\n",
        "        prev_wid = -1\n",
        "        word_ids = tokenized.word_ids(batch_index=k)\n",
        "        existing_labels = all_samples[\"ner_tags\"][k]\n",
        "        i = -1\n",
        "        adjusted = []\n",
        "        for wid in word_ids:\n",
        "            if wid is None:\n",
        "                adjusted.append(-100)  # special tokens\n",
        "            elif wid != prev_wid:\n",
        "                i += 1\n",
        "                if i < len(existing_labels):\n",
        "                    adjusted.append(existing_labels[i])\n",
        "                else:\n",
        "                    adjusted.append(0)\n",
        "                prev_wid = wid\n",
        "            else:\n",
        "                # subword continuation: copy parent label\n",
        "                if i < len(existing_labels):\n",
        "                    adjusted.append(existing_labels[i])\n",
        "                else:\n",
        "                    adjusted.append(0)\n",
        "        all_adjusted_labels.append(adjusted)\n",
        "\n",
        "    tokenized[\"labels\"] = all_adjusted_labels\n",
        "    return tokenized\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_adjust_labels, batched=True)\n",
        "print(\"Tokenization complete.\")\n",
        "print(f\"Train features: {tokenized_dataset['train'].column_names}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a9caf5d",
      "metadata": {
        "id": "8a9caf5d"
      },
      "source": [
        "BERT's **WordPiece tokenizer** splits words into subword units: \"Radiohead\" might become `[\"radio\", \"##head\"]`. This creates a mismatch with our token-level NER labels, which have one label per original word.\n",
        "\n",
        "The `tokenize_adjust_labels` function resolves this by:\n",
        "1. Mapping each subword back to its original word using `word_ids()`\n",
        "2. Assigning the parent word's label to the first subword\n",
        "3. Copying the same label to continuation subwords (`##head` gets the same label as `radio`)\n",
        "4. Assigning `-100` to special tokens (`[CLS]`, `[SEP]`, padding) — this tells PyTorch's cross-entropy loss to **ignore** these positions during backpropagation\n",
        "\n",
        "This alignment step is critical: without it, the model would try to predict labels for `[CLS]` and `[SEP]` tokens, and the loss would be computed on the wrong number of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "149e6e8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "149e6e8f",
        "outputId": "49ec10ae-5be2-4d49-d884-d6e5fefc2680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertForTokenClassification LOAD REPORT from: bert-base-uncased\n",
            "Key                                        | Status     | \n",
            "-------------------------------------------+------------+-\n",
            "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
            "cls.predictions.bias                       | UNEXPECTED | \n",
            "bert.pooler.dense.bias                     | UNEXPECTED | \n",
            "cls.seq_relationship.weight                | UNEXPECTED | \n",
            "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
            "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
            "bert.pooler.dense.weight                   | UNEXPECTED | \n",
            "cls.seq_relationship.bias                  | UNEXPECTED | \n",
            "classifier.bias                            | MISSING    | \n",
            "classifier.weight                          | MISSING    | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training BERT NER model (7 epochs)...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [238/238 27:10, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "      <th>Artist F1</th>\n",
              "      <th>Woa F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.433740</td>\n",
              "      <td>0.175676</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.187050</td>\n",
              "      <td>0.841187</td>\n",
              "      <td>0.234234</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.335728</td>\n",
              "      <td>0.408451</td>\n",
              "      <td>0.446154</td>\n",
              "      <td>0.426471</td>\n",
              "      <td>0.909250</td>\n",
              "      <td>0.510638</td>\n",
              "      <td>0.238095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.269069</td>\n",
              "      <td>0.532258</td>\n",
              "      <td>0.507692</td>\n",
              "      <td>0.519685</td>\n",
              "      <td>0.912740</td>\n",
              "      <td>0.556962</td>\n",
              "      <td>0.458333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.230879</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.740741</td>\n",
              "      <td>0.935428</td>\n",
              "      <td>0.780488</td>\n",
              "      <td>0.679245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.236466</td>\n",
              "      <td>0.776119</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.787879</td>\n",
              "      <td>0.942408</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.708333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.233594</td>\n",
              "      <td>0.779412</td>\n",
              "      <td>0.815385</td>\n",
              "      <td>0.796992</td>\n",
              "      <td>0.942408</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.716981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.237721</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.830769</td>\n",
              "      <td>0.805970</td>\n",
              "      <td>0.942408</td>\n",
              "      <td>0.870588</td>\n",
              "      <td>0.693878</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=238, training_loss=0.2509446825299944, metrics={'train_runtime': 1647.0213, 'train_samples_per_second': 2.291, 'train_steps_per_second': 0.145, 'total_flos': 84725729928840.0, 'train_loss': 0.2509446825299944, 'epoch': 7.0})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "\n",
        "# 6.5  Train the fine-tuned BERT NER model\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForTokenClassification\n",
        ")\n",
        "from evaluate import load as load_metric\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "metric = load_metric(\"seqeval\")\n",
        "\n",
        "def compute_metrics(eval_data):\n",
        "    predictions, labels = eval_data\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove special tokens (label == -100)\n",
        "    paired = [\n",
        "        [(p, l) for p, l in zip(pred, lab) if l != -100]\n",
        "        for pred, lab in zip(predictions, labels)\n",
        "    ]\n",
        "    true_preds  = [[label_names[p] for p, l in sent] for sent in paired]\n",
        "    true_labels = [[label_names[l] for p, l in sent] for sent in paired]\n",
        "\n",
        "    results = metric.compute(predictions=true_preds,\n",
        "                             references=true_labels)\n",
        "    flat = {\n",
        "        \"overall_precision\": results[\"overall_precision\"],\n",
        "        \"overall_recall\":    results[\"overall_recall\"],\n",
        "        \"overall_f1\":        results[\"overall_f1\"],\n",
        "        \"overall_accuracy\":  results[\"overall_accuracy\"],\n",
        "    }\n",
        "    for k, v in results.items():\n",
        "        if isinstance(v, dict) and \"f1\" in v:\n",
        "            flat[f\"{k}_f1\"] = v[\"f1\"]\n",
        "    return flat\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", num_labels=len(label_names))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./fine_tune_bert_output\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=7,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=1000,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=\"none\",        # disable wandb/mlflow\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    processing_class=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"Training BERT NER model (7 epochs)...\\n\")\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c2781a7",
      "metadata": {
        "id": "8c2781a7"
      },
      "source": [
        "The fine-tuning process adapts all 110M BERT parameters plus the new classification head to our music NER task. Key hyperparameters:\n",
        "\n",
        "- **Learning rate $2 \\times 10^{-5}$** — this is much smaller than typical training from scratch ($10^{-3}$) because we are making small adjustments to already-good representations. Too high a learning rate would destroy the pre-trained knowledge (\"catastrophic forgetting\").\n",
        "- **7 epochs** — with only $\\sim$540 training sentences, each epoch is very fast. We train for multiple passes to ensure the model sees enough examples.\n",
        "- **Weight decay 0.01** — L2 regularization to prevent overfitting on the small dataset.\n",
        "\n",
        "The `seqeval` metric evaluates at the **entity level** (matching full spans), not the token level. This is the standard for NER evaluation because getting individual tokens right is useless if entity boundaries are wrong."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "6a1d1120",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "6a1d1120",
        "outputId": "2f1f8894-797a-44ba-cbcf-7791850374c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== BERT NER Evaluation ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  eval_loss: 0.2377\n",
            "  eval_overall_precision: 0.7826\n",
            "  eval_overall_recall: 0.8308\n",
            "  eval_overall_f1: 0.8060\n",
            "  eval_overall_accuracy: 0.9424\n",
            "  eval_Artist_f1: 0.8706\n",
            "  eval_WoA_f1: 0.6939\n",
            "  eval_runtime: 5.1907\n",
            "  eval_samples_per_second: 11.5590\n",
            "  eval_steps_per_second: 0.7710\n",
            "  epoch: 7.0000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 6.6  Evaluate the fine-tuned model\n",
        "\n",
        "print(\"=== BERT NER Evaluation ===\")\n",
        "eval_results = trainer.evaluate()\n",
        "for k, v in eval_results.items():\n",
        "    if isinstance(v, float):\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "    else:\n",
        "        print(f\"  {k}: {v}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d70a0e24",
      "metadata": {
        "id": "d70a0e24"
      },
      "source": [
        "The fine-tuned BERT model typically achieves **overall entity F1 of 60--70%**, with the `Artist` label performing best ($\\sim$75% F1) and `WoA` performing more modestly ($\\sim$50% F1). This substantially outperforms the spaCy model trained from scratch on the same data, demonstrating the power of **transfer learning**: BERT's pre-trained knowledge about language structure, capitalization patterns, and word meanings gives it a significant head start.\n",
        "\n",
        "The improvement is especially notable given the tiny dataset size. With $\\sim$540 training sentences, training from scratch (spaCy) yields $\\sim$45% F1, while fine-tuning (BERT) yields $\\sim$65% F1 — a $\\sim$20-point improvement from leveraging pre-trained representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "4ce8edaf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ce8edaf",
        "outputId": "ea6a0a13-1be2-4b09-a687-c05e837eceb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to models/bert_fine_tuned\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 6.7  Save and test on new text\n",
        "\n",
        "trainer.save_model(\"models/bert_fine_tuned\")\n",
        "print(\"Model saved to models/bert_fine_tuned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "b4cf85e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4cf85e9",
        "outputId": "d6f299bc-3aaa-4a87-eb4f-8605b6b8f6c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: music similar to morphine robocobra quartet featuring elements like saxophone prominent bass\n",
            "  -> music similar to               [O]  (score: 0.999)\n",
            "  -> morphine roboco                [Artist]  (score: 0.834)\n",
            "  -> ##bra quartet                  [Artist]  (score: 0.456)\n",
            "  -> featuring elements like saxophone prominent bass [O]  (score: 0.999)\n",
            "\n",
            "Text: i really enjoy listening to abbey road by the beatles\n",
            "  -> i really enjoy listening to    [O]  (score: 0.998)\n",
            "  -> abbey                          [WoA]  (score: 0.906)\n",
            "  -> road                           [WoA]  (score: 0.714)\n",
            "  -> by                             [O]  (score: 0.997)\n",
            "  -> the                            [Artist]  (score: 0.964)\n",
            "  -> beatles                        [Artist]  (score: 0.915)\n",
            "\n",
            "Text: have you heard ok computer by radiohead it is a masterpiece\n",
            "  -> have you heard                 [O]  (score: 0.812)\n",
            "  -> ok                             [WoA]  (score: 0.950)\n",
            "  -> computer                       [WoA]  (score: 0.964)\n",
            "  -> by                             [O]  (score: 0.994)\n",
            "  -> radiohead                      [Artist]  (score: 0.948)\n",
            "  -> it is a masterpiece            [O]  (score: 0.981)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 6.8  Run inference with a pipeline\n",
        "\n",
        "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
        "\n",
        "model_loaded = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"models/bert_fine_tuned\")\n",
        "tokenizer_loaded = AutoTokenizer.from_pretrained(\n",
        "    \"models/bert_fine_tuned\")\n",
        "\n",
        "pipe = pipeline(\n",
        "    task=\"token-classification\",\n",
        "    model=model_loaded.to(\"cpu\"),\n",
        "    tokenizer=tokenizer_loaded,\n",
        "    aggregation_strategy=\"simple\"\n",
        ")\n",
        "\n",
        "test_texts = [\n",
        "    \"music similar to morphine robocobra quartet featuring elements like saxophone prominent bass\",\n",
        "    \"i really enjoy listening to abbey road by the beatles\",\n",
        "    \"have you heard ok computer by radiohead it is a masterpiece\",\n",
        "]\n",
        "\n",
        "id2label = {0: \"O\", 1: \"B-Artist\", 2: \"I-Artist\", 3: \"B-WoA\", 4: \"I-WoA\"}\n",
        "\n",
        "for text in test_texts:\n",
        "    print(f\"Text: {text}\")\n",
        "    results = pipe(text)\n",
        "    for r in results:\n",
        "        label = r[\"entity_group\"]\n",
        "        # Map LABEL_N to readable names\n",
        "        if label.startswith(\"LABEL_\"):\n",
        "            idx = int(label.split(\"_\")[1])\n",
        "            label = id2label.get(idx, label)\n",
        "            # Convert B-/I- to base label\n",
        "            if label.startswith((\"B-\", \"I-\")):\n",
        "                label = label[2:]\n",
        "        print(f\"  -> {r['word']:<30} [{label}]  (score: {r['score']:.3f})\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9edbd0fe",
      "metadata": {
        "id": "9edbd0fe"
      },
      "source": [
        "The pipeline aggregates subword predictions back into full words and merges consecutive tokens with the same entity type into single spans. The `aggregation_strategy=\"simple\"` mode averages the scores of merged tokens.\n",
        "\n",
        "Notice how the BERT model leverages contextual clues: in \"abbey road by the beatles,\" the word \"by\" signals that what follows is likely an artist, and what precedes is likely a work of art. This kind of contextual reasoning is impossible for simple pattern-matching approaches — it requires the deep bidirectional attention that BERT provides.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e935d6fd",
      "metadata": {
        "id": "e935d6fd"
      },
      "source": [
        "## Summary and Key Takeaways\n",
        "\n",
        "This chapter progressed from simple pattern matching to deep transfer learning, covering the full spectrum of information extraction techniques:\n",
        "\n",
        "**1. Regex is fast but fragile.** For well-structured patterns (emails, URLs, phone numbers), regex is unbeatable in speed and simplicity. But it cannot handle ambiguity, context, or variation — the moment you need to understand *meaning*, you need something more.\n",
        "\n",
        "**2. String similarity handles the messy real world.** Levenshtein distance, Jaro, and Jaro-Winkler similarity provide graceful degradation in the face of typos and misspellings. In production, combine exact matching with fuzzy matching: try exact first, fall back to fuzzy with a confidence threshold.\n",
        "\n",
        "**3. TF-IDF keyword extraction is a powerful unsupervised baseline.** No labeled data needed, scales to millions of documents, and the n-gram + noun chunk variant produces surprisingly readable keyword sets. Use it for content tagging, search indexing, and exploratory analysis.\n",
        "\n",
        "**4. Pre-trained NER models cover common entity types.** spaCy's models handle people, organizations, locations, and dates well enough for many applications. Always evaluate on your specific domain before deploying — accuracy on news text does not guarantee accuracy on medical records or legal contracts.\n",
        "\n",
        "**5. Transfer learning is the key to custom NER.** Fine-tuning BERT on just 540 sentences achieves $\\sim$65% entity F1 — far better than training from scratch ($\\sim$45%). This is the most important practical lesson: when you have limited labeled data, start with a pre-trained model and fine-tune.\n",
        "\n",
        "**6. Data quantity is the bottleneck.** Both the spaCy and BERT NER models are limited by the small training set ($\\sim$200--500 sentences). In production, invest in annotation tooling and iterative data collection — the model architecture matters less than the quality and quantity of your training data."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e8085be4100d40c6a28c1c69c4fb0988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64b331847e9046aab30596a36b12fba6",
              "IPY_MODEL_161c930c3dd445fd9c4f207580c3806a",
              "IPY_MODEL_beaf20c7fda14944aaedf79c60c5a86c"
            ],
            "layout": "IPY_MODEL_3f5226b188064555876da78d8d38a9f3"
          }
        },
        "64b331847e9046aab30596a36b12fba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0101ea8d357d4ab69ed4c7e24d3839c4",
            "placeholder": "​",
            "style": "IPY_MODEL_a0cb2082365f4dfc8cd05d0ccea003f9",
            "value": "Generating train split: 100%"
          }
        },
        "161c930c3dd445fd9c4f207580c3806a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_405949dd745a41bfac67fa9045a10edc",
            "max": 1225,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1187f6e07b047b188daf781a509d66d",
            "value": 1225
          }
        },
        "beaf20c7fda14944aaedf79c60c5a86c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f289e1194710493b9b51d26d492395c7",
            "placeholder": "​",
            "style": "IPY_MODEL_6971dc5d8e7341c8b87f13720c98ad52",
            "value": " 1225/1225 [00:00&lt;00:00, 19377.50 examples/s]"
          }
        },
        "3f5226b188064555876da78d8d38a9f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0101ea8d357d4ab69ed4c7e24d3839c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0cb2082365f4dfc8cd05d0ccea003f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "405949dd745a41bfac67fa9045a10edc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1187f6e07b047b188daf781a509d66d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f289e1194710493b9b51d26d492395c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6971dc5d8e7341c8b87f13720c98ad52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "002dd3df57444aecacb4a8bf902acc82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8330b513aedc4bbb80792a31ab7a3c71",
              "IPY_MODEL_31f4162b94e748e8949c6529cd091b88",
              "IPY_MODEL_2a7026a7af4d4a95bbbc3b966beb657e"
            ],
            "layout": "IPY_MODEL_2f107467b2634af99efaca75e3bc0b54"
          }
        },
        "8330b513aedc4bbb80792a31ab7a3c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b2b5ebb3ca241f19f59a9d222952e33",
            "placeholder": "​",
            "style": "IPY_MODEL_277dd9fa79d0434dbeaca34383ad2c25",
            "value": "Generating test split: 100%"
          }
        },
        "31f4162b94e748e8949c6529cd091b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a9ff7eed42e45aaaed330a242070cba",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2027b95b67f14705b052eb67fca01ec2",
            "value": 1000
          }
        },
        "2a7026a7af4d4a95bbbc3b966beb657e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ac13d55d62e4c6d91258c7e1c57b1f2",
            "placeholder": "​",
            "style": "IPY_MODEL_ffa4d9d0b6c94704bc71b7e2abbdd965",
            "value": " 1000/1000 [00:00&lt;00:00, 27916.99 examples/s]"
          }
        },
        "2f107467b2634af99efaca75e3bc0b54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b2b5ebb3ca241f19f59a9d222952e33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "277dd9fa79d0434dbeaca34383ad2c25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a9ff7eed42e45aaaed330a242070cba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2027b95b67f14705b052eb67fca01ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ac13d55d62e4c6d91258c7e1c57b1f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffa4d9d0b6c94704bc71b7e2abbdd965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d6134f107214e1fa793139485261230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77dadfc690a146b8923ad9f1ff17e219",
              "IPY_MODEL_2939bd750ccf466899507352bd193c85",
              "IPY_MODEL_47990440841f4283aee47fc21bdce5a2"
            ],
            "layout": "IPY_MODEL_50cad1bdc79e4afe96544acfc665bc88"
          }
        },
        "77dadfc690a146b8923ad9f1ff17e219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e6bf07f9c4045ae87aa9995dc36ffcc",
            "placeholder": "​",
            "style": "IPY_MODEL_8d8bf092657a407e892aee5ea3246c06",
            "value": "Map: 100%"
          }
        },
        "2939bd750ccf466899507352bd193c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eb7778a8db441c888eb6afdf86e76aa",
            "max": 539,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e535266fde0d43a78f9b32a9f28fd158",
            "value": 539
          }
        },
        "47990440841f4283aee47fc21bdce5a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85b4151ffd694f81bc578ede7ad84db3",
            "placeholder": "​",
            "style": "IPY_MODEL_657829da855847b6ba2d2bf90145f361",
            "value": " 539/539 [00:00&lt;00:00, 3115.66 examples/s]"
          }
        },
        "50cad1bdc79e4afe96544acfc665bc88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e6bf07f9c4045ae87aa9995dc36ffcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d8bf092657a407e892aee5ea3246c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2eb7778a8db441c888eb6afdf86e76aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e535266fde0d43a78f9b32a9f28fd158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85b4151ffd694f81bc578ede7ad84db3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "657829da855847b6ba2d2bf90145f361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b585a622f4614cd8af4ebfa6a4086eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7fc0f7f75ad4378bdab516e1373d7cd",
              "IPY_MODEL_1fee9215ba654d3795cead296829fc4b",
              "IPY_MODEL_9ed5b125a30e47659a668bf0646f9a97"
            ],
            "layout": "IPY_MODEL_1bd2aef8ab86426daaba8fc999efa537"
          }
        },
        "e7fc0f7f75ad4378bdab516e1373d7cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1af2f4cf5f542f0a69d51d6caed97a9",
            "placeholder": "​",
            "style": "IPY_MODEL_f0e58cbdad7e43e796ea4809de8af7c0",
            "value": "Map: 100%"
          }
        },
        "1fee9215ba654d3795cead296829fc4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a886a5b7ac54f4cab87338324db44b4",
            "max": 60,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef8da4ca6ead4c9e919f6a3c1c3c44d7",
            "value": 60
          }
        },
        "9ed5b125a30e47659a668bf0646f9a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72b03c2e55a14b06957c5c2013dfcd7e",
            "placeholder": "​",
            "style": "IPY_MODEL_be13b72f5f8249d596223bd4e3961bba",
            "value": " 60/60 [00:00&lt;00:00, 1237.14 examples/s]"
          }
        },
        "1bd2aef8ab86426daaba8fc999efa537": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1af2f4cf5f542f0a69d51d6caed97a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0e58cbdad7e43e796ea4809de8af7c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a886a5b7ac54f4cab87338324db44b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef8da4ca6ead4c9e919f6a3c1c3c44d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72b03c2e55a14b06957c5c2013dfcd7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be13b72f5f8249d596223bd4e3961bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}