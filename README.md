# Python Natural Language Processing Cookbook

Welcome to the **Python NLP Cookbook**! This repository contains a collection of "recipes," scripts, and practical code examples for solving various Natural Language Processing (NLP) tasks using the modern Python ecosystem.

From basic text cleaning to cutting-edge Deep Learning models, this guide is designed as a quick reference for beginners and data science practitioners alike.

## About the Project

This repository aims to provide easy-to-understand, *copy-paste* solutions for common NLP problems. Each folder represents a specific topic category, and every Python script is designed to be modular and easy to integrate into your own projects.

Topics covered include:

* Text Preprocessing (Cleaning, Tokenization, Stemming/Lemmatization).
* Linguistic Feature Analysis (POS Tagging, NER).
* Text Classification & Sentiment Analysis.
* Topic Modeling & Text Summarization.
* Transformers implementation (BERT, GPT, etc.).

##  Tech Stack

This project utilizes the most popular Python libraries for NLP:

* **[NLTK](https://www.google.com/search?q=https://www.nltk.org/):** For classical text processing tasks.
* **[spaCy](https://www.google.com/search?q=https://spacy.io/):** For fast, industrial-strength NLP.
* **[Scikit-learn](https://www.google.com/search?q=https://scikit-learn.org/):** For traditional Machine Learning pipelines.
* **[Gensim](https://www.google.com/search?q=https://radimrehurek.com/gensim/):** For Topic Modeling and Word Embeddings.
* **[Hugging Face Transformers](https://www.google.com/search?q=https://huggingface.co/):** For State-of-the-Art models (BERT, RoBERTa, T5).
* **[Pandas & NumPy](https://www.google.com/search?q=https://pandas.pydata.org/):** For data manipulation.

## Repository Structure

```text
python-nlp-cookbook/
â”œâ”€â”€ 01_text_preprocessing/    # Regex, Stopwords, Lemmatization, Cleaning
â”œâ”€â”€ 02_feature_extraction/    # Bag of Words, TF-IDF, Word2Vec, GloVe
â”œâ”€â”€ 03_classification/        # Sentiment Analysis, Spam Detection
â”œâ”€â”€ 04_information_extraction/# Named Entity Recognition (NER), POS Tagging
â”œâ”€â”€ 05_topic_modeling/        # LDA, LSA, NMF
â”œâ”€â”€ 06_text_generation/       # Markov Chains, GPT-2/3
â”œâ”€â”€ 07_transformers/          # Fine-tuning BERT, Hugging Face pipelines
â”œâ”€â”€ data/                     # Sample datasets (dummy data)
â”œâ”€â”€ requirements.txt          # Project dependencies
â””â”€â”€ README.md

```

## Installation

Follow these steps to run the recipes on your local machine:

1. **Clone the repository:**
```bash
git clone https://github.com/your-username/python-nlp-cookbook.git
cd python-nlp-cookbook

```


2. **Create a Virtual Environment (Recommended):**
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate

```


3. **Install Dependencies:**
```bash
pip install -r requirements.txt

```


4. **Download Language Models (Optional, depends on the recipe):**
```bash
# Example for spaCy
python -m spacy download en_core_web_sm

# Example for NLTK
python -c "import nltk; nltk.download('popular')"

```



## Usage

Each folder contains `.py` files or `.ipynb` (Jupyter Notebooks). You can run them directly.

Example of running a preprocessing script:

```bash
cd 01_text_preprocessing
python basic_cleaning.py

```

Or open Jupyter Notebook for interactive experiments:

```bash
jupyter notebook

```

## Recipe Examples

### 1. Tokenization & Lemmatization with spaCy

```python
import spacy

nlp = spacy.load("en_core_web_sm")
text = "The quick brown fox jumps over the lazy dog."
doc = nlp(text)

for token in doc:
    print(f"{token.text} -> {token.lemma_}")

```

### 2. Simple Sentiment Analysis with TextBlob

```python
from textblob import TextBlob

text = "I love learning Natural Language Processing! It's amazing."
blob = TextBlob(text)

print(f"Polarity: {blob.sentiment.polarity}") # Output is close to 1.0 (Positive)

```

## Contributing

Contributions are welcome! If you have a new "recipe" or an improvement for existing code:

1. Fork the repository.
2. Create a new feature branch (`git checkout -b new-feature`).
3. Commit your changes (`git commit -m 'Add sentiment analysis recipe'`).
4. Push to the branch (`git push origin new-feature`).
5. Open a Pull Request.

Please ensure your code is clean and well-commented.

## ðŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](https://www.google.com/search?q=LICENSE) file for details.
