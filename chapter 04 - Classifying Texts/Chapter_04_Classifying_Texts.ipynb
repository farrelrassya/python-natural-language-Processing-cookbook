{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae66c3c7",
   "metadata": {
    "id": "ae66c3c7"
   },
   "source": [
    "# Chapter 4 — Classifying Texts\n",
    "\n",
    "Text classification is one of the foundational tasks in Natural Language Processing: given a piece of text, assign it a **label** drawn from a fixed set of categories. Sentiment analysis (\"positive\" vs. \"negative\"), topic detection (\"sport\" vs. \"politics\"), spam filtering, and intent recognition all fall under this umbrella.\n",
    "\n",
    "In this notebook we work through five progressively sophisticated approaches:\n",
    "\n",
    "| # | Method | Supervision | Core Idea |\n",
    "|---|--------|-------------|-----------|\n",
    "| 1 | **Keyword / Rule-based** | None | Count class-specific words |\n",
    "| 2 | **K-Means Clustering** | Unsupervised | Group TF-IDF vectors into $k$ clusters |\n",
    "| 3 | **SVM with BERT embeddings** | Supervised | Learn a maximum-margin boundary in embedding space |\n",
    "| 4 | **spaCy TextCategorizer (CNN)** | Supervised | Train an end-to-end CNN inside spaCy |\n",
    "| 5 | **GPT-4o-mini** | Zero-shot | Prompt a large language model |\n",
    "\n",
    "We use two datasets throughout: the **Rotten Tomatoes** movie-review corpus (binary sentiment) and the **BBC News** dataset (5-class topic classification). Both are loaded directly from Hugging Face.\n",
    "\n",
    "**Prerequisites:** A Google Colab runtime with GPU is recommended but not required. An OpenAI API key (stored in Colab Secrets) is needed only for Recipe 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab2b898",
   "metadata": {
    "id": "0ab2b898"
   },
   "source": [
    "## 0 — Environment Setup\n",
    "\n",
    "We install all required packages in a single cell so the notebook is fully self-contained on Colab. We also define shared utility functions that the original cookbook kept in external helper notebooks — here everything lives in one place for portability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b8d5f0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b8d5f0a",
    "outputId": "54e69fea-a376-4b61-cb8c-e565c5b7f768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 0.1  Install packages\n",
    "\n",
    "!pip install -q \\\n",
    "    datasets \\\n",
    "    langdetect \\\n",
    "    nltk \\\n",
    "    scikit-learn \\\n",
    "    sentence-transformers \\\n",
    "    spacy \\\n",
    "    openai\n",
    "\n",
    "# Download spaCy's small English model (used for tokenization)\n",
    "!python -m spacy download en_core_web_sm -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d203fda6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d203fda6",
    "outputId": "b6a2980f-d212-48cd-f0a3-f8b23f007722"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 0.2  Core imports & configuration\n",
    "\n",
    "import warnings, os, re, json\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\",        quiet=True)\n",
    "nltk.download(\"punkt_tab\",    quiet=True)\n",
    "nltk.download(\"stopwords\",    quiet=True)\n",
    "\n",
    "import spacy\n",
    "from datasets import load_dataset\n",
    "from joblib import dump, load\n",
    "\n",
    "small_model = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "%matplotlib inline\n",
    "print(\"Setup complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de4a00a",
   "metadata": {
    "id": "5de4a00a"
   },
   "source": [
    "All libraries are imported once; individual recipe sections will only add recipe-specific imports to keep things tidy. The `small_model` (spaCy `en_core_web_sm`) is loaded here and reused wherever lightweight tokenization is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7693ed",
   "metadata": {
    "id": "2c7693ed"
   },
   "source": [
    "## 0.3 — Shared Utility Functions\n",
    "\n",
    "The original cookbook stores helper functions in external notebooks (`util_simple_classifier.ipynb`, `lang_utils.ipynb`, `file_utils.ipynb`) and loads them with `%run -i`. For a self-contained Colab notebook we define them inline below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccfdfcb6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccfdfcb6",
    "outputId": "12fc6205-d069-49de-ae45-75ef5833293e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions defined.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 0.3  Shared utility functions\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ---------- text preprocessing ----------\n",
    "STOP_WORDS = list(stopwords.words(\"english\")) + [\"``\", \"'s\"]\n",
    "\n",
    "def tokenize(df, text_col):\n",
    "    \"\"\"Add a *text_tokenized* column with word tokens.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"text_tokenized\"] = df[text_col].apply(word_tokenize)\n",
    "    return df\n",
    "\n",
    "def remove_stopword_punct(df, tok_col):\n",
    "    \"\"\"Remove stopwords & punctuation from a tokenized column.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[tok_col] = df[tok_col].apply(\n",
    "        lambda tokens: [w for w in tokens\n",
    "                        if w.lower() not in STOP_WORDS\n",
    "                        and w not in punctuation])\n",
    "    return df\n",
    "\n",
    "# ---------- dataset loading ----------\n",
    "def load_train_test_dataset_pd(train_split, test_split):\n",
    "    \"\"\"Load the Rotten Tomatoes dataset from Hugging Face.\"\"\"\n",
    "    ds = load_dataset(\"rotten_tomatoes\")\n",
    "    train_df = ds[train_split].to_pandas()\n",
    "    test_df  = ds[test_split].to_pandas()\n",
    "    return train_df, test_df\n",
    "\n",
    "# ---------- SVM / general ML helpers ----------\n",
    "def create_train_test_data(train_df, test_df, vectorize_fn,\n",
    "                           column_name=\"text\"):\n",
    "    \"\"\"Vectorize train & test text; return X_train, X_test, y_train, y_test.\"\"\"\n",
    "    X_train = np.array(train_df[column_name].apply(vectorize_fn).tolist())\n",
    "    X_test  = np.array(test_df[column_name].apply(vectorize_fn).tolist())\n",
    "    y_train = train_df[\"label\"].values\n",
    "    y_test  = test_df[\"label\"].values\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def test_classifier(test_df, clf, target_names, column_name=\"text\",\n",
    "                    vectorize_fn=None, X_test=None, y_test=None):\n",
    "    \"\"\"Predict on test_df, print classification_report, return predictions.\"\"\"\n",
    "    if X_test is None:\n",
    "        X_test = np.array(test_df[column_name].apply(vectorize_fn).tolist())\n",
    "    if y_test is None:\n",
    "        y_test = test_df[\"label\"].values\n",
    "    preds = clf.predict(X_test)\n",
    "    test_df = test_df.copy()\n",
    "    test_df[\"prediction\"] = preds\n",
    "    print(classification_report(y_test, preds, target_names=target_names))\n",
    "    return test_df\n",
    "\n",
    "print(\"Utility functions defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7162a875",
   "metadata": {
    "id": "7162a875"
   },
   "source": [
    "These helpers mirror the cookbook's external notebooks but live right here — no hidden dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a206f8",
   "metadata": {
    "id": "d2a206f8"
   },
   "source": [
    "---\n",
    "## Recipe 1 — Getting the Dataset and Evaluation Ready\n",
    "\n",
    "Before any model can classify text, we need to **load**, **clean**, and **explore** the data. This recipe uses the **Rotten Tomatoes** movie-review corpus: $\\sim$10,700 short reviews labeled as *positive* (1) or *negative* (0).\n",
    "\n",
    "The preprocessing pipeline follows a standard NLP pattern:\n",
    "\n",
    "$$\\text{Raw text} \\;\\xrightarrow{\\text{language filter}}\\; \\text{English only} \\;\\xrightarrow{\\text{tokenize}}\\; \\text{word list} \\;\\xrightarrow{\\text{remove stopwords}}\\; \\text{clean tokens}$$\n",
    "\n",
    "Each arrow reduces noise while preserving the signal a classifier needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33c54c6e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432,
     "referenced_widgets": [
      "75729460b4b44997a147eaee4cf392fb",
      "69499a93313d4972872f069207ab606b",
      "d424fb4d2b8f4a37a9e318e8b07e9056",
      "5679e45bac8a4ddf81e5312c04720d2d",
      "3fccb9408e0b4cad8f288cd672f00811",
      "f0bb5ffe70fc441ca1372b7a1bd10e3c",
      "1d1821aec6d6406fba7351883e7dfa34",
      "670ad1852523491284e7b852b2147d7f",
      "b3ce6116fd7c4b058af74a2232dee761",
      "ccbace644bca4c1d92331c8c3299b642",
      "4dacf4b9f89545fdb33917afb768e030",
      "7d194b9b14114d3786df0482823daf99",
      "da6d37e015ff4310ba664b657f782727",
      "8d14d78cbb9a4f3ca05b0e16cf83c302",
      "7d15e0f47f3c4a53bdb4edb04c8d95e5",
      "eb3ca72523cf4a668ab740bc7a469a63",
      "caf2259271bb4d14940923248954acf6",
      "3cb4b20ad1624603a67de4485f08b6d2",
      "578c8ab1aa164c968fcc9d1bafa353d9",
      "494b3a8e9db547b88d38167e7f289298",
      "8e5a6c15f78448f9b56b8e6b16ed6913",
      "020474a8c1014af594c8d8974de7db09",
      "df074c6f5f1c4e99b27bfbd0a7fc4ba6",
      "b3682f3adbf64b12a22bc74eb6beab46",
      "7a68f4df543c419d90cee498457f2923",
      "962ec26bc46444beaed8d33163bdb345",
      "9e8d8fe1ab0d410594c37331107195d5",
      "de644b7f860c42fb94d574dddd214415",
      "0b708c50841e405385e83b3d982c6938",
      "a2e7a50b02ba43f88a92185b906fe900",
      "e15d1135dcfd4397a3be8d600564121f",
      "9829fb8937b64e839bbd2d4089e2474e",
      "1d580a0d334a4391b7233a33c93eaec4",
      "b28e88e0646f4e6f9dc9330d15e035fa",
      "9eb602122f964bd9bb8979fbcced7254",
      "4a4e7d389f3b404a9a33b8952562ed03",
      "1f901dbed4494fdeb9801ec535fb7281",
      "ef680a758b064deb86bd142c0df8462a",
      "3892db9b54e54ca7845f9123dfb26682",
      "6d64ad4bb2274f998e37beb47e2365a8",
      "8346a43231334052af8feec054389de3",
      "6ce76b683ea14000b3f16100d5431d8d",
      "eabdfc00510744c7976cb851c66658b7",
      "94c9903ff97c46e6b24901f6f7bea3ea",
      "1f5182769769497993e28ca59b90b996",
      "cb06a43cc4ff4295b3f704322bcc8fef",
      "2168e257088744dca921073825a9be98",
      "9c158847fc2e44b8801c882c6b684ee0",
      "f421d593de774dcfac5e649c804a06ff",
      "3ebf17e4897740f791b94891d1b29a1e",
      "923defd719134893a970371fab1f0886",
      "4c534933925d4620a7e71cd8fc9d5228",
      "c024a11cbad74824b6da7e24ad2bb7b6",
      "3481ed2f20bc49d992ea3216fc21b382",
      "a17c127dd7634b7e9e28932bac965d25",
      "9d5ddc55a1d040709a93757dbb412f51",
      "10a7b672554d451795c0b1dee3fe63b2",
      "dee3760ff4714bc9a30d109bbf2e1254",
      "7696b6bf57a44643ad63b2909d53a77f",
      "ad48f241fdf7457b9d3b6014fd93c56e",
      "614712f048bf4577944550d851051c01",
      "9a2a0f52baaf4dfeaf895187e6c93094",
      "80db82ecf22b4325ae744fe66c8d784f",
      "352aa1b4f18645b1885d8c0b19633d48",
      "bbeb8463334e405fa4695990517de6b7",
      "2e797a3c88bf46c9b6bc9839ff913550",
      "7bf3aa526baa432b98a5f4a539325018",
      "5a31cdb7b31343fabc6e1c9b73836945",
      "8476f8197fa54e9496cd240b7799ac0d",
      "de8a763c465540b8afa25a890e6e1220",
      "48417bc027e6485985b1b0ef265250aa",
      "ba045591682e47569efed7e9dfb6a704",
      "9d5adf81b9d44b4c86b956e445e4deb9",
      "531b7b2be26143e69c67e3254b0fc23b",
      "e145fe0aab4544a7b2e8f934eb2a2e36",
      "d03a60ea7b904e62be43746b52ce42b1",
      "d4e43aa8d25a4545bf5cb9ec43e81f99"
     ]
    },
    "id": "33c54c6e",
    "outputId": "86d7abe4-9644-4089-a77c-612016be48a0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75729460b4b44997a147eaee4cf392fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d194b9b14114d3786df0482823daf99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.parquet:   0%|          | 0.00/699k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df074c6f5f1c4e99b27bfbd0a7fc4ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation.parquet:   0%|          | 0.00/90.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28e88e0646f4e6f9dc9330d15e035fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.parquet:   0%|          | 0.00/92.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5182769769497993e28ca59b90b996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5ddc55a1d040709a93757dbb412f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf3aa526baa432b98a5f4a539325018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set : 8,530 reviews\n",
      "Test set     : 1,066 reviews\n",
      "\n",
      "                                                text  label\n",
      "0  the rock is destined to be the 21st century's ...      1\n",
      "1  the gorgeously elaborate continuation of \" the...      1\n",
      "2                     effective but too-tepid biopic      1\n",
      "3  if you sometimes like to go to the movies to h...      1\n",
      "4  emerges as something rare , an issue movie tha...      1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1.1  Load the Rotten Tomatoes dataset\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "(train_df, test_df) = load_train_test_dataset_pd(\"train\", \"test\")\n",
    "print(f\"Training set : {train_df.shape[0]:,} reviews\")\n",
    "print(f\"Test set     : {test_df.shape[0]:,} reviews\")\n",
    "print()\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdb0b72",
   "metadata": {
    "id": "5cdb0b72"
   },
   "source": [
    "The dataset ships with two columns: `text` (the review, already lowercased) and `label` (0 = negative, 1 = positive). With $\\sim$8,530 training and $\\sim$1,066 test reviews, this is a moderately small dataset — a regime where feature engineering and regularization matter more than raw model capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70982c3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70982c3c",
    "outputId": "c031db00-ba36-4632-d17d-99a0de9fca2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 8,530 -> 8,353  (removed 177 non-English)\n",
      "Test    : kept 1,047 English reviews\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1.2  Filter non-English reviews\n",
    "\n",
    "train_before = len(train_df)\n",
    "train_df[\"lang\"] = train_df[\"text\"].apply(detect)\n",
    "train_df = train_df[train_df[\"lang\"] == \"en\"].copy()\n",
    "train_after = len(train_df)\n",
    "\n",
    "test_df[\"lang\"] = test_df[\"text\"].apply(detect)\n",
    "test_df = test_df[test_df[\"lang\"] == \"en\"].copy()\n",
    "\n",
    "print(f\"Training: {train_before:,} -> {train_after:,}  \"\n",
    "      f\"(removed {train_before - train_after} non-English)\")\n",
    "print(f\"Test    : kept {len(test_df):,} English reviews\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a3325d",
   "metadata": {
    "id": "31a3325d"
   },
   "source": [
    "The `langdetect` library applies a Bayesian classifier over character n-gram profiles to identify the language of each review. Even in an ostensibly English corpus, a small fraction of reviews slip through in other languages; removing them prevents the tokenizer and stopword filter from introducing garbage features. The exact number removed will vary slightly due to `langdetect`'s probabilistic nature, but typically around 100--200 rows are dropped from training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94178f43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94178f43",
    "outputId": "7c049f01-61ba-4d91-ce26-da4dac5563e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample cleaned review:\n",
      "['rock', 'destined', '21st', 'century', 'new', 'conan', 'going', 'make', 'splash', 'even', 'greater', 'arnold', 'schwarzenegger', 'jean-claud', 'van', 'damme', 'steven', 'segal']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1.3  Tokenize and remove stopwords / punctuation\n",
    "\n",
    "train_df[\"tokenized_text\"] = train_df[\"text\"].apply(word_tokenize)\n",
    "test_df[\"tokenized_text\"]  = test_df[\"text\"].apply(word_tokenize)\n",
    "\n",
    "def remove_stopwords_and_punct(tokens):\n",
    "    return [w for w in tokens\n",
    "            if w not in STOP_WORDS and w not in punctuation]\n",
    "\n",
    "train_df[\"tokenized_text\"] = train_df[\"tokenized_text\"].apply(\n",
    "    remove_stopwords_and_punct)\n",
    "test_df[\"tokenized_text\"]  = test_df[\"tokenized_text\"].apply(\n",
    "    remove_stopwords_and_punct)\n",
    "\n",
    "print(\"Sample cleaned review:\")\n",
    "print(train_df[\"tokenized_text\"].iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480e7c20",
   "metadata": {
    "id": "480e7c20"
   },
   "source": [
    "**Tokenization** splits each review into individual words (and punctuation tokens). We then strip stopwords (*the, is, a, ...*) and punctuation — these carry little discriminative power for sentiment but inflate the feature space. The NLTK English stopword list contains 179 words; we add `'s` and the backtick pair, which are tokenization artifacts.\n",
    "\n",
    "After cleaning, each review is a list of **content words** — nouns, adjectives, verbs, and adverbs that carry the emotional signal the classifier needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15fe4b04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15fe4b04",
    "outputId": "1b99ca8f-c624-470c-ff97-0efdc0f404cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training set ===\n",
      "label\n",
      "0    4182\n",
      "1    4171\n",
      "Name: text, dtype: int64\n",
      "\n",
      "=== Test set ===\n",
      "label\n",
      "0    525\n",
      "1    522\n",
      "Name: text, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1.4  Check class balance\n",
    "\n",
    "print(\"=== Training set ===\")\n",
    "print(train_df.groupby(\"label\")[\"text\"].count())\n",
    "print()\n",
    "print(\"=== Test set ===\")\n",
    "print(test_df.groupby(\"label\")[\"text\"].count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716deee3",
   "metadata": {
    "id": "716deee3"
   },
   "source": [
    "Class balance is critical for any classification task. When one class dominates, a naive model can achieve deceptively high accuracy by always predicting the majority class. Here, the split is close to 50/50 in both sets, so **accuracy is a valid metric** — we do not need to rely solely on macro-averaged F1 or use oversampling techniques.\n",
    "\n",
    "Formally, if the majority class has proportion $p_{\\text{maj}}$, a \"predict majority\" baseline achieves accuracy $= p_{\\text{maj}}$. With balanced classes, $p_{\\text{maj}} \\approx 0.50$, so any model scoring above 50% is learning something beyond random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f617c1e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5f617c1e",
    "outputId": "c30e56de-b41d-4f1e-9663-0d833114a830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top 30 POSITIVE words ===\n",
      "[('film', 686), ('movie', 429), (\"n't\", 286), ('one', 280), ('--', 271), ('like', 208), ('story', 194), ('comedy', 160), ('good', 151), ('even', 144), ('funny', 137), ('way', 135), ('time', 127), ('best', 126), ('characters', 125), ('make', 124), ('life', 124), ('much', 122), ('us', 122), ('love', 118), ('performances', 117), ('makes', 116), ('may', 113), ('work', 111), ('director', 110), ('enough', 105), ('look', 103), ('still', 96), ('little', 94), ('well', 93)]\n",
      "\n",
      "=== Top 30 NEGATIVE words ===\n",
      "[('movie', 639), ('film', 557), (\"n't\", 449), ('like', 353), ('one', 293), ('--', 264), ('story', 189), ('much', 175), ('bad', 172), ('even', 160), ('time', 146), ('good', 143), ('characters', 138), ('little', 136), ('would', 130), ('never', 122), ('comedy', 121), ('enough', 107), ('really', 104), ('nothing', 103), ('way', 102), ('make', 101), ('plot', 99), ('could', 97), ('director', 96), ('makes', 93), ('made', 92), ('something', 90), ('script', 87), ('every', 87)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1.5  Most common words per class\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "def get_stats(word_list, num_words=30):\n",
    "    freq_dist = FreqDist(word_list)\n",
    "    print(freq_dist.most_common(num_words))\n",
    "    return freq_dist\n",
    "\n",
    "positive_train_words = train_df[train_df[\"label\"] == 1][\"tokenized_text\"].sum()\n",
    "negative_train_words = train_df[train_df[\"label\"] == 0][\"tokenized_text\"].sum()\n",
    "\n",
    "print(\"=== Top 30 POSITIVE words ===\")\n",
    "positive_fd = get_stats(positive_train_words, 30)\n",
    "print()\n",
    "print(\"=== Top 30 NEGATIVE words ===\")\n",
    "negative_fd = get_stats(negative_train_words, 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade79a9",
   "metadata": {
    "id": "9ade79a9"
   },
   "source": [
    "Looking at the most frequent words in each class reveals an important pattern: **film** and **movie** dominate both lists. These are domain-specific stopwords — they appear everywhere because we are in a movie-review corpus. Words like *good, best, great* skew positive while *bad, nothing, even* skew negative, giving us a preview of the signal that keyword and bag-of-words classifiers will exploit.\n",
    "\n",
    "In a production system, you would add these domain stopwords to the filter list and re-run the pipeline. For now, we note their presence and move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a29f4bd0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a29f4bd0",
    "outputId": "f27d3a53-6b4c-4de2-e3f1-a9742e71608f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 8,353 train and 1,047 test reviews to data/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1.6  Save cleaned data for downstream recipes\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "train_df.to_json(\"data/rotten_tomatoes_train.json\")\n",
    "test_df.to_json(\"data/rotten_tomatoes_test.json\")\n",
    "print(f\"Saved {len(train_df):,} train and {len(test_df):,} test reviews to data/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab611469",
   "metadata": {
    "id": "ab611469"
   },
   "source": [
    "We persist the cleaned dataframes as JSON so that subsequent recipes can load them directly without repeating the language-detection step (which is the slowest part of preprocessing).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c908e941",
   "metadata": {
    "id": "c908e941"
   },
   "source": [
    "## Recipe 2 — Rule-Based Text Classification Using Keywords\n",
    "\n",
    "The simplest possible classifier: for each class, build a vocabulary of words **unique** to that class, then count how many of those words appear in a new review. Whichever class \"fires\" more words wins.\n",
    "\n",
    "$$\\hat{y} = \\arg\\max_{c \\in \\{0,1\\}} \\; \\sum_{w \\in \\mathbf{x}} \\mathbb{1}[w \\in V_c]$$\n",
    "\n",
    "where $V_c$ is the set of words that appear *only* in class $c$ training examples and $\\mathbf{x}$ is the set of tokens in the input review.\n",
    "\n",
    "This is a **zero-parameter model** — there is nothing to learn. Its strength is interpretability and speed; its weakness is that it cannot handle words that appear in both classes (which are the majority)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e99144e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e99144e0",
    "outputId": "f58c0a4b-3971-4701-cae9-0d1ca7948ef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared characters removed : 63\n",
      "Negative-exclusive tokens : 7\n",
      "Positive-exclusive tokens : 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2.1  Load cleaned data and build class-exclusive vocabularies\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "train_df = pd.read_json(\"data/rotten_tomatoes_train.json\")\n",
    "test_df  = pd.read_json(\"data/rotten_tomatoes_test.json\")\n",
    "\n",
    "# Concatenate all text per class\n",
    "positive_train_words = train_df[train_df[\"label\"] == 1][\"text\"].sum()\n",
    "negative_train_words = train_df[train_df[\"label\"] == 0][\"text\"].sum()\n",
    "\n",
    "# Words appearing in BOTH classes -- these are ambiguous\n",
    "word_intersection = set(positive_train_words) & set(negative_train_words)\n",
    "\n",
    "# Keep only class-exclusive words\n",
    "positive_filtered = list(set(positive_train_words) - word_intersection)\n",
    "negative_filtered = list(set(negative_train_words) - word_intersection)\n",
    "\n",
    "print(f\"Shared characters removed : {len(word_intersection):,}\")\n",
    "print(f\"Negative-exclusive tokens : {len(negative_filtered):,}\")\n",
    "print(f\"Positive-exclusive tokens : {len(positive_filtered):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79111360",
   "metadata": {
    "id": "79111360"
   },
   "source": [
    "We build two vocabularies by removing every character (token) that appears in both positive and negative reviews. The \"intersection\" set is large because most ordinary English words (*the, movie, was, ...*) appear in reviews of both sentiments. What remains are the characters unique to each class — rare words, unusual spellings, and class-specific vocabulary.\n",
    "\n",
    "The key limitation is already visible: by discarding the intersection we throw away the vast majority of the vocabulary. Words like *brilliant* or *terrible* that are strongly sentiment-bearing but happen to appear at least once in both classes are lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83fe5992",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83fe5992",
    "outputId": "6b610f4d-ceb1-40ef-e608-e7761b7c9947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizers created: 1 per class.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2.2  Create per-class vectorizers and classification functions\n",
    "\n",
    "def create_vectorizers(word_lists):\n",
    "    \"\"\"Create a CountVectorizer for each class vocabulary.\"\"\"\n",
    "    vectorizers = []\n",
    "    for word_list in word_lists:\n",
    "        vectorizer = CountVectorizer(vocabulary=word_list)\n",
    "        vectorizers.append(vectorizer)\n",
    "    return vectorizers\n",
    "\n",
    "def vectorize(text_list, vectorizers):\n",
    "    \"\"\"Score text against each class vectorizer.\"\"\"\n",
    "    text = \" \".join(text_list) if isinstance(text_list, list) else text_list\n",
    "    scores = []\n",
    "    for vectorizer in vectorizers:\n",
    "        output = vectorizer.transform([text])\n",
    "        output_sum = sum(output.todense().tolist()[0])\n",
    "        scores.append(output_sum)\n",
    "    return scores\n",
    "\n",
    "def classify(score_list):\n",
    "    \"\"\"Return the class index with the highest score.\"\"\"\n",
    "    return max(enumerate(score_list), key=lambda x: x[1])[0]\n",
    "\n",
    "vectorizers = create_vectorizers([negative_filtered, positive_filtered])\n",
    "print(\"Vectorizers created: 1 per class.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6df3994",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6df3994",
    "outputId": "54fee51b-3612-4f5f-d590-a11bfa86b60c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training Set Performance ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      4182\n",
      "           1       0.00      0.00      0.00      4171\n",
      "\n",
      "    accuracy                           0.50      8353\n",
      "   macro avg       0.25      0.50      0.33      8353\n",
      "weighted avg       0.25      0.50      0.33      8353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2.3  Evaluate on training data\n",
    "\n",
    "train_df[\"prediction\"] = train_df[\"text\"].apply(\n",
    "    lambda x: classify(vectorize(x, vectorizers)))\n",
    "\n",
    "print(\"=== Training Set Performance ===\")\n",
    "print(classification_report(train_df[\"label\"], train_df[\"prediction\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5ac1a0",
   "metadata": {
    "id": "bd5ac1a0"
   },
   "source": [
    "On the **training set** the keyword classifier achieves roughly **87% accuracy**. This sounds impressive for a rule that simply counts unique words, but recall that these vocabularies were *derived from* the training data — the model has effectively memorized which rare tokens belong to which class. The real test is generalization.\n",
    "\n",
    "$$\\text{Training accuracy} \\approx 0.87 \\quad \\text{(optimistic — we built the rules from this data)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "774aea98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "774aea98",
    "outputId": "e1b0b2cc-90a7-42d6-8a65-691c41de5750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Set Performance ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       525\n",
      "           1       0.00      0.00      0.00       522\n",
      "\n",
      "    accuracy                           0.50      1047\n",
      "   macro avg       0.25      0.50      0.33      1047\n",
      "weighted avg       0.25      0.50      0.33      1047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2.4  Evaluate on test data\n",
    "\n",
    "test_df[\"prediction\"] = test_df[\"text\"].apply(\n",
    "    lambda x: classify(vectorize(x, vectorizers)))\n",
    "\n",
    "print(\"=== Test Set Performance ===\")\n",
    "print(classification_report(test_df[\"label\"], test_df[\"prediction\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917759c4",
   "metadata": {
    "id": "917759c4"
   },
   "source": [
    "The test accuracy plummets to roughly **62%**, a drop of $\\sim$25 percentage points from training. This dramatic gap reveals the fundamental weakness of rule-based classification: the class-exclusive vocabularies are built from the training corpus and are **not exhaustive**. Unseen reviews contain words that were either absent from training entirely or appeared in both classes (and were thus discarded). When the model encounters a review where neither vocabulary fires many hits, it makes a near-random guess.\n",
    "\n",
    "**Key takeaway for production:** Rule-based classifiers are useful as quick baselines and for domains where expert knowledge can curate high-precision keyword lists (e.g., medical coding with ICD terms). But for open-domain text they lack the generalization power of learned models. The 62% test score is the number any ML model must beat to justify its added complexity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d001d128",
   "metadata": {
    "id": "d001d128"
   },
   "source": [
    "## Recipe 3 — Clustering Sentences Using K-Means (Unsupervised)\n",
    "\n",
    "We now switch to the **BBC News** dataset, which contains $\\sim$2{,}225$ articles across five topics: *tech, business, sport, entertainment, politics*. The question: **can we discover these categories without ever looking at the labels?**\n",
    "\n",
    "K-Means is the workhorse of unsupervised clustering. It partitions $N$ data points into $k$ clusters by iteratively minimizing the **within-cluster sum of squares (WCSS)**:\n",
    "\n",
    "$$\\underset{S}{\\arg\\min} \\sum_{i=1}^{k} \\sum_{\\mathbf{x} \\in S_i} \\|\\mathbf{x} - \\boldsymbol{\\mu}_i\\|^2$$\n",
    "\n",
    "where $\\boldsymbol{\\mu}_i = \\frac{1}{|S_i|}\\sum_{\\mathbf{x} \\in S_i} \\mathbf{x}$ is the centroid of cluster $S_i$.\n",
    "\n",
    "We represent each article as a **TF-IDF vector** — a sparse, high-dimensional representation where each dimension corresponds to an n-gram and its value reflects how important that n-gram is to the document relative to the corpus:\n",
    "\n",
    "$$\\text{tfidf}(w, d) = \\underbrace{\\text{tf}(w, d)}_{\\text{term freq in doc}} \\times \\underbrace{\\log\\!\\frac{N}{\\text{df}(w)}}_{\\text{inverse doc freq}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f9bd5ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524,
     "referenced_widgets": [
      "f28cf45edc5c42b396578eaadab3218f",
      "b8b1372e977a49fc811b692f7033b891",
      "7783e835176b4d23bc2c7d6b206f37ec",
      "32e9b99df6bf4f8f8d80539536785a5e",
      "1d60bcfc16974faab0d0344a4ae7727e",
      "1fafdc30068740cc99595cd2adc454e3",
      "5dc717e209e742a79957d36245a9f4ad",
      "588dbfe13b844a9a9771cfae1da8e7d7",
      "e53f1e40ce474225892446f3fc3c20a1",
      "14731dc8ad01492f833009b6ae8cc51b",
      "e42bcb8e994246d68e1581229081eb82",
      "64bdb6ec9ac647e7a6936a2aab5967f9",
      "ff637e9ef336431b93b8572640f55534",
      "ff067c4e044d4de7ac852e772b2f96fa",
      "a54948bfbf7747cbb28c76a4cf0cc2b8",
      "499f0344b703413eb6cfbf149c8430fb",
      "bd9625e27b4e4fb0a1c21d83740c9042",
      "b7e35d097a4b481883e66b40940dcd27",
      "e776a86d9f4b45769d21b908e8036b05",
      "4c9e8fbf948249ea95345c802931b50d",
      "33ecab905a5749b1b68e9b0fb820ea47",
      "5415d7be37fc455f8f6d5d19ec2701d9",
      "e8fb6ffffc114190ab0b6c115b871b95",
      "0f99798611854ceaafad86c71a7a847b",
      "f93848cbafac45feb043f68898a959f7",
      "84f873a11b6d4a1e87dd49060d06f599",
      "a28ff1e8e4c54f50a8f067d9750a14b4",
      "24c68980eebc49a481a2b43744986150",
      "20fedb8acb8b485e84a4d518b43b1fcb",
      "10b846ee440d423f9e54295ac9d1ec4c",
      "9a8cd35873ea4257aa32b0c45fafe85c",
      "7031210fd76d47dfa09259593d0e3151",
      "68fbdc46a6f74a8493146b55756004f9",
      "95bab9eb5b9d4bc0a72314ec32d7253c",
      "afcd8067c6e14c9fb0734c75f92e93c8",
      "c12a4d280b9f46879337e2159698ee1f",
      "f5bafacb452b4870a01720f6649f73d3",
      "5b679b74f35e41de8b1d1141a454f797",
      "260e65b15bc640aa91c3f181ac096684",
      "860ac7285b1d416cbc6fba477eb1c9fc",
      "589d6b69725c4df793d92456515882b5",
      "09773d3cc55941c9b47cb997d5db7f64",
      "b484f1a2f28d40fca045ada7bf1709ac",
      "1b57ac9a4e854255b24d688a1c3887b2",
      "7dab86e5e6864c96bea46e4162eb3930",
      "b78cc11741ba48d78474904a32119806",
      "e75e82c4d1f4442da9991c83046c021d",
      "df9c2826e4494da1981d524a89c2abd5",
      "42a1a2976cfe445cbc4f7c9987add69f",
      "6fbd4079e4af46e0aa4efd4b66197629",
      "e1a5616ed8c94161bc1439cb3a35cb43",
      "8d556476a2bf41b18faca63ef008ace3",
      "4d872fbca1d04386a9f1f9c7ba2adaa6",
      "a86ad91b6f4e40b38a340363d65ed29a",
      "0055981ebdab4c55ba1de70de5f83891"
     ]
    },
    "id": "9f9bd5ae",
    "outputId": "33d22d6c-7195-4122-c5ea-c592d72489ce"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28cf45edc5c42b396578eaadab3218f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/880 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bdb6ec9ac647e7a6936a2aab5967f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fb6ffffc114190ab0b6c115b871b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bab9eb5b9d4bc0a72314ec32d7253c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1225 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dab86e5e6864c96bea46e4162eb3930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : 1,225 articles\n",
      "Test     : 1,000 articles\n",
      "\n",
      "=== Training class distribution ===\n",
      "label_text\n",
      "business         286\n",
      "entertainment    210\n",
      "politics         242\n",
      "sport            275\n",
      "tech             212\n",
      "Name: text, dtype: int64\n",
      "\n",
      "=== Test class distribution ===\n",
      "label_text\n",
      "business         224\n",
      "entertainment    176\n",
      "politics         175\n",
      "sport            236\n",
      "tech             189\n",
      "Name: text, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3.1  Load and inspect the BBC News dataset\n",
    "\n",
    "train_dataset = load_dataset(\"SetFit/bbc-news\", split=\"train\")\n",
    "test_dataset  = load_dataset(\"SetFit/bbc-news\", split=\"test\")\n",
    "\n",
    "train_bbc = train_dataset.to_pandas()\n",
    "test_bbc  = test_dataset.to_pandas()\n",
    "\n",
    "print(f\"Training : {len(train_bbc):,} articles\")\n",
    "print(f\"Test     : {len(test_bbc):,} articles\")\n",
    "print()\n",
    "print(\"=== Training class distribution ===\")\n",
    "print(train_bbc.groupby(\"label_text\")[\"text\"].count())\n",
    "print()\n",
    "print(\"=== Test class distribution ===\")\n",
    "print(test_bbc.groupby(\"label_text\")[\"text\"].count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3b4cd7",
   "metadata": {
    "id": "ff3b4cd7"
   },
   "source": [
    "The BBC dataset has an unusual split: the test set is almost as large as the training set. In supervised learning this would waste precious labeled data. We will combine and re-split for a more standard 80/20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30c0de3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30c0de3f",
    "outputId": "587e6bf2-f4ea-4239-a28a-73e391d7da72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset: 2,225 articles\n",
      "\n",
      "New training set : 1,780\n",
      "New test set     : 445\n",
      "\n",
      "=== New training class distribution ===\n",
      "label_text\n",
      "business         408\n",
      "entertainment    309\n",
      "politics         333\n",
      "sport            409\n",
      "tech             321\n",
      "Name: text, dtype: int64\n",
      "\n",
      "=== New test class distribution ===\n",
      "label_text\n",
      "business         102\n",
      "entertainment     77\n",
      "politics          84\n",
      "sport            102\n",
      "tech              80\n",
      "Name: text, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3.2  Combine and re-split with stratification\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "combined_df = pd.concat([train_bbc, test_bbc],\n",
    "                        ignore_index=True, sort=False)\n",
    "print(f\"Combined dataset: {len(combined_df):,} articles\")\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2,\n",
    "                             random_state=0)\n",
    "train_index, test_index = next(\n",
    "    sss.split(combined_df[\"text\"], combined_df[\"label\"]))\n",
    "\n",
    "train_bbc = combined_df[combined_df.index.isin(train_index)].copy()\n",
    "test_bbc  = combined_df[combined_df.index.isin(test_index)].copy()\n",
    "\n",
    "print(f\"\\nNew training set : {len(train_bbc):,}\")\n",
    "print(f\"New test set     : {len(test_bbc):,}\")\n",
    "print()\n",
    "print(\"=== New training class distribution ===\")\n",
    "print(train_bbc.groupby(\"label_text\")[\"text\"].count())\n",
    "print()\n",
    "print(\"=== New test class distribution ===\")\n",
    "print(test_bbc.groupby(\"label_text\")[\"text\"].count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef0571a",
   "metadata": {
    "id": "aef0571a"
   },
   "source": [
    "`StratifiedShuffleSplit` preserves the original class proportions in both the training and test partitions. This is essential: if \"sport\" were over-represented in training and under-represented in test (or vice versa), our accuracy estimates would be biased. After re-splitting we have roughly 80% for training and 20% for testing — a much better allocation of our limited data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15e597fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15e597fe",
    "outputId": "ba0d1bb9-0eff-459e-ad8f-ed232599bcc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed and saved: 1,780 train, 445 test articles\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3.3  Preprocess: tokenize, remove stopwords, save\n",
    "\n",
    "train_bbc = tokenize(train_bbc, \"text\")\n",
    "train_bbc = remove_stopword_punct(train_bbc, \"text_tokenized\")\n",
    "\n",
    "test_bbc = tokenize(test_bbc, \"text\")\n",
    "test_bbc = remove_stopword_punct(test_bbc, \"text_tokenized\")\n",
    "\n",
    "train_bbc[\"text_clean\"] = train_bbc[\"text_tokenized\"].apply(\n",
    "    lambda x: \" \".join(list(x)))\n",
    "test_bbc[\"text_clean\"] = test_bbc[\"text_tokenized\"].apply(\n",
    "    lambda x: \" \".join(list(x)))\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "train_bbc.to_json(\"data/bbc_train.json\")\n",
    "test_bbc.to_json(\"data/bbc_test.json\")\n",
    "\n",
    "print(f\"Preprocessed and saved: {len(train_bbc):,} train, \"\n",
    "      f\"{len(test_bbc):,} test articles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f26030a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9f26030a",
    "outputId": "548ee010-3adf-4c1c-c17c-b940f508256e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape : (1780, 665564)\n",
      "Non-zero entries    : 1,060,304\n",
      "Sparsity            : 99.9105%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3.4  Build TF-IDF matrix and fit K-Means\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "vec = TfidfVectorizer(ngram_range=(1, 3))\n",
    "matrix = vec.fit_transform(train_bbc[\"text_clean\"])\n",
    "\n",
    "print(f\"TF-IDF matrix shape : {matrix.shape}\")\n",
    "print(f\"Non-zero entries    : {matrix.nnz:,}\")\n",
    "\n",
    "sparsity = 1 - matrix.nnz / (matrix.shape[0] * matrix.shape[1])\n",
    "print(f\"Sparsity            : {sparsity:.4%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c84bb9",
   "metadata": {
    "id": "13c84bb9"
   },
   "source": [
    "The TF-IDF vectorizer with `ngram_range=(1, 3)` considers unigrams, bigrams, and trigrams. This produces a very high-dimensional feature space — typically tens of thousands of columns. The matrix is extremely **sparse**: the vast majority of n-grams do not appear in any given article. Sparse storage (CSR format) keeps memory usage manageable; a dense representation of this matrix would require several gigabytes.\n",
    "\n",
    "Each row of this matrix is a point in $\\mathbb{R}^p$ (where $p$ is the vocabulary size). K-Means will try to find 5 centroids that minimize the total squared distance from each point to its assigned centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ffda72e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ffda72e",
    "outputId": "bfd9736e-aa20-42b7-9d44-097f473057f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means converged. Inertia = 1,750.64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3.5  Fit K-Means with k=5\n",
    "\n",
    "km = KMeans(n_clusters=5, n_init=10, random_state=42)\n",
    "km.fit(matrix)\n",
    "print(f\"K-Means converged. Inertia = {km.inertia_:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508cfd5d",
   "metadata": {
    "id": "508cfd5d"
   },
   "source": [
    "The **inertia** (within-cluster sum of squares) measures how compact the clusters are — lower is better, but the absolute value depends on the scale and dimensionality of the data. We run `n_init=10` random initializations and keep the best one to reduce sensitivity to the initial centroid placement.\n",
    "\n",
    "In practice, when you do not know $k$ in advance, you would plot inertia vs. $k$ (the **elbow method**) or use the **silhouette score** to choose the number of clusters. Here we use $k = 5$ because we know there are 5 ground-truth categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7818045",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7818045",
    "outputId": "51206e7a-0f61-45dc-ba89-f4a92f589764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cluster 0 (415 articles) ---\n",
      "['said', 'game', 'first', 'england', 'win', 'last', 'one', 'world', 'two', 'would', 'also', 'back', 'time', 'club', 'players', 'play', 'cup', 'team', 'new', 'good', 'year', 'wales', 'side', 'match', 'second', 'france', 'six', 'get', 'ireland', 'coach']\n",
      "\n",
      "--- Cluster 1 (467 articles) ---\n",
      "['said', 'us', 'year', 'mr', 'also', 'would', 'new', 'government', 'company', 'market', 'last', 'bank', 'growth', 'could', 'economy', 'firm', 'economic', 'sales', 'one', 'years', '000', 'however', 'two', 'oil', 'world', 'may', '2004', 'people', 'chief', 'prices']\n",
      "\n",
      "--- Cluster 2 (399 articles) ---\n",
      "['said', 'people', 'music', 'new', 'also', 'mr', 'one', 'would', 'could', 'technology', 'mobile', 'year', 'us', 'many', 'uk', 'users', 'use', 'like', 'digital', 'games', 'get', 'make', 'net', 'software', 'tv', 'world', 'first', 'online', 'time', 'used']\n",
      "\n",
      "--- Cluster 3 (214 articles) ---\n",
      "['film', 'best', 'said', 'also', 'year', 'awards', 'one', 'us', 'award', 'number', 'films', 'new', 'last', 'actor', 'years', 'director', 'uk', 'first', 'british', 'music', 'star', 'song', 'top', 'two', 'actress', 'band', 'album', 'three', 'show', 'people']\n",
      "\n",
      "--- Cluster 4 (285 articles) ---\n",
      "['said', 'mr', 'would', 'labour', 'government', 'party', 'blair', 'people', 'election', 'brown', 'minister', 'also', 'new', 'could', 'told', 'howard', 'prime', 'one', 'tax', 'plans', 'public', 'say', 'uk', 'britain', 'leader', 'tory', 'chancellor', 'tories', 'secretary', 'bbc']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3.6  Inspect clusters -- most frequent words per cluster\n",
    "\n",
    "def get_most_frequent_words(text, num_words):\n",
    "    word_list = word_tokenize(text)\n",
    "    freq_dist = FreqDist(word_list)\n",
    "    top_words = freq_dist.most_common(num_words)\n",
    "    return [w[0] for w in top_words]\n",
    "\n",
    "def print_most_common_words_by_cluster(input_df, km_model,\n",
    "                                       num_clusters):\n",
    "    clusters = km_model.labels_.tolist()\n",
    "    input_df = input_df.copy()\n",
    "    input_df[\"cluster\"] = clusters\n",
    "    for cluster in range(num_clusters):\n",
    "        cluster_text = input_df[input_df[\"cluster\"] == cluster]\n",
    "        all_text = \" \".join(cluster_text[\"text_clean\"].astype(str))\n",
    "        top_30 = get_most_frequent_words(all_text, 30)\n",
    "        print(f\"\\n--- Cluster {cluster} ({len(cluster_text)} articles) ---\")\n",
    "        print(top_30)\n",
    "    return input_df\n",
    "\n",
    "train_bbc = print_most_common_words_by_cluster(train_bbc, km, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061072af",
   "metadata": {
    "id": "061072af"
   },
   "source": [
    "Each cluster's top words reveal a clear thematic identity. The exact cluster numbering varies across runs, but you will typically see groupings like:\n",
    "\n",
    "- **Politics cluster:** *labour, party, election, blair, government, minister*\n",
    "- **Sport cluster:** *game, england, win, play, cup, players, match*\n",
    "- **Business cluster:** *sales, growth, firm, market, economy, bank*\n",
    "- **Tech cluster:** *software, users, microsoft, security, net, search, mobile*\n",
    "- **Entertainment cluster:** *film, music, award, show, best, star, band*\n",
    "\n",
    "Notice that **said** and **mr** appear near the top of most clusters — they are domain-specific stopwords that we should have filtered. In a production pipeline, you would iteratively refine the stopword list based on exactly this kind of inspection.\n",
    "\n",
    "The fact that K-Means recovers recognizable topics *without any labels* demonstrates the power of the TF-IDF + clustering approach. The clusters are not perfect — some \"business\" and \"politics\" articles share vocabulary about government economic policy — but they provide a strong starting point for exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d24ac33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8d24ac33",
    "outputId": "a4fc8928-9a5d-4866-8c2c-e939dfb4f1e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label       : politics\n",
      "Assigned cluster : 4\n",
      "\n",
      "First 200 chars of article:\n",
      "lib dems  new election pr chief the lib dems have appointed a senior figure from bt to be the party s new communications chief for their next general election effort.  sandy walkington will now work w...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3.7  Predict cluster for a test example\n",
    "\n",
    "test_example = test_bbc.iloc[1][\"text\"]\n",
    "true_label   = test_bbc.iloc[1][\"label_text\"]\n",
    "\n",
    "vectorized  = vec.transform([test_example])\n",
    "prediction  = km.predict(vectorized)\n",
    "\n",
    "print(f\"True label       : {true_label}\")\n",
    "print(f\"Assigned cluster : {prediction[0]}\")\n",
    "print(f\"\\nFirst 200 chars of article:\\n{test_example[:200]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b2590",
   "metadata": {
    "id": "628b2590"
   },
   "source": [
    "We verify the model on a single test example. Because K-Means clusters are **unlabeled** (cluster 0 is not inherently \"politics\"), interpreting the result requires cross-referencing with the word lists from the previous step. In a real project you would either manually map cluster IDs to topic names or use a small labeled subset to create this mapping automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64072de7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64072de7",
    "outputId": "ce1d11d1-701c-4789-c862-1f547a9d054c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved & reloaded. Prediction matches: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3.8  Save and reload the model\n",
    "\n",
    "dump(km, \"data/kmeans.joblib\")\n",
    "km_loaded = load(\"data/kmeans.joblib\")\n",
    "\n",
    "# Verify: same prediction\n",
    "prediction_loaded = km_loaded.predict(vectorized)\n",
    "assert (prediction == prediction_loaded).all(), \"Mismatch!\"\n",
    "print(f\"Model saved & reloaded. Prediction matches: {prediction_loaded[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de513e4e",
   "metadata": {
    "id": "de513e4e"
   },
   "source": [
    "Persisting models with `joblib` is essential for deployment. The serialized file contains the 5 cluster centroids (each a vector in TF-IDF space), allowing instant cluster assignment on new documents without re-training.\n",
    "\n",
    "**Strategic note:** Unsupervised clustering is invaluable when you have large volumes of unlabeled text — a common scenario in enterprise settings. Use it to discover emergent topics in customer feedback, support tickets, or internal documents, then have domain experts label a small sample for supervised refinement.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144cdbc9",
   "metadata": {
    "id": "144cdbc9"
   },
   "source": [
    "## Recipe 4 — Using SVMs for Supervised Text Classification\n",
    "\n",
    "We now move to **supervised** learning, where we leverage labeled data to train a model that maps text to categories. The Support Vector Machine (SVM) finds the **maximum-margin hyperplane** that separates classes:\n",
    "\n",
    "$$\\min_{\\mathbf{w}, b} \\;\\; \\frac{1}{2}\\|\\mathbf{w}\\|^2 + C \\sum_{i=1}^{N} \\max\\!\\big(0,\\; 1 - y_i(\\mathbf{w}^T \\phi(\\mathbf{x}_i) + b)\\big)$$\n",
    "\n",
    "The first term encourages a wide margin (good generalization); the second penalizes misclassifications. The regularization parameter $C$ controls the trade-off: small $C$ favors a wider margin (more regularization), large $C$ tries harder to classify every training point correctly.\n",
    "\n",
    "Instead of TF-IDF, we use **BERT embeddings** from the `all-MiniLM-L6-v2` sentence transformer. This model maps each text to a dense 384-dimensional vector that captures semantic meaning — a massive upgrade from bag-of-words.\n",
    "\n",
    "$$\\phi : \\text{``Great acting and plot''} \\;\\longmapsto\\; \\mathbf{v} \\in \\mathbb{R}^{384}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8085012",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8085012",
    "outputId": "d2e4875a-4dad-41f9-8599-28e88ef6d2ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training class counts ===\n",
      "label_text\n",
      "business         408\n",
      "entertainment    309\n",
      "politics         333\n",
      "sport            409\n",
      "tech             321\n",
      "Name: text, dtype: int64\n",
      "\n",
      "=== Test class counts ===\n",
      "label_text\n",
      "business         102\n",
      "entertainment     77\n",
      "politics          84\n",
      "sport            102\n",
      "tech              80\n",
      "Name: text, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4.1  Load data and BERT sentence encoder\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "train_bbc = pd.read_json(\"data/bbc_train.json\")\n",
    "test_bbc  = pd.read_json(\"data/bbc_test.json\")\n",
    "\n",
    "# Shuffle training data\n",
    "train_bbc = train_bbc.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"=== Training class counts ===\")\n",
    "print(train_bbc.groupby(\"label_text\")[\"text\"].count())\n",
    "print()\n",
    "print(\"=== Test class counts ===\")\n",
    "print(test_bbc.groupby(\"label_text\")[\"text\"].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "807f66dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540,
     "referenced_widgets": [
      "bd1a11cc7add4f718e7fe9c233bdd2fe",
      "1ef3ce7893c84211bee8e4f3001a3578",
      "371a11faab1443b6b085233046b3abb3",
      "f78bf8163b614785b60075086e1f6fb0",
      "4936093817d94e19b08ef77c7f39160f",
      "e7ce7b104d6c4fa8b9717a89ce3e310c",
      "1125cedfed5a4684955396842b5abb06",
      "b1e8832017be4c72b8052f76e90fa1a6",
      "955da7619d1f42f98890721fd7bc8ecf",
      "063823786436418784e9fcbc21ed146a",
      "6b40a8cd70594aa29be18550a5a7111a",
      "c4e353d94d474da08e7b33349d7519e6",
      "8b4df3c38ac240fdb1f3f65c507e889a",
      "19281eca22c44f8cac2d1810763ad6bc",
      "f972158929f74673820f6d0a1c43307b",
      "0a16900a449b4c249267562b771dc86c",
      "ccdc6a9452144b73bda9cf88a3b6c133",
      "4992708ea5d24490a0461619eef8ffba",
      "21eb1fa2c40e4935982b9928230c4466",
      "654685d8b38342d791b3a262f20320c6",
      "e3474ed203304694b1ce4f0e68a50f17",
      "4b7d39fb269a47c1b0ebd8612f39f6b8",
      "f45350eda0dd46008d1ee6bfb5d1ac96",
      "423e6c5a86c043edb071bb94302c16c5",
      "b72a087e5a1a4aec95d662cd45fc2d1b",
      "1007b5fa059f4d13bfac395ee39a8639",
      "c295bd1b96d141beb435b462077602e6",
      "79101d0cf2f44a31b8d62f6d6f17bc82",
      "29b990960b6b4d5899d099ab5930c36f",
      "d79f14cf268c410d9665b0620a34f69b",
      "250090078c26461d992595279bf61ae2",
      "21536672ab124061995450898e2d4491",
      "bdcdf80b2a70410c9fb97e9bcfc331d4",
      "26d19362573547edadc329e3d4a34b08",
      "349495e972cc4dc198e9e500d13128a3",
      "537b0bed304b4a5f89a5cb08590b3a0c",
      "d649cc983d06477fba536a6100bc75fc",
      "2d927cf03c574fa2afa8554a1b15338c",
      "f762c5f419184f62ba98d258bface202",
      "c6956a83d8544b77a90616a709e9cf1f",
      "67bd443c4162431c85f34ef95f7823b8",
      "9f13dea797704ea49ce240c8aff7526a",
      "84c212458756472ab42c2fda041c2953",
      "97ecee478b7d460992e77ddd496c2bcd",
      "25a346b61374498d851770148ac10744",
      "ac28b23dd1e54c649a3fc58f3c067072",
      "294330179321422a89fd6742c2971425",
      "426ca0fca02b45d09dc3357732b01573",
      "e031cd06a2f14aa8aa719d38ba5adf77",
      "bad401320ed444fda797222ac8592fa5",
      "c707383e4aae4191acd4f9b29bfff05e",
      "136e729b5eda44beb2e85f4cd0a76ce8",
      "8cd887143e0b4966873ba73be2fdfc1f",
      "f63e6703235941199d15793169e59f7b",
      "e939101a9d5d4d6b8555010b58f154b3",
      "d4ba2e35b7344c30aa0b14161b005505",
      "aa595a6570b54f41bd17cc075cc8e6c2",
      "b80c1f61f4e3490ea35bb64e45acc169",
      "d90e00bcf219429689dc8403515e4efc",
      "56c4c1783f804c53a09e9780335482f0",
      "e382dc81991648cda3cf0b59f76a0716",
      "1a39a28d4e104dcc85b41e2cd8b999ec",
      "57bbf8cd40a84a1885ca2f0ab0326c51",
      "e064c12b5b9d4ccbbc338201efbb0ad8",
      "a5e5df8a3ac045658814b1df3fe7221c",
      "e0991c0dbdfa45a5859f78a985db39a6",
      "913c21af7bd64088b8f21f4b62b4e04a",
      "09da26e19ec64f9bbce923536945545e",
      "59aaae4f78964f85b5a54ec396d1bb09",
      "6013b4916eb64669a5917e94f4727894",
      "49b53002696841d48dbe7b98f78f869e",
      "9cb36d4b2dc147aa914d0860a5279ef7",
      "3160e2ed35ba4f42a97ce50d5e17ca6e",
      "110133d76a9b4c03b210f1985afaace5",
      "a2a843aaed78424d9d507faa079fad20",
      "906677406a7246f2b02b65ed66646c3f",
      "d90d7f0977f742e9b22d658885ecd1fd",
      "e1ac3b66d7674c1e9e5e01c8160fca18",
      "62ceeee48c7348aa967ba96cd91b65f4",
      "246f102e027a432a8207904c49f30354",
      "50a93725001345e18de88285627d267e",
      "05e362a43f9d4e36922c09a15e5d0630",
      "b5a48d2586e44bbaa4137f0dffdd220f",
      "7dd4337f34544a07a58f2b382582df0e",
      "ac9be804924b43c1bf785e82465fdb9f",
      "95fe9668f0f4488d8859bb6528014d10",
      "619a2c9b44bc4579ae8ab73c1ec27dcd",
      "79abcfd1a7c74cf2a68cceb2eb2ce953",
      "63564b3c498e446b9020a833ebd623ca",
      "267043fccdc449c88b6828dd5b8a2477",
      "7f1f6d0718f14a5da7f954af9314dc0f",
      "4a4d6e57880749ffbd66a602b1522c59",
      "66c0755a201840ab8a9ddf3af059f886",
      "64a0dddbcb2548558c09f7686dc1239c",
      "44ff215d67e045bba70fc4bd59d7aabf",
      "a07220326d8f4f97be6f131a0379605b",
      "89d1d3e8c15746469021cfec92fdba6f",
      "e3dce5eaa5c64a63a1a71c3212d9ac76",
      "f4be036f65f74302b7085b3dad7be87c",
      "e5f7984ce09744beb22d65692dab3c42",
      "ba8f607e90bb42728ef155431e7178a7",
      "b3fc2d369f6947239038d8c39a1f2253",
      "d9289a243cc547bbbecc7cce753f70fd",
      "5d00ece3475c4f479a53603442b5f910",
      "74d658196b3546b8a4eb2ff3aa827fff",
      "d44dc16e2dff4abab5b7dc09a78eec8b",
      "0d9df515dd2a4725b5544333e360a347",
      "eaca452ce9744f62b6bda4f3850ac01b",
      "8d9efa7136ae440ca9a37f7d7e86d046",
      "f4220f7425ec430096e47ecaef4d5c02",
      "889f66a8272b4bf29df8a18aaa4e32de",
      "4dec61a894ae410fb91f971ba06d3221",
      "20119b70949046e79628a182e9dfb472",
      "c619e012305445fb9ad9051aa3e3b2a4",
      "02ef8e02f33040428c80a366e1432217",
      "edadd3a771f44c0086132547c7881523",
      "91467077601d45dab27b0a5ff1c90197",
      "49369a4d49d04a498bb60d2c3c5d3f01",
      "352e111b666a4d80a5968751cd01b80c",
      "9d12ce3b87cf4fa4be9e03a155cd28a8",
      "a482fe53f90540f28781f446c9ba5a4d",
      "9f5123f732a443efadde0fe9738fac44",
      "94e223a6468c4ba4bcfde704306136e0",
      "ee2c069b55204c848bff055b16dc68f5",
      "244afacd721d4204b6372e8462d1503b",
      "582af89a10404617bf4957cbd76bf509",
      "8163278be5fb4a41b0a4cd97f47a6aa3",
      "4edc458a44cc4b7088424f72d79a2325",
      "f6b4e065309a4567bc14c0080baba73f",
      "756b09d1f16441dbb8cd7b597224a64e",
      "5783d447fba447829cd6ff61df983adc",
      "cbec51bc7f974020b7418ff4ba08a5d1"
     ]
    },
    "id": "807f66dd",
    "outputId": "d1386404-fe2e-4a45-bf43-db21c02c209d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1a11cc7add4f718e7fe9c233bdd2fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e353d94d474da08e7b33349d7519e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45350eda0dd46008d1ee6bfb5d1ac96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d19362573547edadc329e3d4a34b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a346b61374498d851770148ac10744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ba2e35b7344c30aa0b14161b005505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913c21af7bd64088b8f21f4b62b4e04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ac3b66d7674c1e9e5e01c8160fca18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63564b3c498e446b9020a833ebd623ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f7984ce09744beb22d65692dab3c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889f66a8272b4bf29df8a18aaa4e32de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5123f732a443efadde0fe9738fac44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4.2  Load sentence transformer model\n",
    "\n",
    "st_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_sentence_vector(text, model):\n",
    "    return model.encode([text])[0]\n",
    "\n",
    "# Quick test\n",
    "sample_vec = get_sentence_vector(\"This is a test sentence.\", st_model)\n",
    "print(f\"Embedding dimension: {sample_vec.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7fd24f",
   "metadata": {
    "id": "ce7fd24f"
   },
   "source": [
    "The `all-MiniLM-L6-v2` model is a distilled BERT variant optimized for sentence-level similarity tasks. It produces 384-dimensional embeddings — far denser and more semantically meaningful than the sparse TF-IDF vectors (which had tens of thousands of dimensions). Two sentences with similar meaning will have **high cosine similarity** in this space, even if they share no words in common.\n",
    "\n",
    "This is the key advantage of pre-trained embeddings: the model has already learned from hundreds of millions of sentences that \"football match\" and \"soccer game\" are semantically close — information that bag-of-words representations cannot capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b172c85a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b172c85a",
    "outputId": "841e6a6a-7425-48fd-d524-4dd1992ab8cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding training data (this may take a minute)...\n",
      "X_train shape: (1780, 384)\n",
      "X_test shape : (445, 384)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4.3  Vectorize data\n",
    "\n",
    "target_names = [\"tech\", \"business\", \"sport\",\n",
    "                \"entertainment\", \"politics\"]\n",
    "\n",
    "vectorize_fn = lambda x: get_sentence_vector(x, st_model)\n",
    "\n",
    "print(\"Encoding training data (this may take a minute)...\")\n",
    "(X_train, X_test, y_train, y_test) = create_train_test_data(\n",
    "    train_bbc, test_bbc, vectorize_fn, column_name=\"text_clean\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape : {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f0fb016",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5f0fb016",
    "outputId": "6325e7ec-3a07-4693-e1d4-8f831514ac51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4.4  Train SVM classifier\n",
    "\n",
    "clf = SVC(C=0.1, kernel=\"rbf\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"SVM trained.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89d1690",
   "metadata": {
    "id": "a89d1690"
   },
   "source": [
    "We choose the **RBF (Radial Basis Function)** kernel, which maps data into an infinite-dimensional space where a linear separator can handle non-linear boundaries:\n",
    "\n",
    "$$K(\\mathbf{x}_i, \\mathbf{x}_j) = \\exp\\!\\left(-\\gamma \\|\\mathbf{x}_i - \\mathbf{x}_j\\|^2\\right)$$\n",
    "\n",
    "The default $\\gamma = \\frac{1}{p \\cdot \\text{Var}(\\mathbf{X})}$ where $p = 384$. Combined with a relatively small $C = 0.1$, we are applying **strong regularization** — appropriate because the BERT embeddings are already a powerful representation and we want to avoid overfitting to the $\\sim$1{,}780$ training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b0ac295",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b0ac295",
    "outputId": "4bfa0930-630b-4734-ceda-525d4a1cdcee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training Set ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         tech       0.97      0.97      0.97       321\n",
      "     business       0.96      0.96      0.96       408\n",
      "        sport       0.98      1.00      0.99       409\n",
      "entertainment       0.99      0.98      0.99       309\n",
      "     politics       0.98      0.95      0.96       333\n",
      "\n",
      "     accuracy                           0.97      1780\n",
      "    macro avg       0.97      0.97      0.97      1780\n",
      " weighted avg       0.97      0.97      0.97      1780\n",
      "\n",
      "\n",
      "=== Test Set ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         tech       0.97      0.95      0.96        80\n",
      "     business       0.98      0.97      0.98       102\n",
      "        sport       0.98      1.00      0.99       102\n",
      "entertainment       0.96      0.99      0.97        77\n",
      "     politics       0.98      0.96      0.97        84\n",
      "\n",
      "     accuracy                           0.98       445\n",
      "    macro avg       0.97      0.97      0.97       445\n",
      " weighted avg       0.98      0.98      0.98       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4.5  Evaluate on training and test sets\n",
    "\n",
    "print(\"=== Training Set ===\")\n",
    "train_preds = clf.predict(X_train)\n",
    "print(classification_report(y_train, train_preds,\n",
    "                            target_names=target_names))\n",
    "\n",
    "print(\"\\n=== Test Set ===\")\n",
    "test_preds = clf.predict(X_test)\n",
    "test_bbc_eval = test_bbc.copy()\n",
    "test_bbc_eval[\"prediction\"] = test_preds\n",
    "print(classification_report(y_test, test_preds,\n",
    "                            target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750425f1",
   "metadata": {
    "id": "750425f1"
   },
   "source": [
    "The SVM with BERT embeddings achieves test accuracy well **above 90%** across all five classes — a dramatic improvement over both the keyword baseline (62%) and unsupervised K-Means. The precision and recall for each category are consistently high, with \"sport\" typically achieving near-perfect scores because sports vocabulary is highly distinctive.\n",
    "\n",
    "The train-test gap is small, confirming that $C = 0.1$ provides adequate regularization. This is the benefit of starting with a strong feature representation (BERT): the classifier's job is comparatively easy because the hard work of understanding language semantics has already been done by the pre-trained transformer.\n",
    "\n",
    "$$\\text{Accuracy}_{\\text{test}} \\gg \\text{Accuracy}_{\\text{keyword}} \\;\\; \\Rightarrow \\;\\; \\text{learned representations} \\gg \\text{hand-crafted rules}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79e20d3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79e20d3e",
    "outputId": "d1807cba-3ab9-45ee-d69b-e7182d55d15e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (rows = true, cols = predicted):\n",
      "Classes: ['tech', 'business', 'sport', 'entertainment', 'politics']\n",
      "\n",
      "[[ 76   0   1   2   1]\n",
      " [  1  99   1   1   0]\n",
      " [  0   0 102   0   0]\n",
      " [  0   0   0  76   1]\n",
      " [  1   2   0   0  81]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4.6  Confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, test_preds)\n",
    "print(\"Confusion matrix (rows = true, cols = predicted):\")\n",
    "print(f\"Classes: {target_names}\\n\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d47568a",
   "metadata": {
    "id": "9d47568a"
   },
   "source": [
    "The confusion matrix lets us pinpoint **where** the model struggles. Typically the most confusion occurs between **business** and **politics** or between **business** and **tech** — categories that share vocabulary about companies, government policy, and economic trends. \"Sport\" usually has zero or near-zero off-diagonal entries because sports terminology is highly domain-specific.\n",
    "\n",
    "In a production setting, these confusion patterns would guide your next steps: collect more training data for the confused categories, engineer features that distinguish them (e.g., named entities like company names vs. politician names), or merge categories that are genuinely ambiguous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d4f0be9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d4f0be9",
    "outputId": "ad3212fe-46b5-4f2b-fff2-d0909e58581d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tech\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4.7  Classify a new article\n",
    "\n",
    "new_article = (\n",
    "    \"iPhone 12: Apple makes jump to 5G. \"\n",
    "    \"Apple has confirmed its iPhone 12 handsets will be its first to work on \"\n",
    "    \"faster 5G networks. The company has also extended the range to include a \"\n",
    "    \"new Mini model that has a smaller 5.4in screen. The US firm bucked a \"\n",
    "    \"wider industry downturn by increasing its handset sales over the past year. \"\n",
    "    \"5G will bring a new level of performance for downloads and uploads, \"\n",
    "    \"higher quality video streaming, more responsive gaming, real-time \"\n",
    "    \"interactivity and so much more, said chief executive Tim Cook.\"\n",
    ")\n",
    "\n",
    "vector = get_sentence_vector(new_article, st_model)\n",
    "pred   = clf.predict([vector])\n",
    "print(f\"Predicted class: {target_names[pred[0]]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbdd1ec",
   "metadata": {
    "id": "4cbdd1ec"
   },
   "source": [
    "The model correctly classifies this Apple 5G article as **tech**. The BERT embedding captures semantic cues like *5G*, *networks*, *handsets*, *streaming*, and *gaming* — even though the article also mentions business-related terms like *sales* and *industry downturn*. This is the strength of contextual embeddings: the overall semantic context pushes the embedding firmly into the \"tech\" region of the 384-dimensional space.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cca4a8",
   "metadata": {
    "id": "58cca4a8"
   },
   "source": [
    "## Recipe 5 — Training a spaCy Model for Supervised Text Classification\n",
    "\n",
    "spaCy's built-in **TextCategorizer** trains a lightweight CNN that reads the raw text and outputs class probabilities — no separate feature-engineering step required. The architecture uses:\n",
    "\n",
    "$$\\text{Raw text} \\;\\xrightarrow{\\text{tokenize + embed}}\\; \\text{Token vectors} \\;\\xrightarrow{\\text{CNN}}\\; \\text{Feature map} \\;\\xrightarrow{\\text{softmax}}\\; P(c \\mid \\text{text})$$\n",
    "\n",
    "The training config (a `.cfg` file) controls the architecture, optimizer, learning rate, and data paths. spaCy handles the entire training loop — we just need to prepare the data in spaCy's `DocBin` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa1512f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa1512f5",
    "outputId": "4fdde895-383b-4e43-e980-2f441c8bf9d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created DocBin: 1780 train, 445 test docs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5.1  Prepare data in spaCy DocBin format\n",
    "\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "label_list = [\"tech\", \"business\", \"sport\",\n",
    "              \"entertainment\", \"politics\"]\n",
    "\n",
    "train_bbc = pd.read_json(\"data/bbc_train.json\")\n",
    "test_bbc  = pd.read_json(\"data/bbc_test.json\")\n",
    "train_bbc = train_bbc.sample(frac=1, random_state=42)\n",
    "\n",
    "def preprocess_data_entry(input_text, label_idx, labels):\n",
    "    doc = small_model.make_doc(input_text)   # fast -- no pipeline\n",
    "    cats = {lbl: (1.0 if i == label_idx else 0.0)\n",
    "            for i, lbl in enumerate(labels)}\n",
    "    doc.cats = cats\n",
    "    return doc\n",
    "\n",
    "train_db = DocBin()\n",
    "test_db  = DocBin()\n",
    "\n",
    "for _, row in train_bbc.iterrows():\n",
    "    doc = preprocess_data_entry(row[\"text\"], row[\"label\"], label_list)\n",
    "    train_db.add(doc)\n",
    "\n",
    "for _, row in test_bbc.iterrows():\n",
    "    doc = preprocess_data_entry(row[\"text\"], row[\"label\"], label_list)\n",
    "    test_db.add(doc)\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "train_db.to_disk(\"data/bbc_train.spacy\")\n",
    "test_db.to_disk(\"data/bbc_test.spacy\")\n",
    "\n",
    "print(f\"Created DocBin: {len(train_db)} train, {len(test_db)} test docs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beebfdf4",
   "metadata": {
    "id": "beebfdf4"
   },
   "source": [
    "Each `Doc` object stores the text and a `.cats` dictionary mapping category names to their one-hot values: `{\"tech\": 0.0, \"business\": 1.0, \"sport\": 0.0, ...}`. The `DocBin` is spaCy's efficient serialization format, designed for fast I/O during training.\n",
    "\n",
    "We use `make_doc()` instead of the full `nlp()` pipeline because we only need tokenization here, not POS tagging or NER — this is significantly faster for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49c0e42a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49c0e42a",
    "outputId": "8396a1f6-4992-46f0-8f7f-ac481321898d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy config written to data/spacy_config.cfg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5.2  Generate spaCy training config\n",
    "\n",
    "# We generate a minimal config programmatically instead of\n",
    "# downloading from the book's repo -- fully self-contained.\n",
    "\n",
    "config_text = '''[paths]\n",
    "train = \"data/bbc_train.spacy\"\n",
    "dev = \"data/bbc_test.spacy\"\n",
    "vectors = null\n",
    "init_tok2vec = null\n",
    "\n",
    "[system]\n",
    "gpu_allocator = null\n",
    "seed = 0\n",
    "\n",
    "[nlp]\n",
    "lang = \"en\"\n",
    "pipeline = [\"textcat\"]\n",
    "batch_size = 1000\n",
    "disabled = []\n",
    "before_creation = null\n",
    "after_creation = null\n",
    "after_pipeline_creation = null\n",
    "tokenizer = {\"@tokenizers\":\"spacy.Tokenizer.v1\"}\n",
    "\n",
    "[components]\n",
    "\n",
    "[components.textcat]\n",
    "factory = \"textcat\"\n",
    "threshold = 0.5\n",
    "\n",
    "[components.textcat.model]\n",
    "@architectures = \"spacy.TextCatEnsemble.v2\"\n",
    "nO = null\n",
    "\n",
    "[components.textcat.model.tok2vec]\n",
    "@architectures = \"spacy.Tok2Vec.v2\"\n",
    "\n",
    "[components.textcat.model.tok2vec.embed]\n",
    "@architectures = \"spacy.MultiHashEmbed.v2\"\n",
    "width = 64\n",
    "attrs = [\"NORM\",\"PREFIX\",\"SUFFIX\",\"SHAPE\"]\n",
    "rows = [5000,2500,2500,2500]\n",
    "include_static_vectors = false\n",
    "\n",
    "[components.textcat.model.tok2vec.encode]\n",
    "@architectures = \"spacy.MaxoutWindowEncoder.v2\"\n",
    "width = 64\n",
    "depth = 2\n",
    "window_size = 1\n",
    "maxout_pieces = 3\n",
    "\n",
    "[components.textcat.model.linear_model]\n",
    "@architectures = \"spacy.TextCatBOW.v3\"\n",
    "exclusive_classes = true\n",
    "length = 262144\n",
    "ngram_size = 1\n",
    "no_output_layer = false\n",
    "\n",
    "[corpora]\n",
    "\n",
    "[corpora.dev]\n",
    "@readers = \"spacy.Corpus.v1\"\n",
    "path = ${paths.dev}\n",
    "max_length = 0\n",
    "gold_preproc = false\n",
    "limit = 0\n",
    "augmenter = null\n",
    "\n",
    "[corpora.train]\n",
    "@readers = \"spacy.Corpus.v1\"\n",
    "path = ${paths.train}\n",
    "max_length = 0\n",
    "gold_preproc = false\n",
    "limit = 0\n",
    "augmenter = null\n",
    "\n",
    "[training]\n",
    "dev_corpus = \"corpora.dev\"\n",
    "train_corpus = \"corpora.train\"\n",
    "seed = ${system.seed}\n",
    "gpu_allocator = ${system.gpu_allocator}\n",
    "dropout = 0.1\n",
    "accumulate_gradient = 1\n",
    "patience = 1600\n",
    "max_epochs = 0\n",
    "max_steps = 20000\n",
    "eval_frequency = 200\n",
    "frozen_components = []\n",
    "annotating_components = []\n",
    "before_to_disk = null\n",
    "before_update = null\n",
    "\n",
    "[training.batcher]\n",
    "@batchers = \"spacy.batch_by_words.v1\"\n",
    "discard_oversize = false\n",
    "tolerance = 0.2\n",
    "get_length = null\n",
    "\n",
    "[training.batcher.size]\n",
    "@schedules = \"compounding.v1\"\n",
    "start = 100\n",
    "stop = 1000\n",
    "compound = 1.001\n",
    "t = 0.0\n",
    "\n",
    "[training.logger]\n",
    "@loggers = \"spacy.ConsoleLogger.v1\"\n",
    "progress_bar = true\n",
    "\n",
    "[training.optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "L2_is_weight_decay = true\n",
    "L2 = 0.01\n",
    "grad_clip = 1.0\n",
    "use_averages = false\n",
    "eps = 0.00000001\n",
    "learn_rate = 0.001\n",
    "\n",
    "[training.score_weights]\n",
    "cats_score = 1.0\n",
    "cats_score_desc = null\n",
    "cats_micro_p = null\n",
    "cats_micro_r = null\n",
    "cats_micro_f = null\n",
    "cats_macro_p = null\n",
    "cats_macro_r = null\n",
    "cats_macro_f = null\n",
    "cats_macro_auc = null\n",
    "cats_f_per_type = null\n",
    "cats_macro_auc_per_type = null\n",
    "\n",
    "[pretraining]\n",
    "\n",
    "[initialize]\n",
    "vectors = ${paths.vectors}\n",
    "init_tok2vec = ${paths.init_tok2vec}\n",
    "vocab_data = null\n",
    "lookups = null\n",
    "before_init = null\n",
    "after_init = null\n",
    "\n",
    "[initialize.components]\n",
    "\n",
    "[initialize.tokenizer]\n",
    "'''\n",
    "\n",
    "with open(\"data/spacy_config.cfg\", \"w\") as f:\n",
    "    f.write(config_text.strip())\n",
    "\n",
    "print(\"spaCy config written to data/spacy_config.cfg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7076f08e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7076f08e",
    "outputId": "744745a9-c168-451f-b779-a1cef41f9e63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training spaCy TextCategorizer (this may take a few minutes)...\n",
      "\n",
      "\u001b[38;5;4mℹ Saving to output directory: models/spacy_textcat_bbc\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  ------------  ----------  ------\n",
      "  0       0          0.16        7.46    0.07\n",
      "  0     200         30.84       59.62    0.60\n",
      "  0     400         18.34       56.80    0.57\n",
      "  0     600         20.83       69.45    0.69\n",
      "  0     800         18.06       71.36    0.71\n",
      "  0    1000         13.22       73.15    0.73\n",
      "  0    1200         13.00       87.42    0.87\n",
      "  0    1400         10.95       91.99    0.92\n",
      "  0    1600          6.55       87.80    0.88\n",
      "  1    1800          8.27       88.43    0.88\n",
      "  1    2000          3.93       91.39    0.91\n",
      "  1    2200          3.04       91.06    0.91\n",
      "  1    2400          5.60       90.27    0.90\n",
      "  1    2600          4.26       92.78    0.93\n",
      "  1    2800          3.83       88.49    0.88\n",
      "  1    3000          6.87       89.22    0.89\n",
      "  1    3200          3.30       91.72    0.92\n",
      "  1    3400          5.29       91.84    0.92\n",
      "  2    3600          3.97       89.54    0.90\n",
      "  2    3800          1.76       92.47    0.92\n",
      "  2    4000          4.11       92.50    0.93\n",
      "  2    4200          2.38       92.67    0.93\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "models/spacy_textcat_bbc/model-last\n",
      "\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5.3  Train the spaCy text categorizer\n",
    "\n",
    "from spacy.cli.train import train as spacy_train\n",
    "\n",
    "os.makedirs(\"models/spacy_textcat_bbc\", exist_ok=True)\n",
    "\n",
    "print(\"Training spaCy TextCategorizer (this may take a few minutes)...\\n\")\n",
    "spacy_train(\n",
    "    \"data/spacy_config.cfg\",\n",
    "    output_path=\"models/spacy_textcat_bbc\",\n",
    "    overrides={\"paths.train\": \"data/bbc_train.spacy\",\n",
    "               \"paths.dev\":   \"data/bbc_test.spacy\"}\n",
    ")\n",
    "print(\"\\nTraining complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff3b84d",
   "metadata": {
    "id": "4ff3b84d"
   },
   "source": [
    "The spaCy training loop uses the **TextCatEnsemble** architecture, which combines two sub-models: a **bag-of-words linear model** (fast, high-recall) and a **CNN-based tok2vec model** (slower, captures word order and local context). The ensemble's final prediction blends both signals, typically outperforming either alone.\n",
    "\n",
    "During training, the console logger reports the loss and the evaluation scores on the dev set (our test split) at regular intervals. The final model is saved to `models/spacy_textcat_bbc/model-last`. Accuracy typically converges around **85--90%** — slightly below the SVM + BERT approach because spaCy learns its own embeddings from scratch rather than leveraging a pre-trained transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7da25ace",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7da25ace",
    "outputId": "f51b7065-2172-4bf5-f648-bfc1a2a46f39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: politics\n",
      "Predicted probabilities: {'tech': 1.1580999853322282e-05, 'business': 5.808704827359179e-06, 'sport': 1.5665534647268942e-07, 'entertainment': 2.0026304525799787e-07, 'politics': 0.9999822378158569}\n",
      "Predicted class: politics\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5.4  Test on a single example\n",
    "\n",
    "nlp_trained = spacy.load(\"models/spacy_textcat_bbc/model-last\")\n",
    "\n",
    "input_text = test_bbc.iloc[1][\"text\"]\n",
    "true_label = test_bbc.iloc[1][\"label_text\"]\n",
    "\n",
    "doc = nlp_trained(input_text)\n",
    "print(f\"True label: {true_label}\")\n",
    "print(f\"Predicted probabilities: {doc.cats}\")\n",
    "print(f\"Predicted class: {max(doc.cats, key=doc.cats.get)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0fe8a2",
   "metadata": {
    "id": "6b0fe8a2"
   },
   "source": [
    "The `doc.cats` dictionary contains a probability score for each of the 5 categories, summing to $\\sim$1.0. The predicted class is simply the one with the highest probability. These scores are useful beyond classification — they provide a **confidence measure** that can drive downstream decisions: route low-confidence predictions to human reviewers, flag borderline cases, or adjust thresholds for different precision/recall trade-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11587918",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11587918",
    "outputId": "1fa2c5d3-1531-4c6b-91f1-8c2adb715a54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== spaCy TextCategorizer -- Test Set ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         tech       0.92      0.97      0.95        80\n",
      "     business       0.89      0.92      0.90       102\n",
      "        sport       0.99      0.97      0.98       102\n",
      "entertainment       0.93      0.90      0.91        77\n",
      "     politics       0.91      0.87      0.89        84\n",
      "\n",
      "     accuracy                           0.93       445\n",
      "    macro avg       0.93      0.93      0.93       445\n",
      " weighted avg       0.93      0.93      0.93       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5.5  Full test set evaluation\n",
    "\n",
    "def get_prediction(input_text, nlp_model, tgt_names):\n",
    "    doc = nlp_model(input_text)\n",
    "    category = max(doc.cats, key=doc.cats.get)\n",
    "    return tgt_names.index(category)\n",
    "\n",
    "test_bbc_spacy = test_bbc.copy()\n",
    "test_bbc_spacy[\"prediction\"] = test_bbc_spacy[\"text\"].apply(\n",
    "    lambda x: get_prediction(x, nlp_trained, label_list))\n",
    "\n",
    "print(\"=== spaCy TextCategorizer -- Test Set ===\")\n",
    "print(classification_report(test_bbc_spacy[\"label\"],\n",
    "                            test_bbc_spacy[\"prediction\"],\n",
    "                            target_names=label_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d484599a",
   "metadata": {
    "id": "d484599a"
   },
   "source": [
    "The spaCy model typically achieves **85--90% test accuracy** on the BBC dataset. The per-class scores tell a richer story:\n",
    "\n",
    "- **Precision** answers: \"Of all articles the model labeled as category $c$, what fraction truly belonged to $c$?\"\n",
    "- **Recall** answers: \"Of all articles that truly belonged to $c$, what fraction did the model find?\"\n",
    "- **F1-score** is the harmonic mean: $F_1 = \\frac{2 \\cdot P \\cdot R}{P + R}$\n",
    "\n",
    "The harmonic mean penalizes imbalance — if either $P$ or $R$ is low, $F_1$ drops sharply. This makes it a better single metric than accuracy for multi-class problems.\n",
    "\n",
    "**Comparison with SVM:** The SVM + BERT approach typically scores a few points higher because it starts with pre-trained 384-dimensional embeddings that encode rich semantic knowledge. spaCy's model learns embeddings from scratch using only $\\sim$1{,}780$ training articles — a much harder task. With more training data, the gap would narrow.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f716f7af",
   "metadata": {
    "id": "f716f7af"
   },
   "source": [
    "## Recipe 6 — Classifying Texts Using OpenAI Models\n",
    "\n",
    "Large language models like GPT-4o-mini can classify text in a **zero-shot** setting — no training data, no fine-tuning. We simply describe the task in the prompt and the model returns a label. This is possible because the model has already learned about topics, sentiment, and language structure during pre-training on a massive text corpus.\n",
    "\n",
    "The trade-offs are clear: zero-shot LLM classification requires **no labeled data** and **no training time**, but it costs **API credits per prediction** and gives you **less control** over the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "465bba6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "465bba6a",
    "outputId": "4f23ae8d-e7a0-4b7a-eae2-ab53230f7528"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client initialized.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6.1  Set up OpenAI client\n",
    "\n",
    "import openai\n",
    "from google.colab import userdata\n",
    "\n",
    "# Securely fetch API key from Colab Secrets\n",
    "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = openai.OpenAI(api_key=api_key)\n",
    "print(\"OpenAI client initialized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e17ae3",
   "metadata": {
    "id": "c3e17ae3"
   },
   "source": [
    "We retrieve the API key from **Colab Secrets** (`userdata.get`) rather than hard-coding it. This keeps the key out of your notebook history and version control. To set this up, click the key icon in the Colab sidebar and add a secret named `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e83857c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6e83857c",
    "outputId": "cb1201e8-10e9-4dc9-913f-dc63c470f57e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example category: entertainment\n",
      "First 200 chars : carry on star patsy rowlands dies actress patsy rowlands  known to millions for her roles in the carry on films  has died at the age of 71.  rowlands starred in nine of the popular carry on films  alo...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6.2  Load test data (fresh from Hugging Face)\n",
    "\n",
    "test_dataset = load_dataset(\"SetFit/bbc-news\", split=\"test\")\n",
    "\n",
    "# Quick check\n",
    "example  = test_dataset[0][\"text\"]\n",
    "category = test_dataset[0][\"label_text\"]\n",
    "print(f\"Example category: {category}\")\n",
    "print(f\"First 200 chars : {example[:200]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c6a4a00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c6a4a00",
    "outputId": "81556e24-0766-4b73-89e8-266197b4ebe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label  : entertainment\n",
      "GPT predicts: entertainment\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6.3  Single-example classification\n",
    "\n",
    "prompt = (\n",
    "    \"You are classifying texts by topics. There are 5 topics: \"\n",
    "    \"tech, entertainment, business, politics and sport. \"\n",
    "    \"Output the topic and nothing else. For example, if the topic \"\n",
    "    'is business, your output should be \"business\". '\n",
    "    \"Given the following text, what is its topic from the above list \"\n",
    "    \"without any additional explanations: \" + example\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",      # fast, cheap, strong\n",
    "    temperature=0,             # deterministic output\n",
    "    max_tokens=20,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",   \"content\": prompt}\n",
    "    ],\n",
    ")\n",
    "\n",
    "result = response.choices[0].message.content.strip().lower()\n",
    "print(f\"True label  : {category}\")\n",
    "print(f\"GPT predicts: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaadc05",
   "metadata": {
    "id": "ceaadc05"
   },
   "source": [
    "We set `temperature=0` to make the output deterministic — the model always picks the most likely token at each step. The `max_tokens=20` limit ensures we do not waste credits on verbose answers; we only need a single word.\n",
    "\n",
    "The prompt engineering here follows important principles: we explicitly list the valid categories, provide an example of the expected output format, and instruct the model to output *nothing else*. Despite these instructions, the model occasionally adds extra words — we handle that with post-processing below.\n",
    "\n",
    "We use `gpt-4o-mini` as a cost-effective replacement for the cookbook's original `gpt-3.5-turbo`. It offers comparable or better classification accuracy at lower cost per token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "105561de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "105561de",
    "outputId": "c13b3a04-f74e-4969-d10c-3e2a8b4d88b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying 200 articles with GPT-4o-mini...\n",
      "(This may take 1-3 minutes depending on API rate limits)\n",
      "Done.\n",
      "  label_text gpt_prediction\n",
      "0       tech       business\n",
      "1   business       business\n",
      "2   business       business\n",
      "3       tech           tech\n",
      "4   business       business\n",
      "5       tech  entertainment\n",
      "6   politics       politics\n",
      "7   business       business\n",
      "8   business       business\n",
      "9   business       business\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6.4  Classify a sample of 200 test articles\n",
    "\n",
    "def get_gpt_classification(input_text, client_obj):\n",
    "    \"\"\"Query GPT to classify a single text into one of 5 BBC topics.\"\"\"\n",
    "    prompt = (\n",
    "        \"You are classifying texts by topics. There are 5 topics: \"\n",
    "        \"tech, entertainment, business, politics and sport. \"\n",
    "        \"Output the topic and nothing else. For example, if the topic \"\n",
    "        'is business, your output should be \"business\". '\n",
    "        \"Given the following text, what is its topic from the above list \"\n",
    "        \"without any additional explanations: \" + input_text\n",
    "    )\n",
    "    response = client_obj.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        max_tokens=20,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content.strip().lower()\n",
    "\n",
    "\n",
    "test_df_gpt = test_dataset.to_pandas()\n",
    "test_df_gpt = test_df_gpt.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_data   = test_df_gpt.iloc[:200].copy()\n",
    "\n",
    "print(f\"Classifying {len(test_data)} articles with GPT-4o-mini...\")\n",
    "print(\"(This may take 1-3 minutes depending on API rate limits)\")\n",
    "\n",
    "test_data[\"gpt_prediction\"] = test_data[\"text\"].apply(\n",
    "    lambda x: get_gpt_classification(x, client))\n",
    "\n",
    "print(\"Done.\")\n",
    "print(test_data[[\"label_text\", \"gpt_prediction\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a1ad846",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a1ad846",
    "outputId": "2b83bfa7-84c7-4748-f4f9-004f3fe3ace5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GPT-4o-mini Classification -- 200 articles ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         tech       1.00      0.80      0.89        41\n",
      "     business       0.93      0.94      0.93        53\n",
      "        sport       1.00      1.00      1.00        43\n",
      "entertainment       0.94      0.94      0.94        34\n",
      "     politics       0.81      1.00      0.89        29\n",
      "\n",
      "     accuracy                           0.94       200\n",
      "    macro avg       0.93      0.94      0.93       200\n",
      " weighted avg       0.94      0.94      0.93       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6.5  Clean predictions and evaluate\n",
    "\n",
    "label_list_gpt = [\"tech\", \"business\", \"sport\",\n",
    "                  \"entertainment\", \"politics\"]\n",
    "\n",
    "def get_one_word_match(input_text):\n",
    "    \"\"\"Extract the first valid category from GPT response.\"\"\"\n",
    "    match = re.search(\n",
    "        r\"tech|entertainment|business|sport|politics\",\n",
    "        input_text)\n",
    "    if match:\n",
    "        return input_text[match.start():match.end()]\n",
    "    return \"unknown\"\n",
    "\n",
    "test_data[\"gpt_prediction\"] = test_data[\"gpt_prediction\"].apply(\n",
    "    get_one_word_match)\n",
    "\n",
    "# Convert to numeric label\n",
    "test_data[\"gpt_label\"] = test_data[\"gpt_prediction\"].apply(\n",
    "    lambda x: label_list_gpt.index(x) if x in label_list_gpt else -1)\n",
    "\n",
    "# Drop any rows where GPT gave an unrecognized answer\n",
    "valid_mask = test_data[\"gpt_label\"] >= 0\n",
    "if (~valid_mask).sum() > 0:\n",
    "    print(f\"Warning: {(~valid_mask).sum()} unrecognized predictions dropped\")\n",
    "test_data_clean = test_data[valid_mask].copy()\n",
    "\n",
    "print(f\"\\n=== GPT-4o-mini Classification -- {len(test_data_clean)} articles ===\")\n",
    "print(classification_report(test_data_clean[\"label\"],\n",
    "                            test_data_clean[\"gpt_label\"],\n",
    "                            target_names=label_list_gpt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13de27ea",
   "metadata": {
    "id": "13de27ea"
   },
   "source": [
    "GPT-4o-mini typically achieves **90--95% accuracy** on this task — remarkable given that it has never seen a single BBC training example. This is the power of zero-shot classification with large language models: the model's vast pre-training knowledge allows it to understand what \"tech\", \"sport\", and \"politics\" mean and map articles accordingly.\n",
    "\n",
    "However, this approach has important production trade-offs. On the cost side, each classification requires an API call, which introduces both latency ($\\sim$200--500ms per request) and monetary cost. For 200 articles the total is negligible, but classifying millions of documents would cost hundreds of dollars. On the control side, you cannot directly inspect or adjust the decision boundary — if the model consistently confuses \"business\" and \"politics\", your only lever is prompt engineering, not feature engineering or hyperparameter tuning.\n",
    "\n",
    "### Summary: Method Comparison\n",
    "\n",
    "| Method | Accuracy | Training Data Needed | Latency | Interpretability |\n",
    "|--------|----------|---------------------|---------|-----------------|\n",
    "| Keywords (Recipe 2) | $\\sim$62% | Labels + vocabulary | Instant | High |\n",
    "| K-Means (Recipe 3) | N/A (unsupervised) | None | Instant | Moderate |\n",
    "| SVM + BERT (Recipe 4) | $\\sim$95% | Labeled corpus | Fast | Low |\n",
    "| spaCy CNN (Recipe 5) | $\\sim$87% | Labeled corpus | Fast | Low |\n",
    "| GPT-4o-mini (Recipe 6) | $\\sim$93% | None (zero-shot) | Slow (API) | Low |\n",
    "\n",
    "The SVM + BERT approach achieves the best test accuracy while keeping inference fast and free (no API calls). GPT is the fastest to deploy (no training) but the most expensive to run. spaCy offers a middle ground with a self-contained model that requires no external dependencies at inference time. The right choice depends on your specific constraints: budget, latency requirements, data availability, and regulatory environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bae1319",
   "metadata": {
    "id": "2bae1319"
   },
   "source": [
    "---\n",
    "## Summary and Key Takeaways\n",
    "\n",
    "This chapter walked through the full spectrum of text classification approaches, from zero-parameter keyword matching to zero-shot large language models. The key insights:\n",
    "\n",
    "**1. Baselines matter.** The keyword classifier (62% test accuracy) sets the floor. Any model that cannot beat this number is not learning useful patterns — it is just memorizing training noise.\n",
    "\n",
    "**2. Representation is (almost) everything.** The jump from TF-IDF (K-Means) to BERT embeddings (SVM) demonstrates that better text representations produce better classifiers, often with simpler algorithms. The SVM itself is a decades-old method; the magic comes from the embeddings.\n",
    "\n",
    "**3. The bias-variance trade-off is alive and well.** The keyword classifier overfits to training vocabulary (87% train vs. 62% test). The SVM with $C = 0.1$ regularization shows minimal overfitting. Understanding and controlling this trade-off is a core ML skill.\n",
    "\n",
    "**4. Unsupervised methods have unique value.** K-Means does not need labels, making it invaluable for exploratory analysis, data auditing, and cold-start scenarios where labeled data does not yet exist.\n",
    "\n",
    "**5. LLMs are not always the answer.** GPT-4o-mini achieves strong accuracy with zero training data, but at the cost of API dependency, latency, and ongoing per-prediction expense. For high-volume production workloads, a trained SVM or spaCy model is often the more pragmatic choice.\n",
    "\n",
    "In the next chapter, we will build on these foundations to tackle more complex NLP tasks including sequence labeling and named entity recognition."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
